{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "import copy\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "from optuna.integration import lightgbm as lgb_optuna\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20120101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36152\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "df = pd.read_csv('testcsvs/testout.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "df = df[(df['a_glicko_rd'] <= 150) & (df['b_glicko_rd'] <= 150)]\n",
    "\n",
    "df = df.drop(['tourney_id','match_num', 'tourney_name', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug'], axis=1)\n",
    "\n",
    "# df = pd.DataFrame(games).drop(['tourney_id', 'tourney_name', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug','a_win_percent', 'a_serve_rating', 'a_return_rating', 'a_pressure_rating', 'a_avg_vs_elo', 'a_matches_played', 'b_win_percent', 'b_serve_rating', 'b_return_rating', 'b_pressure_rating', 'b_avg_vs_elo', 'b_matches_played', 'A_Odds', 'b_odds'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>a_glicko_rating</th>\n",
       "      <th>a_glicko_rd</th>\n",
       "      <th>a_glicko_vol</th>\n",
       "      <th>a_point_glicko_rating</th>\n",
       "      <th>a_point_glicko_rd</th>\n",
       "      <th>a_point_glicko_vol</th>\n",
       "      <th>a_game_glicko_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>b_surface_second_won_glicko_vol</th>\n",
       "      <th>b_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_return_second_won_glicko_vol</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1839.797067</td>\n",
       "      <td>66.607302</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>1531.323923</td>\n",
       "      <td>62.908167</td>\n",
       "      <td>0.059333</td>\n",
       "      <td>1564.401893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059353</td>\n",
       "      <td>1514.785695</td>\n",
       "      <td>64.544807</td>\n",
       "      <td>0.059353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1704.915868</td>\n",
       "      <td>66.531031</td>\n",
       "      <td>0.059971</td>\n",
       "      <td>1521.849326</td>\n",
       "      <td>63.670643</td>\n",
       "      <td>0.059581</td>\n",
       "      <td>1543.174689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>1524.305006</td>\n",
       "      <td>62.313940</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1570.551049</td>\n",
       "      <td>83.226172</td>\n",
       "      <td>0.059989</td>\n",
       "      <td>1511.282842</td>\n",
       "      <td>71.979231</td>\n",
       "      <td>0.059878</td>\n",
       "      <td>1516.780899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059383</td>\n",
       "      <td>1508.366657</td>\n",
       "      <td>63.335804</td>\n",
       "      <td>0.059383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1731.171432</td>\n",
       "      <td>66.027320</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>1516.808438</td>\n",
       "      <td>63.500630</td>\n",
       "      <td>0.059475</td>\n",
       "      <td>1541.510490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059427</td>\n",
       "      <td>1507.539322</td>\n",
       "      <td>63.640647</td>\n",
       "      <td>0.059427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1545.639101</td>\n",
       "      <td>79.730461</td>\n",
       "      <td>0.060001</td>\n",
       "      <td>1503.968536</td>\n",
       "      <td>69.668106</td>\n",
       "      <td>0.059875</td>\n",
       "      <td>1503.773430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058717</td>\n",
       "      <td>1503.340027</td>\n",
       "      <td>62.313771</td>\n",
       "      <td>0.058717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  a_player_rank  b_player_rank  a_glicko_rating  a_glicko_rd  \\\n",
       "5373      3.0           15.0           74.0      1839.797067    66.607302   \n",
       "5375      3.0           46.0           65.0      1704.915868    66.531031   \n",
       "5377      3.0           95.0           89.0      1570.551049    83.226172   \n",
       "5378      3.0           48.0           83.0      1731.171432    66.027320   \n",
       "5380      3.0           70.0           22.0      1545.639101    79.730461   \n",
       "\n",
       "      a_glicko_vol  a_point_glicko_rating  a_point_glicko_rd  \\\n",
       "5373      0.059900            1531.323923          62.908167   \n",
       "5375      0.059971            1521.849326          63.670643   \n",
       "5377      0.059989            1511.282842          71.979231   \n",
       "5378      0.059948            1516.808438          63.500630   \n",
       "5380      0.060001            1503.968536          69.668106   \n",
       "\n",
       "      a_point_glicko_vol  a_game_glicko_rating  ...  \\\n",
       "5373            0.059333           1564.401893  ...   \n",
       "5375            0.059581           1543.174689  ...   \n",
       "5377            0.059878           1516.780899  ...   \n",
       "5378            0.059475           1541.510490  ...   \n",
       "5380            0.059875           1503.773430  ...   \n",
       "\n",
       "      b_surface_second_won_glicko_vol  \\\n",
       "5373                         0.059353   \n",
       "5375                         0.058877   \n",
       "5377                         0.059383   \n",
       "5378                         0.059427   \n",
       "5380                         0.058717   \n",
       "\n",
       "      b_surface_return_second_won_glicko_rating  \\\n",
       "5373                                1514.785695   \n",
       "5375                                1524.305006   \n",
       "5377                                1508.366657   \n",
       "5378                                1507.539322   \n",
       "5380                                1503.340027   \n",
       "\n",
       "      b_surface_return_second_won_glicko_rd  \\\n",
       "5373                              64.544807   \n",
       "5375                              62.313940   \n",
       "5377                              63.335804   \n",
       "5378                              63.640647   \n",
       "5380                              62.313771   \n",
       "\n",
       "      b_surface_return_second_won_glicko_vol  a_b_win  a_odds  b_odds  \\\n",
       "5373                                0.059353      1.0    1.28    3.59   \n",
       "5375                                0.058877      0.0     NaN     NaN   \n",
       "5377                                0.059383      1.0    1.59    2.29   \n",
       "5378                                0.059427      0.0    2.40    1.54   \n",
       "5380                                0.058717      0.0    4.44    1.19   \n",
       "\n",
       "      surface_Clay  surface_Grass  surface_Hard  \n",
       "5373           0.0            0.0           1.0  \n",
       "5375           0.0            0.0           1.0  \n",
       "5377           0.0            0.0           1.0  \n",
       "5378           0.0            0.0           1.0  \n",
       "5380           0.0            0.0           1.0  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(features, df_train, df_validate, df_test):\n",
    "    y_train = df_train[\"Result\"]\n",
    "    y_validate = df_validate[\"Result\"]\n",
    "    y_test = df_test[\"Result\"]\n",
    "\n",
    "    X_train = df_train[features]\n",
    "    X_validate = df_validate[features]\n",
    "    X_test = df_test[features]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_eval = lgb.Dataset(X_validate, label=y_validate, reference=lgb_train)\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        'num_leaves': [31, 50, 70],\n",
    "        'feature_fraction': [0.8, 0.9, 1.0],\n",
    "        'bagging_fraction': [0.8, 0.9, 1.0],\n",
    "        'min_child_samples': [20, 30, 40],\n",
    "        'lambda_l1': [0.0, 0.1, 0.5],\n",
    "        'lambda_l2': [0.0, 0.1, 0.5],\n",
    "        'max_depth': [-1, 10, 20],\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # LightGBM model\n",
    "    gbm = lgb.LGBMClassifier(**params, n_estimators=300)\n",
    "\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, \n",
    "                               scoring='roc_auc', cv=skf, verbose=1, n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    \n",
    "    # Use the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, df_test, features):\n",
    "    X_test = df_test[features]\n",
    "    y_test = df_test[\"Result\"]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == 0.5).any(axis=1)]\n",
    "\n",
    "# Extract and manage odds columns\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "# Split the data into features and target\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the training set further into training and validation sets\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert back to DataFrames to match your trainModel function expectations\n",
    "df_train = pd.DataFrame(X_train, columns=df.columns.drop('a_b_win'))\n",
    "df_train['Result'] = y_train\n",
    "\n",
    "df_validate = pd.DataFrame(X_validate, columns=df.columns.drop('a_b_win'))\n",
    "df_validate['Result'] = y_validate\n",
    "\n",
    "df_test = pd.DataFrame(X_test, columns=df.columns.drop('a_b_win'))\n",
    "df_test['Result'] = y_test\n",
    "\n",
    "# List of features you want to use for training\n",
    "selected_features = df_train.columns.drop('Result').tolist()  # This includes all features except the target column\n",
    "\n",
    "# Train the model with hyperparameter tuning and cross-validation\n",
    "model = trainModel(selected_features, df_train, df_validate, df_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_metrics = evaluateModel(model, df_test, selected_features)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {evaluation_metrics['accuracy']:.4f}\")\n",
    "print(f\"AUC: {evaluation_metrics['auc']:.4f}\")\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for the feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # To have the most important features on top\n",
    "plt.show()\n",
    "\n",
    "# Optionally, save the model to a file\n",
    "model.booster_.save_model('lightgbm_model.txt')\n",
    "\n",
    "# Optionally save predictions with odds\n",
    "y_pred = model.predict(X_test)\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'A_Odds': odds_df.loc[idx_test, 'a_odds'].values,\n",
    "    'B_Odds': odds_df.loc[idx_test, 'b_odds'].values\n",
    "})\n",
    "\n",
    "results_df.to_csv('predictions_with_odds.csv', index=False)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Receiver Operating Characteristics\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[330], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# results_df.head()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "confidence_pct = .7\n",
    "confidence_top_pct = .8\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct and row['Predicted'] > 1/row['A_Odds']:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1\n",
    "            total_won += row['A_Odds']-1\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= 1\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct and 1-row['Predicted'] > 1/row['B_Odds']:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1\n",
    "            total_won += row['B_Odds']-1\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= 1\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total won on $1 bets: {total_won:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"Amount of differing favorites {diff_fav/length}\")\n",
    "print(f\"Amount of incorrect bets : {wrong/better}\")\n",
    "print(f\"Correct Bets: {bet_correct/better}\")\n",
    "print(f\"Model % Correct : {model_correct/length} Vegas Correct % : {vegas_correct/length}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
