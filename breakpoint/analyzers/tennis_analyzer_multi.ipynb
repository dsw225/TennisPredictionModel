{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import joblib\n",
    "import math\n",
    "from datetime import datetime\n",
    "from math import ceil, floor\n",
    "\n",
    "import django\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from asgiref.sync import sync_to_async  # type: ignore\n",
    "from django.db import models\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "from lightgbm import LGBMClassifier\n",
    "from optuna.integration import lightgbm as lgb_optuna\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightgbm as lgb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20120101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36157\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "df = pd.read_csv('testcsvs/glickoalltest.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "df = df[(df['a_glicko_rd'] <= 150) & (df['b_glicko_rd'] <= 150)]\n",
    "\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "\n",
    "# df = pd.DataFrame(games).drop(['tourney_id', 'tourney_name', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug','a_win_percent', 'a_serve_rating', 'a_return_rating', 'a_pressure_rating', 'a_avg_vs_elo', 'a_matches_played', 'b_win_percent', 'b_serve_rating', 'b_return_rating', 'b_pressure_rating', 'b_avg_vs_elo', 'b_matches_played', 'A_Odds', 'b_odds'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>glicko_rating_diff_high</th>\n",
       "      <th>glicko_rating_diff_low</th>\n",
       "      <th>a_glicko_rating</th>\n",
       "      <th>b_glicko_rating</th>\n",
       "      <th>a_glicko_rd</th>\n",
       "      <th>b_glicko_rd</th>\n",
       "      <th>point_glicko_rating_diff_high</th>\n",
       "      <th>...</th>\n",
       "      <th>surface_return_second_won_glicko_rating_diff_high</th>\n",
       "      <th>surface_return_second_won_glicko_rating_diff_low</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-311.617231</td>\n",
       "      <td>-40.704658</td>\n",
       "      <td>1663.254111</td>\n",
       "      <td>1839.415055</td>\n",
       "      <td>69.063534</td>\n",
       "      <td>66.392752</td>\n",
       "      <td>-145.321147</td>\n",
       "      <td>...</td>\n",
       "      <td>-141.831083</td>\n",
       "      <td>110.643651</td>\n",
       "      <td>1514.815163</td>\n",
       "      <td>1530.408879</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-147.093176</td>\n",
       "      <td>121.020149</td>\n",
       "      <td>1691.581925</td>\n",
       "      <td>1704.618439</td>\n",
       "      <td>67.784328</td>\n",
       "      <td>66.272335</td>\n",
       "      <td>-128.899533</td>\n",
       "      <td>...</td>\n",
       "      <td>-124.671282</td>\n",
       "      <td>124.710330</td>\n",
       "      <td>1524.284813</td>\n",
       "      <td>1524.265289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-181.835201</td>\n",
       "      <td>123.629608</td>\n",
       "      <td>1570.250330</td>\n",
       "      <td>1599.353126</td>\n",
       "      <td>82.839194</td>\n",
       "      <td>69.893210</td>\n",
       "      <td>-124.286662</td>\n",
       "      <td>...</td>\n",
       "      <td>-126.885213</td>\n",
       "      <td>130.276738</td>\n",
       "      <td>1510.001918</td>\n",
       "      <td>1508.306155</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-45.128121</td>\n",
       "      <td>225.802369</td>\n",
       "      <td>1730.873087</td>\n",
       "      <td>1640.535963</td>\n",
       "      <td>65.783232</td>\n",
       "      <td>69.682012</td>\n",
       "      <td>-126.628591</td>\n",
       "      <td>...</td>\n",
       "      <td>-124.858464</td>\n",
       "      <td>126.689605</td>\n",
       "      <td>1508.449284</td>\n",
       "      <td>1507.533713</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-452.184818</td>\n",
       "      <td>-159.378373</td>\n",
       "      <td>1545.426123</td>\n",
       "      <td>1851.207719</td>\n",
       "      <td>79.493396</td>\n",
       "      <td>66.909826</td>\n",
       "      <td>-168.130661</td>\n",
       "      <td>...</td>\n",
       "      <td>-142.624208</td>\n",
       "      <td>109.143893</td>\n",
       "      <td>1486.596303</td>\n",
       "      <td>1503.336460</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  a_player_rank  b_player_rank  glicko_rating_diff_high  \\\n",
       "5373      3.0           74.0           15.0              -311.617231   \n",
       "5375      3.0           65.0           46.0              -147.093176   \n",
       "5377      3.0           95.0           89.0              -181.835201   \n",
       "5378      3.0           48.0           83.0               -45.128121   \n",
       "5380      3.0           70.0           22.0              -452.184818   \n",
       "\n",
       "      glicko_rating_diff_low  a_glicko_rating  b_glicko_rating  a_glicko_rd  \\\n",
       "5373              -40.704658      1663.254111      1839.415055    69.063534   \n",
       "5375              121.020149      1691.581925      1704.618439    67.784328   \n",
       "5377              123.629608      1570.250330      1599.353126    82.839194   \n",
       "5378              225.802369      1730.873087      1640.535963    65.783232   \n",
       "5380             -159.378373      1545.426123      1851.207719    79.493396   \n",
       "\n",
       "      b_glicko_rd  point_glicko_rating_diff_high  ...  \\\n",
       "5373    66.392752                    -145.321147  ...   \n",
       "5375    66.272335                    -128.899533  ...   \n",
       "5377    69.893210                    -124.286662  ...   \n",
       "5378    69.682012                    -126.628591  ...   \n",
       "5380    66.909826                    -168.130661  ...   \n",
       "\n",
       "      surface_return_second_won_glicko_rating_diff_high  \\\n",
       "5373                                        -141.831083   \n",
       "5375                                        -124.671282   \n",
       "5377                                        -126.885213   \n",
       "5378                                        -124.858464   \n",
       "5380                                        -142.624208   \n",
       "\n",
       "      surface_return_second_won_glicko_rating_diff_low  \\\n",
       "5373                                        110.643651   \n",
       "5375                                        124.710330   \n",
       "5377                                        130.276738   \n",
       "5378                                        126.689605   \n",
       "5380                                        109.143893   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rating  \\\n",
       "5373                                1514.815163   \n",
       "5375                                1524.284813   \n",
       "5377                                1510.001918   \n",
       "5378                                1508.449284   \n",
       "5380                                1486.596303   \n",
       "\n",
       "      b_surface_second_won_glicko_rating  a_odds  b_odds  a_b_win  \\\n",
       "5373                         1530.408879    3.59    1.28      0.0   \n",
       "5375                         1524.265289     NaN     NaN      1.0   \n",
       "5377                         1508.306155    1.59    2.29      1.0   \n",
       "5378                         1507.533713    2.40    1.54      0.0   \n",
       "5380                         1503.336460    4.44    1.19      0.0   \n",
       "\n",
       "      surface_Clay  surface_Grass  surface_Hard  \n",
       "5373           0.0            0.0           1.0  \n",
       "5375           0.0            0.0           1.0  \n",
       "5377           0.0            0.0           1.0  \n",
       "5378           0.0            0.0           1.0  \n",
       "5380           0.0            0.0           1.0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata, norm\n",
    "\n",
    "def rank_gauss_transform(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Applies the Rank Gauss transform to a pandas Series.\"\"\"\n",
    "    # Rank the data\n",
    "    ranked = rankdata(series, method='average')\n",
    "    # Scale the ranks to be between -1 and 1\n",
    "    scaled_ranks = (ranked - 0.5) / len(series)\n",
    "    # Apply the inverse normal (gaussian) CDF\n",
    "    transformed = norm.ppf(scaled_ranks)\n",
    "    return pd.Series(transformed, index=series.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's binary_logloss: 0.518712\tvalid_1's binary_logloss: 0.592064\n",
      "LightGBM Accuracy: 0.6805396096440872\n",
      "LightGBM ROC AUC: 0.749610595109569\n",
      "Epoch 10/50, Loss: 0.5437866449356079\n",
      "Epoch 20/50, Loss: 0.4960002899169922\n",
      "Epoch 30/50, Loss: 0.3898712396621704\n",
      "Epoch 40/50, Loss: 0.3576592803001404\n",
      "Epoch 50/50, Loss: 0.4251019060611725\n",
      "PyTorch Accuracy: 0.6093570608495982\n",
      "PyTorch ROC AUC: 0.637091784174915\n",
      "LightGBM Accuracy: 0.6805396096440872, ROC AUC: 0.749610595109569\n",
      "PyTorch Accuracy: 0.6093570608495982, ROC AUC: 0.637091784174915\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == .5).any(axis=1)]\n",
    "df = df[~(df == -20).any(axis=1)]\n",
    "\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "feature_names = df.drop('a_b_win', axis=1).columns.tolist()\n",
    "X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "# Apply Rank Gauss Transformation to all features\n",
    "X_train_transformed = X_train_df.apply(rank_gauss_transform, axis=0)\n",
    "X_test_transformed = X_test_df.apply(rank_gauss_transform, axis=0)\n",
    "\n",
    "# Convert back to numpy arrays for modeling\n",
    "X_train_transformed = X_train_transformed.values\n",
    "X_test_transformed = X_test_transformed.values\n",
    "\n",
    "# LightGBM Model Training\n",
    "train_data = lgb.Dataset(X_train_transformed, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_transformed, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "lgbm_model = lgb.train(params, train_data, valid_sets=[train_data, test_data], num_boost_round=1000, callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
    "\n",
    "# LightGBM Predictions and Evaluation\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_transformed)\n",
    "y_pred_lgbm_binary = [1 if prob > 0.5 else 0 for prob in y_pred_lgbm]\n",
    "\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm_binary)\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(f'LightGBM Accuracy: {accuracy_lgbm}')\n",
    "print(f'LightGBM ROC AUC: {roc_auc_lgbm}')\n",
    "\n",
    "# PyTorch Model Definition\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Convert transformed data to tensors for PyTorch\n",
    "# Convert transformed data to tensors for PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_transformed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_transformed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# DataLoader for PyTorch\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the PyTorch model, loss function, and optimizer\n",
    "input_dim = X_train_transformed.shape[1]\n",
    "model = BinaryClassificationModel(input_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the PyTorch Model\n",
    "num_epochs = 50\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# PyTorch Predictions and Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_pytorch = model(X_test_tensor).squeeze()\n",
    "    y_pred_pytorch_binary = (y_pred_pytorch > 0.5).float()\n",
    "\n",
    "accuracy_pytorch = accuracy_score(y_test_tensor, y_pred_pytorch_binary)\n",
    "roc_auc_pytorch = roc_auc_score(y_test_tensor, y_pred_pytorch)\n",
    "\n",
    "print(f'PyTorch Accuracy: {accuracy_pytorch}')\n",
    "print(f'PyTorch ROC AUC: {roc_auc_pytorch}')\n",
    "\n",
    "# Comparison of Results\n",
    "print(f'LightGBM Accuracy: {accuracy_lgbm}, ROC AUC: {roc_auc_lgbm}')\n",
    "print(f'PyTorch Accuracy: {accuracy_pytorch}, ROC AUC: {roc_auc_pytorch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# results_df.head()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = (vegas_odds * calculated_probability - (1 - calculated_probability)) / vegas_odds\n",
    "    \n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total won on $10 bets: -305.43 on a total # bets: 3484 from a total of 3484 games\n",
      "Amount of differing favorites 0.13662456946039037\n",
      "Amount of upset correct 0.4264705882352941 won $-212.89999999999992 on 476 bets\n",
      "Amount of incorrect bets : 0.3145809414466131\n",
      "Correct Bets: 0.6854190585533869\n",
      "Model % Correct : 0.6854190585533869 Vegas Correct % : 0.7049368541905855\n"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "confidence_pct = .5\n",
    "confidence_top_pct = 1\n",
    "\n",
    "UNIT = 10\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :#and row['Predicted'] > 1/row['A_Odds']:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1\n",
    "            total_won += (row['A_Odds']-1) * (kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= (kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :#and 1-row['Predicted'] > 1/row['B_Odds']:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1\n",
    "            total_won += (row['B_Odds']-1) * (kelly_criterion(row['B_Odds'],row['Predicted']) * UNIT)\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= (kelly_criterion(row['B_Odds'],row['Predicted']) * UNIT)\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        upset_predict += 1\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            upset_correct += 1\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_won += (row['A_Odds']-1) * UNIT\n",
    "            else:\n",
    "                upset_won += (row['B_Odds']-1) * UNIT\n",
    "        else:\n",
    "            upset_won -= UNIT\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total won on ${UNIT} bets: {total_won:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"Amount of differing favorites {diff_fav/length}\")\n",
    "print(f\"Amount of upset correct {upset_correct/upset_predict} won ${upset_won} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bets : {wrong/better}\")\n",
    "print(f\"Correct Bets: {bet_correct/better}\")\n",
    "print(f\"Model % Correct : {model_correct/length} Vegas Correct % : {vegas_correct/length}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
