{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20120101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32397\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "RD_CUTOFF = 125\n",
    "\n",
    "df = pd.read_csv('../testcsvs/glickoUpdated.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "df = df[(df['a_surface_glicko_rd'] <= RD_CUTOFF) & (df['b_surface_glicko_rd'] <= RD_CUTOFF) & (df['a_glicko_rd'] <= RD_CUTOFF) & (df['b_glicko_rd'] <= RD_CUTOFF)]\n",
    "\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_age</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>b_player_age</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>glicko_rating_diff</th>\n",
       "      <th>a_glicko_rating</th>\n",
       "      <th>b_glicko_rating</th>\n",
       "      <th>a_glicko_rd</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_second_won_glicko_rd</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-156.391443</td>\n",
       "      <td>1648.533408</td>\n",
       "      <td>1804.924851</td>\n",
       "      <td>73.590383</td>\n",
       "      <td>...</td>\n",
       "      <td>1509.676357</td>\n",
       "      <td>1525.177533</td>\n",
       "      <td>68.224718</td>\n",
       "      <td>63.306180</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.779397</td>\n",
       "      <td>1684.801531</td>\n",
       "      <td>1682.022134</td>\n",
       "      <td>68.576543</td>\n",
       "      <td>...</td>\n",
       "      <td>1520.481105</td>\n",
       "      <td>1493.441526</td>\n",
       "      <td>64.043825</td>\n",
       "      <td>72.508115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-61.159514</td>\n",
       "      <td>1621.512570</td>\n",
       "      <td>1682.672084</td>\n",
       "      <td>76.007944</td>\n",
       "      <td>...</td>\n",
       "      <td>1506.545429</td>\n",
       "      <td>1507.882055</td>\n",
       "      <td>67.307645</td>\n",
       "      <td>65.888687</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-65.573917</td>\n",
       "      <td>1697.467187</td>\n",
       "      <td>1763.041103</td>\n",
       "      <td>68.133731</td>\n",
       "      <td>...</td>\n",
       "      <td>1517.206849</td>\n",
       "      <td>1534.732931</td>\n",
       "      <td>63.710167</td>\n",
       "      <td>64.101412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-75.476705</td>\n",
       "      <td>1697.646993</td>\n",
       "      <td>1773.123697</td>\n",
       "      <td>71.445373</td>\n",
       "      <td>...</td>\n",
       "      <td>1494.807275</td>\n",
       "      <td>1535.923504</td>\n",
       "      <td>68.493754</td>\n",
       "      <td>63.744405</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  tourney_round  a_player_age  a_player_rank  b_player_age  \\\n",
       "5373      3.0            0.8          28.0           74.0          23.0   \n",
       "5375      3.0            0.8          28.0           65.0          25.0   \n",
       "5378      3.0            0.8          26.0           83.0          24.0   \n",
       "5381      3.0            0.8          28.0           65.0          27.0   \n",
       "5382      3.0            0.8          29.0           57.0          27.0   \n",
       "\n",
       "      b_player_rank  glicko_rating_diff  a_glicko_rating  b_glicko_rating  \\\n",
       "5373           15.0         -156.391443      1648.533408      1804.924851   \n",
       "5375           46.0            2.779397      1684.801531      1682.022134   \n",
       "5378           48.0          -61.159514      1621.512570      1682.672084   \n",
       "5381           38.0          -65.573917      1697.467187      1763.041103   \n",
       "5382           38.0          -75.476705      1697.646993      1773.123697   \n",
       "\n",
       "      a_glicko_rd  ...  a_surface_return_second_won_glicko_rating  \\\n",
       "5373    73.590383  ...                                1509.676357   \n",
       "5375    68.576543  ...                                1520.481105   \n",
       "5378    76.007944  ...                                1506.545429   \n",
       "5381    68.133731  ...                                1517.206849   \n",
       "5382    71.445373  ...                                1494.807275   \n",
       "\n",
       "      b_surface_second_won_glicko_rating  \\\n",
       "5373                         1525.177533   \n",
       "5375                         1493.441526   \n",
       "5378                         1507.882055   \n",
       "5381                         1534.732931   \n",
       "5382                         1535.923504   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rd  b_surface_second_won_glicko_rd  \\\n",
       "5373                              68.224718                       63.306180   \n",
       "5375                              64.043825                       72.508115   \n",
       "5378                              67.307645                       65.888687   \n",
       "5381                              63.710167                       64.101412   \n",
       "5382                              68.493754                       63.744405   \n",
       "\n",
       "      a_odds  b_odds  a_b_win  surface_Clay  surface_Grass  surface_Hard  \n",
       "5373    3.59    1.28      0.0           0.0            0.0           1.0  \n",
       "5375     NaN     NaN      1.0           0.0            0.0           1.0  \n",
       "5378    1.54    2.40      1.0           0.0            0.0           1.0  \n",
       "5381     NaN     NaN      0.0           0.0            0.0           1.0  \n",
       "5382    2.34    1.56      0.0           0.0            0.0           1.0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.shortcut = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn(self.fc(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "class OutcomeProbabilityV6(nn.Module):\n",
    "    def __init__(self, input_dim=172, dropout_prob=0.33):\n",
    "        hidden_dim1=input_dim * 2\n",
    "        hidden_dim2=input_dim\n",
    "        hidden_dim3=round(input_dim/2) \n",
    "        super(OutcomeProbabilityV6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(hidden_dim1, hidden_dim1)\n",
    "        self.res_block2 = ResidualBlock(hidden_dim1, hidden_dim2)\n",
    "        self.res_block3 = ResidualBlock(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        \n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, epochs=100, learning_rate=0.0001, weight_decay=1e-5, target_accuracy=0.75):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    best_acc = -np.inf\n",
    "    best_weights = None\n",
    "    early_stopping_patience = 20\n",
    "    early_stopping_counter = 0\n",
    "    current_epoch = 0\n",
    "\n",
    "    while best_acc < target_accuracy and current_epoch < epochs:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                y_pred = model(X_batch)\n",
    "                val_loss += loss_fn(y_pred, y_batch).item() * X_batch.size(0)\n",
    "                predicted = y_pred.round()\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        acc = correct / total\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        # if early_stopping_counter >= early_stopping_patience:\n",
    "        #     print(\"Early stopping triggered\")\n",
    "        #     break\n",
    "\n",
    "        if (current_epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{current_epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {acc*100:.2f}%')\n",
    "\n",
    "        current_epoch += 1\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "def cross_validate(model_class, X, y, folds=5, epochs=100, batch_size=128, target_accuracy=0.75):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    best_acc = 0.0\n",
    "    best_model_weights = None\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        print(f\"Fold {fold + 1}/{folds}\")\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        X_train_fold = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
    "        X_val_fold = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        train_data = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_data = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = model_class(input_dim=X.shape[1])\n",
    "        fold_acc, fold_weights = train_and_evaluate(model, train_loader, val_loader, epochs=epochs, target_accuracy=target_accuracy)\n",
    "        if fold_acc > best_acc:\n",
    "            best_acc = fold_acc\n",
    "            best_model_weights = fold_weights\n",
    "\n",
    "    return best_acc, best_model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6118, Val Loss: 0.5995, Accuracy: 67.73%\n",
      "Epoch [20/100], Loss: 0.6019, Val Loss: 0.5931, Accuracy: 68.44%\n",
      "Epoch [30/100], Loss: 0.6009, Val Loss: 0.5916, Accuracy: 68.44%\n",
      "Epoch [40/100], Loss: 0.5968, Val Loss: 0.5924, Accuracy: 68.12%\n",
      "Epoch [50/100], Loss: 0.5967, Val Loss: 0.5924, Accuracy: 68.25%\n",
      "Epoch [60/100], Loss: 0.5963, Val Loss: 0.5922, Accuracy: 68.31%\n",
      "Epoch [70/100], Loss: 0.5981, Val Loss: 0.5923, Accuracy: 68.18%\n",
      "Epoch [80/100], Loss: 0.5967, Val Loss: 0.5927, Accuracy: 68.18%\n",
      "Epoch [90/100], Loss: 0.5979, Val Loss: 0.5925, Accuracy: 68.31%\n",
      "Epoch [100/100], Loss: 0.5968, Val Loss: 0.5926, Accuracy: 68.12%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6095, Val Loss: 0.6050, Accuracy: 66.65%\n",
      "Epoch [20/100], Loss: 0.6011, Val Loss: 0.6053, Accuracy: 66.71%\n",
      "Epoch [30/100], Loss: 0.5941, Val Loss: 0.6029, Accuracy: 66.71%\n",
      "Epoch [40/100], Loss: 0.5974, Val Loss: 0.5998, Accuracy: 67.41%\n",
      "Epoch [50/100], Loss: 0.5950, Val Loss: 0.6008, Accuracy: 67.03%\n",
      "Epoch [60/100], Loss: 0.5947, Val Loss: 0.6008, Accuracy: 66.97%\n",
      "Epoch [70/100], Loss: 0.5966, Val Loss: 0.6003, Accuracy: 67.54%\n",
      "Epoch [80/100], Loss: 0.5885, Val Loss: 0.6008, Accuracy: 67.41%\n",
      "Epoch [90/100], Loss: 0.5938, Val Loss: 0.6005, Accuracy: 67.35%\n",
      "Epoch [100/100], Loss: 0.5929, Val Loss: 0.6008, Accuracy: 67.03%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6048, Val Loss: 0.6060, Accuracy: 65.09%\n",
      "Epoch [20/100], Loss: 0.6031, Val Loss: 0.6018, Accuracy: 65.79%\n",
      "Epoch [30/100], Loss: 0.5946, Val Loss: 0.5997, Accuracy: 65.66%\n",
      "Epoch [40/100], Loss: 0.5919, Val Loss: 0.6007, Accuracy: 66.11%\n",
      "Epoch [50/100], Loss: 0.5909, Val Loss: 0.6003, Accuracy: 65.79%\n",
      "Epoch [60/100], Loss: 0.5896, Val Loss: 0.5977, Accuracy: 66.05%\n",
      "Epoch [70/100], Loss: 0.5855, Val Loss: 0.5981, Accuracy: 66.43%\n",
      "Epoch [80/100], Loss: 0.5854, Val Loss: 0.5980, Accuracy: 65.98%\n",
      "Epoch [90/100], Loss: 0.5845, Val Loss: 0.5976, Accuracy: 66.11%\n",
      "Epoch [100/100], Loss: 0.5850, Val Loss: 0.5977, Accuracy: 66.30%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6113, Val Loss: 0.5951, Accuracy: 67.33%\n",
      "Epoch [20/100], Loss: 0.6031, Val Loss: 0.5929, Accuracy: 67.39%\n",
      "Epoch [30/100], Loss: 0.5996, Val Loss: 0.5938, Accuracy: 67.20%\n",
      "Epoch [40/100], Loss: 0.5958, Val Loss: 0.5946, Accuracy: 67.46%\n",
      "Epoch [50/100], Loss: 0.5960, Val Loss: 0.5941, Accuracy: 67.39%\n",
      "Epoch [60/100], Loss: 0.5951, Val Loss: 0.5943, Accuracy: 67.33%\n",
      "Epoch [70/100], Loss: 0.5982, Val Loss: 0.5942, Accuracy: 67.20%\n",
      "Epoch [80/100], Loss: 0.5965, Val Loss: 0.5942, Accuracy: 67.14%\n",
      "Epoch [90/100], Loss: 0.5933, Val Loss: 0.5942, Accuracy: 67.39%\n",
      "Epoch [100/100], Loss: 0.5961, Val Loss: 0.5940, Accuracy: 67.20%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6097, Val Loss: 0.5977, Accuracy: 67.58%\n",
      "Epoch [20/100], Loss: 0.5993, Val Loss: 0.5975, Accuracy: 67.39%\n",
      "Epoch [30/100], Loss: 0.5968, Val Loss: 0.5961, Accuracy: 67.46%\n",
      "Epoch [40/100], Loss: 0.5896, Val Loss: 0.5965, Accuracy: 67.20%\n",
      "Epoch [50/100], Loss: 0.5903, Val Loss: 0.5972, Accuracy: 67.20%\n",
      "Epoch [60/100], Loss: 0.5910, Val Loss: 0.5966, Accuracy: 67.07%\n",
      "Epoch [70/100], Loss: 0.5939, Val Loss: 0.5966, Accuracy: 67.01%\n",
      "Epoch [80/100], Loss: 0.5923, Val Loss: 0.5963, Accuracy: 67.01%\n",
      "Epoch [90/100], Loss: 0.5904, Val Loss: 0.5967, Accuracy: 67.01%\n",
      "Epoch [100/100], Loss: 0.5950, Val Loss: 0.5968, Accuracy: 66.94%\n",
      "Best cross-validated accuracy: 68.63%\n",
      "Epoch [10/100], Loss: 0.5963, Val Loss: 0.5768, Accuracy: 68.85%\n",
      "Epoch [20/100], Loss: 0.5947, Val Loss: 0.5753, Accuracy: 68.39%\n",
      "Epoch [30/100], Loss: 0.5931, Val Loss: 0.5769, Accuracy: 68.70%\n",
      "Epoch [40/100], Loss: 0.5892, Val Loss: 0.5748, Accuracy: 69.26%\n",
      "Epoch [50/100], Loss: 0.5890, Val Loss: 0.5751, Accuracy: 69.31%\n",
      "Epoch [60/100], Loss: 0.5933, Val Loss: 0.5756, Accuracy: 69.26%\n",
      "Epoch [70/100], Loss: 0.5905, Val Loss: 0.5745, Accuracy: 69.42%\n",
      "Epoch [80/100], Loss: 0.5867, Val Loss: 0.5751, Accuracy: 69.11%\n",
      "Epoch [90/100], Loss: 0.5873, Val Loss: 0.5754, Accuracy: 69.11%\n",
      "Epoch [100/100], Loss: 0.5894, Val Loss: 0.5748, Accuracy: 69.31%\n",
      "Final model accuracy on test set: 69.67%\n",
      "Accuracy 69.67% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6096, Val Loss: 0.6003, Accuracy: 67.41%\n",
      "Epoch [20/100], Loss: 0.6043, Val Loss: 0.5953, Accuracy: 68.25%\n",
      "Epoch [30/100], Loss: 0.6009, Val Loss: 0.5949, Accuracy: 68.44%\n",
      "Epoch [40/100], Loss: 0.5985, Val Loss: 0.5933, Accuracy: 67.29%\n",
      "Epoch [50/100], Loss: 0.5961, Val Loss: 0.5938, Accuracy: 67.67%\n",
      "Epoch [60/100], Loss: 0.5897, Val Loss: 0.5924, Accuracy: 68.12%\n",
      "Epoch [70/100], Loss: 0.5912, Val Loss: 0.5930, Accuracy: 67.93%\n",
      "Epoch [80/100], Loss: 0.5910, Val Loss: 0.5930, Accuracy: 67.80%\n",
      "Epoch [90/100], Loss: 0.5902, Val Loss: 0.5928, Accuracy: 67.99%\n",
      "Epoch [100/100], Loss: 0.5908, Val Loss: 0.5930, Accuracy: 67.99%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6136, Val Loss: 0.6041, Accuracy: 66.33%\n",
      "Epoch [20/100], Loss: 0.6018, Val Loss: 0.6023, Accuracy: 66.65%\n",
      "Epoch [30/100], Loss: 0.5990, Val Loss: 0.6016, Accuracy: 67.35%\n",
      "Epoch [40/100], Loss: 0.5954, Val Loss: 0.6020, Accuracy: 67.09%\n",
      "Epoch [50/100], Loss: 0.5941, Val Loss: 0.6022, Accuracy: 66.84%\n",
      "Epoch [60/100], Loss: 0.5958, Val Loss: 0.6019, Accuracy: 66.71%\n",
      "Epoch [70/100], Loss: 0.5957, Val Loss: 0.6019, Accuracy: 66.71%\n",
      "Epoch [80/100], Loss: 0.5939, Val Loss: 0.6026, Accuracy: 66.97%\n",
      "Epoch [90/100], Loss: 0.5941, Val Loss: 0.6023, Accuracy: 66.84%\n",
      "Epoch [100/100], Loss: 0.5959, Val Loss: 0.6023, Accuracy: 66.97%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6129, Val Loss: 0.6037, Accuracy: 66.18%\n",
      "Epoch [20/100], Loss: 0.6013, Val Loss: 0.5997, Accuracy: 66.43%\n",
      "Epoch [30/100], Loss: 0.5961, Val Loss: 0.5978, Accuracy: 66.05%\n",
      "Epoch [40/100], Loss: 0.5984, Val Loss: 0.5968, Accuracy: 66.43%\n",
      "Epoch [50/100], Loss: 0.5897, Val Loss: 0.5976, Accuracy: 66.69%\n",
      "Epoch [60/100], Loss: 0.5922, Val Loss: 0.5973, Accuracy: 66.30%\n",
      "Epoch [70/100], Loss: 0.5887, Val Loss: 0.5975, Accuracy: 66.50%\n",
      "Epoch [80/100], Loss: 0.5920, Val Loss: 0.5976, Accuracy: 66.56%\n",
      "Epoch [90/100], Loss: 0.5896, Val Loss: 0.5976, Accuracy: 66.56%\n",
      "Epoch [100/100], Loss: 0.5858, Val Loss: 0.5973, Accuracy: 66.30%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6087, Val Loss: 0.5985, Accuracy: 67.14%\n",
      "Epoch [20/100], Loss: 0.6050, Val Loss: 0.5954, Accuracy: 66.88%\n",
      "Epoch [30/100], Loss: 0.5995, Val Loss: 0.5953, Accuracy: 67.14%\n",
      "Epoch [40/100], Loss: 0.6005, Val Loss: 0.5953, Accuracy: 67.07%\n",
      "Epoch [50/100], Loss: 0.6019, Val Loss: 0.5954, Accuracy: 67.01%\n",
      "Epoch [60/100], Loss: 0.6017, Val Loss: 0.5955, Accuracy: 67.20%\n",
      "Epoch [70/100], Loss: 0.5991, Val Loss: 0.5950, Accuracy: 66.88%\n",
      "Epoch [80/100], Loss: 0.5971, Val Loss: 0.5953, Accuracy: 67.01%\n",
      "Epoch [90/100], Loss: 0.5968, Val Loss: 0.5952, Accuracy: 67.07%\n",
      "Epoch [100/100], Loss: 0.6003, Val Loss: 0.5953, Accuracy: 66.50%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6127, Val Loss: 0.6023, Accuracy: 67.33%\n",
      "Epoch [20/100], Loss: 0.6020, Val Loss: 0.5967, Accuracy: 67.39%\n",
      "Epoch [30/100], Loss: 0.5965, Val Loss: 0.5986, Accuracy: 67.91%\n",
      "Epoch [40/100], Loss: 0.5971, Val Loss: 0.5977, Accuracy: 67.91%\n",
      "Epoch [50/100], Loss: 0.5973, Val Loss: 0.5972, Accuracy: 67.65%\n",
      "Epoch [60/100], Loss: 0.5968, Val Loss: 0.5975, Accuracy: 68.10%\n",
      "Epoch [70/100], Loss: 0.5967, Val Loss: 0.5973, Accuracy: 67.65%\n",
      "Epoch [80/100], Loss: 0.5951, Val Loss: 0.5972, Accuracy: 67.78%\n",
      "Epoch [90/100], Loss: 0.5948, Val Loss: 0.5972, Accuracy: 67.78%\n",
      "Epoch [100/100], Loss: 0.5968, Val Loss: 0.5975, Accuracy: 67.84%\n",
      "Best cross-validated accuracy: 68.50%\n",
      "Epoch [10/100], Loss: 0.5971, Val Loss: 0.5791, Accuracy: 68.49%\n",
      "Epoch [20/100], Loss: 0.5933, Val Loss: 0.5763, Accuracy: 69.26%\n",
      "Epoch [30/100], Loss: 0.5918, Val Loss: 0.5742, Accuracy: 69.36%\n",
      "Epoch [40/100], Loss: 0.5913, Val Loss: 0.5804, Accuracy: 68.44%\n",
      "Epoch [50/100], Loss: 0.5883, Val Loss: 0.5753, Accuracy: 69.47%\n",
      "Epoch [60/100], Loss: 0.5882, Val Loss: 0.5746, Accuracy: 69.57%\n",
      "Epoch [70/100], Loss: 0.5889, Val Loss: 0.5755, Accuracy: 69.21%\n",
      "Epoch [80/100], Loss: 0.5864, Val Loss: 0.5751, Accuracy: 69.42%\n",
      "Epoch [90/100], Loss: 0.5887, Val Loss: 0.5747, Accuracy: 69.52%\n",
      "Epoch [100/100], Loss: 0.5893, Val Loss: 0.5746, Accuracy: 69.57%\n",
      "Final model accuracy on test set: 69.72%\n",
      "Accuracy 69.72% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6110, Val Loss: 0.5951, Accuracy: 68.12%\n",
      "Epoch [20/100], Loss: 0.6025, Val Loss: 0.5939, Accuracy: 68.37%\n",
      "Epoch [30/100], Loss: 0.5996, Val Loss: 0.5920, Accuracy: 68.25%\n",
      "Epoch [40/100], Loss: 0.5981, Val Loss: 0.5915, Accuracy: 68.50%\n",
      "Epoch [50/100], Loss: 0.5957, Val Loss: 0.5912, Accuracy: 67.80%\n",
      "Epoch [60/100], Loss: 0.5911, Val Loss: 0.5912, Accuracy: 68.31%\n",
      "Epoch [70/100], Loss: 0.5899, Val Loss: 0.5917, Accuracy: 67.99%\n",
      "Epoch [80/100], Loss: 0.5897, Val Loss: 0.5913, Accuracy: 68.05%\n",
      "Epoch [90/100], Loss: 0.5895, Val Loss: 0.5914, Accuracy: 68.05%\n",
      "Epoch [100/100], Loss: 0.5899, Val Loss: 0.5917, Accuracy: 68.05%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6074, Val Loss: 0.6085, Accuracy: 66.26%\n",
      "Epoch [20/100], Loss: 0.6017, Val Loss: 0.6024, Accuracy: 66.84%\n",
      "Epoch [30/100], Loss: 0.5969, Val Loss: 0.6021, Accuracy: 67.29%\n",
      "Epoch [40/100], Loss: 0.5891, Val Loss: 0.6009, Accuracy: 67.41%\n",
      "Epoch [50/100], Loss: 0.5900, Val Loss: 0.6023, Accuracy: 66.58%\n",
      "Epoch [60/100], Loss: 0.5892, Val Loss: 0.6030, Accuracy: 67.29%\n",
      "Epoch [70/100], Loss: 0.5875, Val Loss: 0.6033, Accuracy: 67.22%\n",
      "Epoch [80/100], Loss: 0.5876, Val Loss: 0.6022, Accuracy: 67.35%\n",
      "Epoch [90/100], Loss: 0.5858, Val Loss: 0.6022, Accuracy: 67.35%\n",
      "Epoch [100/100], Loss: 0.5887, Val Loss: 0.6026, Accuracy: 67.22%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6091, Val Loss: 0.6057, Accuracy: 65.92%\n",
      "Epoch [20/100], Loss: 0.6037, Val Loss: 0.6030, Accuracy: 66.18%\n",
      "Epoch [30/100], Loss: 0.5993, Val Loss: 0.6010, Accuracy: 65.86%\n",
      "Epoch [40/100], Loss: 0.5969, Val Loss: 0.6005, Accuracy: 66.05%\n",
      "Epoch [50/100], Loss: 0.5944, Val Loss: 0.6002, Accuracy: 66.69%\n",
      "Epoch [60/100], Loss: 0.5906, Val Loss: 0.5989, Accuracy: 65.92%\n",
      "Epoch [70/100], Loss: 0.5869, Val Loss: 0.5983, Accuracy: 66.30%\n",
      "Epoch [80/100], Loss: 0.5875, Val Loss: 0.5982, Accuracy: 66.24%\n",
      "Epoch [90/100], Loss: 0.5853, Val Loss: 0.5983, Accuracy: 66.24%\n",
      "Epoch [100/100], Loss: 0.5885, Val Loss: 0.5983, Accuracy: 66.75%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6109, Val Loss: 0.5983, Accuracy: 67.07%\n",
      "Epoch [20/100], Loss: 0.6028, Val Loss: 0.5940, Accuracy: 66.18%\n",
      "Epoch [30/100], Loss: 0.5992, Val Loss: 0.5956, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5961, Val Loss: 0.5935, Accuracy: 66.88%\n",
      "Epoch [50/100], Loss: 0.5917, Val Loss: 0.5944, Accuracy: 67.58%\n",
      "Epoch [60/100], Loss: 0.5916, Val Loss: 0.5944, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5900, Val Loss: 0.5944, Accuracy: 67.01%\n",
      "Epoch [80/100], Loss: 0.5887, Val Loss: 0.5943, Accuracy: 67.20%\n",
      "Epoch [90/100], Loss: 0.5903, Val Loss: 0.5944, Accuracy: 67.14%\n",
      "Epoch [100/100], Loss: 0.5939, Val Loss: 0.5944, Accuracy: 67.07%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6099, Val Loss: 0.5980, Accuracy: 67.26%\n",
      "Epoch [20/100], Loss: 0.5978, Val Loss: 0.5982, Accuracy: 67.20%\n",
      "Epoch [30/100], Loss: 0.5931, Val Loss: 0.5966, Accuracy: 67.91%\n",
      "Epoch [40/100], Loss: 0.5949, Val Loss: 0.5960, Accuracy: 67.84%\n",
      "Epoch [50/100], Loss: 0.5908, Val Loss: 0.5963, Accuracy: 67.52%\n",
      "Epoch [60/100], Loss: 0.5916, Val Loss: 0.5962, Accuracy: 67.52%\n",
      "Epoch [70/100], Loss: 0.5895, Val Loss: 0.5960, Accuracy: 67.84%\n",
      "Epoch [80/100], Loss: 0.5956, Val Loss: 0.5965, Accuracy: 67.58%\n",
      "Epoch [90/100], Loss: 0.5900, Val Loss: 0.5964, Accuracy: 67.26%\n",
      "Epoch [100/100], Loss: 0.5924, Val Loss: 0.5965, Accuracy: 67.65%\n",
      "Best cross-validated accuracy: 68.95%\n",
      "Epoch [10/100], Loss: 0.6028, Val Loss: 0.5834, Accuracy: 68.39%\n",
      "Epoch [20/100], Loss: 0.5966, Val Loss: 0.5772, Accuracy: 68.90%\n",
      "Epoch [30/100], Loss: 0.5944, Val Loss: 0.5748, Accuracy: 69.11%\n",
      "Epoch [40/100], Loss: 0.5920, Val Loss: 0.5776, Accuracy: 69.36%\n",
      "Epoch [50/100], Loss: 0.5913, Val Loss: 0.5772, Accuracy: 69.16%\n",
      "Epoch [60/100], Loss: 0.5881, Val Loss: 0.5751, Accuracy: 69.16%\n",
      "Epoch [70/100], Loss: 0.5864, Val Loss: 0.5757, Accuracy: 68.95%\n",
      "Epoch [80/100], Loss: 0.5869, Val Loss: 0.5746, Accuracy: 69.26%\n",
      "Epoch [90/100], Loss: 0.5861, Val Loss: 0.5748, Accuracy: 69.31%\n",
      "Epoch [100/100], Loss: 0.5850, Val Loss: 0.5748, Accuracy: 69.21%\n",
      "Final model accuracy on test set: 69.52%\n",
      "Accuracy 69.52% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6131, Val Loss: 0.5987, Accuracy: 67.80%\n",
      "Epoch [20/100], Loss: 0.6029, Val Loss: 0.5941, Accuracy: 67.99%\n",
      "Epoch [30/100], Loss: 0.5989, Val Loss: 0.5929, Accuracy: 67.99%\n",
      "Epoch [40/100], Loss: 0.5961, Val Loss: 0.5927, Accuracy: 68.12%\n",
      "Epoch [50/100], Loss: 0.5981, Val Loss: 0.5925, Accuracy: 68.05%\n",
      "Epoch [60/100], Loss: 0.5977, Val Loss: 0.5932, Accuracy: 67.99%\n",
      "Epoch [70/100], Loss: 0.5968, Val Loss: 0.5929, Accuracy: 68.12%\n",
      "Epoch [80/100], Loss: 0.5966, Val Loss: 0.5927, Accuracy: 67.99%\n",
      "Epoch [90/100], Loss: 0.5933, Val Loss: 0.5926, Accuracy: 68.05%\n",
      "Epoch [100/100], Loss: 0.5968, Val Loss: 0.5931, Accuracy: 67.80%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6121, Val Loss: 0.6059, Accuracy: 66.65%\n",
      "Epoch [20/100], Loss: 0.6042, Val Loss: 0.6021, Accuracy: 67.16%\n",
      "Epoch [30/100], Loss: 0.5980, Val Loss: 0.6021, Accuracy: 66.65%\n",
      "Epoch [40/100], Loss: 0.5928, Val Loss: 0.6003, Accuracy: 66.84%\n",
      "Epoch [50/100], Loss: 0.5918, Val Loss: 0.6015, Accuracy: 67.09%\n",
      "Epoch [60/100], Loss: 0.5927, Val Loss: 0.6014, Accuracy: 67.09%\n",
      "Epoch [70/100], Loss: 0.5944, Val Loss: 0.6016, Accuracy: 66.71%\n",
      "Epoch [80/100], Loss: 0.5915, Val Loss: 0.6007, Accuracy: 67.16%\n",
      "Epoch [90/100], Loss: 0.5935, Val Loss: 0.6019, Accuracy: 66.65%\n",
      "Epoch [100/100], Loss: 0.5917, Val Loss: 0.6015, Accuracy: 66.58%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6103, Val Loss: 0.6054, Accuracy: 66.43%\n",
      "Epoch [20/100], Loss: 0.6033, Val Loss: 0.5996, Accuracy: 66.56%\n",
      "Epoch [30/100], Loss: 0.5967, Val Loss: 0.5995, Accuracy: 66.30%\n",
      "Epoch [40/100], Loss: 0.5932, Val Loss: 0.5992, Accuracy: 66.05%\n",
      "Epoch [50/100], Loss: 0.5902, Val Loss: 0.5975, Accuracy: 65.73%\n",
      "Epoch [60/100], Loss: 0.5902, Val Loss: 0.5981, Accuracy: 66.30%\n",
      "Epoch [70/100], Loss: 0.5882, Val Loss: 0.5978, Accuracy: 66.11%\n",
      "Epoch [80/100], Loss: 0.5908, Val Loss: 0.5980, Accuracy: 66.05%\n",
      "Epoch [90/100], Loss: 0.5907, Val Loss: 0.5977, Accuracy: 65.98%\n",
      "Epoch [100/100], Loss: 0.5955, Val Loss: 0.5980, Accuracy: 66.18%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6064, Val Loss: 0.5950, Accuracy: 66.88%\n",
      "Epoch [20/100], Loss: 0.6007, Val Loss: 0.5945, Accuracy: 66.30%\n",
      "Epoch [30/100], Loss: 0.6029, Val Loss: 0.5946, Accuracy: 66.75%\n",
      "Epoch [40/100], Loss: 0.6017, Val Loss: 0.5944, Accuracy: 66.69%\n",
      "Epoch [50/100], Loss: 0.6024, Val Loss: 0.5949, Accuracy: 67.07%\n",
      "Epoch [60/100], Loss: 0.5993, Val Loss: 0.5946, Accuracy: 66.37%\n",
      "Epoch [70/100], Loss: 0.5992, Val Loss: 0.5946, Accuracy: 66.56%\n",
      "Epoch [80/100], Loss: 0.5967, Val Loss: 0.5946, Accuracy: 66.11%\n",
      "Epoch [90/100], Loss: 0.5990, Val Loss: 0.5945, Accuracy: 66.30%\n",
      "Epoch [100/100], Loss: 0.6024, Val Loss: 0.5947, Accuracy: 66.69%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6117, Val Loss: 0.5998, Accuracy: 67.58%\n",
      "Epoch [20/100], Loss: 0.6013, Val Loss: 0.5984, Accuracy: 67.33%\n",
      "Epoch [30/100], Loss: 0.5980, Val Loss: 0.5973, Accuracy: 68.10%\n",
      "Epoch [40/100], Loss: 0.5912, Val Loss: 0.5960, Accuracy: 67.65%\n",
      "Epoch [50/100], Loss: 0.5912, Val Loss: 0.5959, Accuracy: 67.58%\n",
      "Epoch [60/100], Loss: 0.5926, Val Loss: 0.5967, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5903, Val Loss: 0.5958, Accuracy: 67.71%\n",
      "Epoch [80/100], Loss: 0.5909, Val Loss: 0.5971, Accuracy: 67.01%\n",
      "Epoch [90/100], Loss: 0.5915, Val Loss: 0.5960, Accuracy: 67.46%\n",
      "Epoch [100/100], Loss: 0.5912, Val Loss: 0.5960, Accuracy: 67.65%\n",
      "Best cross-validated accuracy: 68.61%\n",
      "Epoch [10/100], Loss: 0.6009, Val Loss: 0.5761, Accuracy: 69.21%\n",
      "Epoch [20/100], Loss: 0.5940, Val Loss: 0.5755, Accuracy: 69.21%\n",
      "Epoch [30/100], Loss: 0.5939, Val Loss: 0.5773, Accuracy: 68.75%\n",
      "Epoch [40/100], Loss: 0.5921, Val Loss: 0.5775, Accuracy: 69.52%\n",
      "Epoch [50/100], Loss: 0.5884, Val Loss: 0.5754, Accuracy: 69.26%\n",
      "Epoch [60/100], Loss: 0.5867, Val Loss: 0.5753, Accuracy: 69.16%\n",
      "Epoch [70/100], Loss: 0.5888, Val Loss: 0.5760, Accuracy: 68.90%\n",
      "Epoch [80/100], Loss: 0.5889, Val Loss: 0.5754, Accuracy: 69.16%\n",
      "Epoch [90/100], Loss: 0.5892, Val Loss: 0.5758, Accuracy: 69.11%\n",
      "Epoch [100/100], Loss: 0.5849, Val Loss: 0.5754, Accuracy: 69.31%\n",
      "Final model accuracy on test set: 69.88%\n",
      "Accuracy 69.88% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6096, Val Loss: 0.5964, Accuracy: 67.73%\n",
      "Epoch [20/100], Loss: 0.6016, Val Loss: 0.5950, Accuracy: 68.05%\n",
      "Epoch [30/100], Loss: 0.6001, Val Loss: 0.5933, Accuracy: 68.25%\n",
      "Epoch [40/100], Loss: 0.5955, Val Loss: 0.5933, Accuracy: 67.86%\n",
      "Epoch [50/100], Loss: 0.5924, Val Loss: 0.5911, Accuracy: 68.05%\n",
      "Epoch [60/100], Loss: 0.5950, Val Loss: 0.5946, Accuracy: 67.16%\n",
      "Epoch [70/100], Loss: 0.5869, Val Loss: 0.5915, Accuracy: 67.41%\n",
      "Epoch [80/100], Loss: 0.5868, Val Loss: 0.5919, Accuracy: 67.29%\n",
      "Epoch [90/100], Loss: 0.5906, Val Loss: 0.5914, Accuracy: 67.41%\n",
      "Epoch [100/100], Loss: 0.5877, Val Loss: 0.5914, Accuracy: 67.35%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6108, Val Loss: 0.6054, Accuracy: 66.07%\n",
      "Epoch [20/100], Loss: 0.6019, Val Loss: 0.6028, Accuracy: 66.71%\n",
      "Epoch [30/100], Loss: 0.5973, Val Loss: 0.6022, Accuracy: 66.97%\n",
      "Epoch [40/100], Loss: 0.5922, Val Loss: 0.6018, Accuracy: 66.97%\n",
      "Epoch [50/100], Loss: 0.5861, Val Loss: 0.6022, Accuracy: 67.22%\n",
      "Epoch [60/100], Loss: 0.5889, Val Loss: 0.6016, Accuracy: 66.84%\n",
      "Epoch [70/100], Loss: 0.5874, Val Loss: 0.6014, Accuracy: 67.09%\n",
      "Epoch [80/100], Loss: 0.5883, Val Loss: 0.6017, Accuracy: 66.90%\n",
      "Epoch [90/100], Loss: 0.5920, Val Loss: 0.6019, Accuracy: 66.97%\n",
      "Epoch [100/100], Loss: 0.5860, Val Loss: 0.6017, Accuracy: 66.97%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6108, Val Loss: 0.6085, Accuracy: 65.66%\n",
      "Epoch [20/100], Loss: 0.6017, Val Loss: 0.6060, Accuracy: 66.05%\n",
      "Epoch [30/100], Loss: 0.5924, Val Loss: 0.6018, Accuracy: 65.73%\n",
      "Epoch [40/100], Loss: 0.5916, Val Loss: 0.6005, Accuracy: 66.24%\n",
      "Epoch [50/100], Loss: 0.5962, Val Loss: 0.6025, Accuracy: 65.60%\n",
      "Epoch [60/100], Loss: 0.5916, Val Loss: 0.6007, Accuracy: 66.05%\n",
      "Epoch [70/100], Loss: 0.5875, Val Loss: 0.6015, Accuracy: 65.79%\n",
      "Epoch [80/100], Loss: 0.5891, Val Loss: 0.5997, Accuracy: 66.11%\n",
      "Epoch [90/100], Loss: 0.5859, Val Loss: 0.5997, Accuracy: 66.11%\n",
      "Epoch [100/100], Loss: 0.5861, Val Loss: 0.5998, Accuracy: 66.30%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6141, Val Loss: 0.5973, Accuracy: 67.20%\n",
      "Epoch [20/100], Loss: 0.6086, Val Loss: 0.5950, Accuracy: 66.94%\n",
      "Epoch [30/100], Loss: 0.5998, Val Loss: 0.5944, Accuracy: 66.88%\n",
      "Epoch [40/100], Loss: 0.5930, Val Loss: 0.5949, Accuracy: 67.65%\n",
      "Epoch [50/100], Loss: 0.5969, Val Loss: 0.5944, Accuracy: 67.39%\n",
      "Epoch [60/100], Loss: 0.5961, Val Loss: 0.5946, Accuracy: 67.39%\n",
      "Epoch [70/100], Loss: 0.5930, Val Loss: 0.5946, Accuracy: 67.52%\n",
      "Epoch [80/100], Loss: 0.5956, Val Loss: 0.5946, Accuracy: 67.07%\n",
      "Epoch [90/100], Loss: 0.5927, Val Loss: 0.5945, Accuracy: 67.39%\n",
      "Epoch [100/100], Loss: 0.5933, Val Loss: 0.5947, Accuracy: 67.65%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6050, Val Loss: 0.6006, Accuracy: 67.97%\n",
      "Epoch [20/100], Loss: 0.6003, Val Loss: 0.5981, Accuracy: 67.97%\n",
      "Epoch [30/100], Loss: 0.5979, Val Loss: 0.5963, Accuracy: 67.52%\n",
      "Epoch [40/100], Loss: 0.5903, Val Loss: 0.5958, Accuracy: 67.20%\n",
      "Epoch [50/100], Loss: 0.5940, Val Loss: 0.5960, Accuracy: 67.07%\n",
      "Epoch [60/100], Loss: 0.5925, Val Loss: 0.5962, Accuracy: 67.20%\n",
      "Epoch [70/100], Loss: 0.5923, Val Loss: 0.5964, Accuracy: 67.07%\n",
      "Epoch [80/100], Loss: 0.5931, Val Loss: 0.5963, Accuracy: 67.20%\n",
      "Epoch [90/100], Loss: 0.5901, Val Loss: 0.5960, Accuracy: 67.52%\n",
      "Epoch [100/100], Loss: 0.5924, Val Loss: 0.5959, Accuracy: 67.39%\n",
      "Best cross-validated accuracy: 68.50%\n",
      "Epoch [10/100], Loss: 0.5960, Val Loss: 0.5751, Accuracy: 68.55%\n",
      "Epoch [20/100], Loss: 0.5931, Val Loss: 0.5747, Accuracy: 69.72%\n",
      "Epoch [30/100], Loss: 0.5890, Val Loss: 0.5755, Accuracy: 69.31%\n",
      "Epoch [40/100], Loss: 0.5883, Val Loss: 0.5750, Accuracy: 69.11%\n",
      "Epoch [50/100], Loss: 0.5872, Val Loss: 0.5758, Accuracy: 69.06%\n",
      "Epoch [60/100], Loss: 0.5899, Val Loss: 0.5756, Accuracy: 69.01%\n",
      "Epoch [70/100], Loss: 0.5867, Val Loss: 0.5754, Accuracy: 69.11%\n",
      "Epoch [80/100], Loss: 0.5900, Val Loss: 0.5749, Accuracy: 69.16%\n",
      "Epoch [90/100], Loss: 0.5898, Val Loss: 0.5750, Accuracy: 69.21%\n",
      "Epoch [100/100], Loss: 0.5890, Val Loss: 0.5758, Accuracy: 69.11%\n",
      "Final model accuracy on test set: 69.72%\n",
      "Accuracy 69.72% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6056, Val Loss: 0.5973, Accuracy: 67.61%\n",
      "Epoch [20/100], Loss: 0.6045, Val Loss: 0.5949, Accuracy: 67.61%\n",
      "Epoch [30/100], Loss: 0.5999, Val Loss: 0.5925, Accuracy: 67.93%\n",
      "Epoch [40/100], Loss: 0.5944, Val Loss: 0.5923, Accuracy: 67.86%\n",
      "Epoch [50/100], Loss: 0.5957, Val Loss: 0.5923, Accuracy: 68.05%\n",
      "Epoch [60/100], Loss: 0.5956, Val Loss: 0.5923, Accuracy: 68.05%\n",
      "Epoch [70/100], Loss: 0.5944, Val Loss: 0.5922, Accuracy: 67.86%\n",
      "Epoch [80/100], Loss: 0.5928, Val Loss: 0.5922, Accuracy: 67.73%\n",
      "Epoch [90/100], Loss: 0.5942, Val Loss: 0.5920, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5962, Val Loss: 0.5928, Accuracy: 67.67%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6095, Val Loss: 0.6070, Accuracy: 66.39%\n",
      "Epoch [20/100], Loss: 0.6007, Val Loss: 0.6042, Accuracy: 66.84%\n",
      "Epoch [30/100], Loss: 0.5970, Val Loss: 0.6020, Accuracy: 66.90%\n",
      "Epoch [40/100], Loss: 0.5940, Val Loss: 0.6030, Accuracy: 67.22%\n",
      "Epoch [50/100], Loss: 0.5903, Val Loss: 0.6019, Accuracy: 67.54%\n",
      "Epoch [60/100], Loss: 0.5885, Val Loss: 0.6016, Accuracy: 67.67%\n",
      "Epoch [70/100], Loss: 0.5894, Val Loss: 0.6018, Accuracy: 67.93%\n",
      "Epoch [80/100], Loss: 0.5903, Val Loss: 0.6019, Accuracy: 67.86%\n",
      "Epoch [90/100], Loss: 0.5883, Val Loss: 0.6017, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5908, Val Loss: 0.6019, Accuracy: 67.80%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6070, Val Loss: 0.6068, Accuracy: 65.86%\n",
      "Epoch [20/100], Loss: 0.6003, Val Loss: 0.6022, Accuracy: 65.79%\n",
      "Epoch [30/100], Loss: 0.5962, Val Loss: 0.6017, Accuracy: 66.30%\n",
      "Epoch [40/100], Loss: 0.5952, Val Loss: 0.5994, Accuracy: 65.79%\n",
      "Epoch [50/100], Loss: 0.5912, Val Loss: 0.6000, Accuracy: 66.24%\n",
      "Epoch [60/100], Loss: 0.5888, Val Loss: 0.5995, Accuracy: 66.37%\n",
      "Epoch [70/100], Loss: 0.5900, Val Loss: 0.5998, Accuracy: 66.11%\n",
      "Epoch [80/100], Loss: 0.5856, Val Loss: 0.5998, Accuracy: 66.37%\n",
      "Epoch [90/100], Loss: 0.5888, Val Loss: 0.5997, Accuracy: 66.24%\n",
      "Epoch [100/100], Loss: 0.5882, Val Loss: 0.5995, Accuracy: 66.18%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6126, Val Loss: 0.5984, Accuracy: 67.65%\n",
      "Epoch [20/100], Loss: 0.6053, Val Loss: 0.5956, Accuracy: 66.75%\n",
      "Epoch [30/100], Loss: 0.6017, Val Loss: 0.5951, Accuracy: 66.94%\n",
      "Epoch [40/100], Loss: 0.5963, Val Loss: 0.5946, Accuracy: 67.33%\n",
      "Epoch [50/100], Loss: 0.6000, Val Loss: 0.5944, Accuracy: 67.20%\n",
      "Epoch [60/100], Loss: 0.5966, Val Loss: 0.5946, Accuracy: 67.33%\n",
      "Epoch [70/100], Loss: 0.6002, Val Loss: 0.5949, Accuracy: 67.20%\n",
      "Epoch [80/100], Loss: 0.6003, Val Loss: 0.5950, Accuracy: 66.24%\n",
      "Epoch [90/100], Loss: 0.5948, Val Loss: 0.5946, Accuracy: 67.20%\n",
      "Epoch [100/100], Loss: 0.5974, Val Loss: 0.5948, Accuracy: 66.56%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6124, Val Loss: 0.6031, Accuracy: 67.26%\n",
      "Epoch [20/100], Loss: 0.6047, Val Loss: 0.5982, Accuracy: 67.33%\n",
      "Epoch [30/100], Loss: 0.5973, Val Loss: 0.5980, Accuracy: 68.29%\n",
      "Epoch [40/100], Loss: 0.5943, Val Loss: 0.5979, Accuracy: 67.07%\n",
      "Epoch [50/100], Loss: 0.5895, Val Loss: 0.5975, Accuracy: 67.33%\n",
      "Epoch [60/100], Loss: 0.5891, Val Loss: 0.5980, Accuracy: 66.69%\n",
      "Epoch [70/100], Loss: 0.5894, Val Loss: 0.5977, Accuracy: 66.75%\n",
      "Epoch [80/100], Loss: 0.5881, Val Loss: 0.5982, Accuracy: 66.69%\n",
      "Epoch [90/100], Loss: 0.5909, Val Loss: 0.5982, Accuracy: 66.62%\n",
      "Epoch [100/100], Loss: 0.5904, Val Loss: 0.5978, Accuracy: 66.69%\n",
      "Best cross-validated accuracy: 68.48%\n",
      "Epoch [10/100], Loss: 0.6012, Val Loss: 0.5775, Accuracy: 68.49%\n",
      "Epoch [20/100], Loss: 0.6001, Val Loss: 0.5776, Accuracy: 69.36%\n",
      "Epoch [30/100], Loss: 0.5933, Val Loss: 0.5765, Accuracy: 69.01%\n",
      "Epoch [40/100], Loss: 0.5926, Val Loss: 0.5754, Accuracy: 69.16%\n",
      "Epoch [50/100], Loss: 0.5951, Val Loss: 0.5764, Accuracy: 69.06%\n",
      "Epoch [60/100], Loss: 0.5928, Val Loss: 0.5757, Accuracy: 69.26%\n",
      "Epoch [70/100], Loss: 0.5922, Val Loss: 0.5757, Accuracy: 69.16%\n",
      "Epoch [80/100], Loss: 0.5927, Val Loss: 0.5767, Accuracy: 68.90%\n",
      "Epoch [90/100], Loss: 0.5922, Val Loss: 0.5757, Accuracy: 68.95%\n",
      "Epoch [100/100], Loss: 0.5943, Val Loss: 0.5758, Accuracy: 69.06%\n",
      "Final model accuracy on test set: 69.62%\n",
      "Accuracy 69.62% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6100, Val Loss: 0.5987, Accuracy: 67.16%\n",
      "Epoch [20/100], Loss: 0.6066, Val Loss: 0.5957, Accuracy: 67.67%\n",
      "Epoch [30/100], Loss: 0.6011, Val Loss: 0.5995, Accuracy: 67.73%\n",
      "Epoch [40/100], Loss: 0.5945, Val Loss: 0.5935, Accuracy: 68.18%\n",
      "Epoch [50/100], Loss: 0.5964, Val Loss: 0.5928, Accuracy: 67.93%\n",
      "Epoch [60/100], Loss: 0.5957, Val Loss: 0.5920, Accuracy: 67.93%\n",
      "Epoch [70/100], Loss: 0.5966, Val Loss: 0.5919, Accuracy: 68.18%\n",
      "Epoch [80/100], Loss: 0.5953, Val Loss: 0.5917, Accuracy: 68.05%\n",
      "Epoch [90/100], Loss: 0.5953, Val Loss: 0.5921, Accuracy: 68.05%\n",
      "Epoch [100/100], Loss: 0.5907, Val Loss: 0.5917, Accuracy: 67.93%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6086, Val Loss: 0.6050, Accuracy: 66.65%\n",
      "Epoch [20/100], Loss: 0.6007, Val Loss: 0.6002, Accuracy: 66.77%\n",
      "Epoch [30/100], Loss: 0.5959, Val Loss: 0.6015, Accuracy: 67.54%\n",
      "Epoch [40/100], Loss: 0.5932, Val Loss: 0.6007, Accuracy: 66.97%\n",
      "Epoch [50/100], Loss: 0.5910, Val Loss: 0.6007, Accuracy: 67.09%\n",
      "Epoch [60/100], Loss: 0.5908, Val Loss: 0.6005, Accuracy: 67.22%\n",
      "Epoch [70/100], Loss: 0.5924, Val Loss: 0.6002, Accuracy: 67.16%\n",
      "Epoch [80/100], Loss: 0.5921, Val Loss: 0.6002, Accuracy: 67.22%\n",
      "Epoch [90/100], Loss: 0.5924, Val Loss: 0.5997, Accuracy: 67.41%\n",
      "Epoch [100/100], Loss: 0.5948, Val Loss: 0.6007, Accuracy: 67.09%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6119, Val Loss: 0.6060, Accuracy: 65.34%\n",
      "Epoch [20/100], Loss: 0.6045, Val Loss: 0.6016, Accuracy: 66.18%\n",
      "Epoch [30/100], Loss: 0.5958, Val Loss: 0.6003, Accuracy: 66.37%\n",
      "Epoch [40/100], Loss: 0.5959, Val Loss: 0.5998, Accuracy: 66.11%\n",
      "Epoch [50/100], Loss: 0.5894, Val Loss: 0.5986, Accuracy: 66.05%\n",
      "Epoch [60/100], Loss: 0.5936, Val Loss: 0.5989, Accuracy: 66.37%\n",
      "Epoch [70/100], Loss: 0.5927, Val Loss: 0.5988, Accuracy: 66.11%\n",
      "Epoch [80/100], Loss: 0.5945, Val Loss: 0.5993, Accuracy: 65.98%\n",
      "Epoch [90/100], Loss: 0.5937, Val Loss: 0.5987, Accuracy: 66.11%\n",
      "Epoch [100/100], Loss: 0.5945, Val Loss: 0.5984, Accuracy: 66.37%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6054, Val Loss: 0.5961, Accuracy: 66.50%\n",
      "Epoch [20/100], Loss: 0.6007, Val Loss: 0.5959, Accuracy: 66.88%\n",
      "Epoch [30/100], Loss: 0.5965, Val Loss: 0.5949, Accuracy: 67.07%\n",
      "Epoch [40/100], Loss: 0.6000, Val Loss: 0.5949, Accuracy: 66.82%\n",
      "Epoch [50/100], Loss: 0.5959, Val Loss: 0.5948, Accuracy: 66.88%\n",
      "Epoch [60/100], Loss: 0.5960, Val Loss: 0.5949, Accuracy: 66.88%\n",
      "Epoch [70/100], Loss: 0.5992, Val Loss: 0.5951, Accuracy: 66.94%\n",
      "Epoch [80/100], Loss: 0.5960, Val Loss: 0.5951, Accuracy: 66.75%\n",
      "Epoch [90/100], Loss: 0.5932, Val Loss: 0.5949, Accuracy: 66.69%\n",
      "Epoch [100/100], Loss: 0.6006, Val Loss: 0.5955, Accuracy: 66.94%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6109, Val Loss: 0.5997, Accuracy: 67.52%\n",
      "Epoch [20/100], Loss: 0.6004, Val Loss: 0.5981, Accuracy: 68.10%\n",
      "Epoch [30/100], Loss: 0.5974, Val Loss: 0.5971, Accuracy: 67.14%\n",
      "Epoch [40/100], Loss: 0.5922, Val Loss: 0.5978, Accuracy: 67.14%\n",
      "Epoch [50/100], Loss: 0.5954, Val Loss: 0.5980, Accuracy: 66.94%\n",
      "Epoch [60/100], Loss: 0.5913, Val Loss: 0.5984, Accuracy: 66.69%\n",
      "Epoch [70/100], Loss: 0.5897, Val Loss: 0.5975, Accuracy: 66.75%\n",
      "Epoch [80/100], Loss: 0.5963, Val Loss: 0.5975, Accuracy: 67.07%\n",
      "Epoch [90/100], Loss: 0.5919, Val Loss: 0.5981, Accuracy: 66.88%\n",
      "Epoch [100/100], Loss: 0.5922, Val Loss: 0.5981, Accuracy: 66.62%\n",
      "Best cross-validated accuracy: 68.31%\n",
      "Epoch [10/100], Loss: 0.5958, Val Loss: 0.5765, Accuracy: 68.70%\n",
      "Epoch [20/100], Loss: 0.5926, Val Loss: 0.5734, Accuracy: 69.21%\n",
      "Epoch [30/100], Loss: 0.5919, Val Loss: 0.5763, Accuracy: 69.01%\n",
      "Epoch [40/100], Loss: 0.5867, Val Loss: 0.5752, Accuracy: 69.16%\n",
      "Epoch [50/100], Loss: 0.5865, Val Loss: 0.5751, Accuracy: 68.80%\n",
      "Epoch [60/100], Loss: 0.5884, Val Loss: 0.5754, Accuracy: 68.90%\n",
      "Epoch [70/100], Loss: 0.5868, Val Loss: 0.5751, Accuracy: 68.80%\n",
      "Epoch [80/100], Loss: 0.5877, Val Loss: 0.5752, Accuracy: 68.70%\n",
      "Epoch [90/100], Loss: 0.5847, Val Loss: 0.5754, Accuracy: 69.16%\n",
      "Epoch [100/100], Loss: 0.5864, Val Loss: 0.5747, Accuracy: 68.95%\n",
      "Final model accuracy on test set: 69.47%\n",
      "Accuracy 69.47% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6100, Val Loss: 0.6025, Accuracy: 67.67%\n",
      "Epoch [20/100], Loss: 0.6023, Val Loss: 0.5967, Accuracy: 67.93%\n",
      "Epoch [30/100], Loss: 0.6007, Val Loss: 0.5955, Accuracy: 68.12%\n",
      "Epoch [40/100], Loss: 0.5977, Val Loss: 0.5919, Accuracy: 68.50%\n",
      "Epoch [50/100], Loss: 0.5927, Val Loss: 0.5931, Accuracy: 67.73%\n",
      "Epoch [60/100], Loss: 0.5937, Val Loss: 0.5923, Accuracy: 67.73%\n",
      "Epoch [70/100], Loss: 0.5939, Val Loss: 0.5925, Accuracy: 67.80%\n",
      "Epoch [80/100], Loss: 0.5889, Val Loss: 0.5925, Accuracy: 67.67%\n",
      "Epoch [90/100], Loss: 0.5903, Val Loss: 0.5921, Accuracy: 67.67%\n",
      "Epoch [100/100], Loss: 0.5917, Val Loss: 0.5923, Accuracy: 67.93%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6091, Val Loss: 0.6065, Accuracy: 66.33%\n",
      "Epoch [20/100], Loss: 0.6049, Val Loss: 0.6031, Accuracy: 67.09%\n",
      "Epoch [30/100], Loss: 0.5963, Val Loss: 0.6041, Accuracy: 67.09%\n",
      "Epoch [40/100], Loss: 0.5941, Val Loss: 0.6023, Accuracy: 67.09%\n",
      "Epoch [50/100], Loss: 0.5961, Val Loss: 0.6023, Accuracy: 66.90%\n",
      "Epoch [60/100], Loss: 0.5925, Val Loss: 0.6024, Accuracy: 66.90%\n",
      "Epoch [70/100], Loss: 0.5945, Val Loss: 0.6027, Accuracy: 66.90%\n",
      "Epoch [80/100], Loss: 0.5938, Val Loss: 0.6017, Accuracy: 66.84%\n",
      "Epoch [90/100], Loss: 0.5945, Val Loss: 0.6019, Accuracy: 67.09%\n",
      "Epoch [100/100], Loss: 0.5927, Val Loss: 0.6023, Accuracy: 67.03%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6122, Val Loss: 0.6071, Accuracy: 66.05%\n",
      "Epoch [20/100], Loss: 0.6041, Val Loss: 0.6021, Accuracy: 66.75%\n",
      "Epoch [30/100], Loss: 0.5996, Val Loss: 0.5994, Accuracy: 66.18%\n",
      "Epoch [40/100], Loss: 0.5970, Val Loss: 0.5992, Accuracy: 66.37%\n",
      "Epoch [50/100], Loss: 0.5948, Val Loss: 0.5993, Accuracy: 66.50%\n",
      "Epoch [60/100], Loss: 0.5926, Val Loss: 0.5982, Accuracy: 66.82%\n",
      "Epoch [70/100], Loss: 0.5852, Val Loss: 0.5997, Accuracy: 67.14%\n",
      "Epoch [80/100], Loss: 0.5903, Val Loss: 0.5980, Accuracy: 66.50%\n",
      "Epoch [90/100], Loss: 0.5869, Val Loss: 0.5982, Accuracy: 66.69%\n",
      "Epoch [100/100], Loss: 0.5864, Val Loss: 0.5979, Accuracy: 66.30%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6129, Val Loss: 0.5967, Accuracy: 67.33%\n",
      "Epoch [20/100], Loss: 0.6056, Val Loss: 0.5936, Accuracy: 66.43%\n",
      "Epoch [30/100], Loss: 0.5983, Val Loss: 0.5947, Accuracy: 67.52%\n",
      "Epoch [40/100], Loss: 0.5960, Val Loss: 0.5942, Accuracy: 67.14%\n",
      "Epoch [50/100], Loss: 0.5939, Val Loss: 0.5945, Accuracy: 67.14%\n",
      "Epoch [60/100], Loss: 0.5948, Val Loss: 0.5944, Accuracy: 66.82%\n",
      "Epoch [70/100], Loss: 0.5941, Val Loss: 0.5944, Accuracy: 66.94%\n",
      "Epoch [80/100], Loss: 0.5963, Val Loss: 0.5942, Accuracy: 66.75%\n",
      "Epoch [90/100], Loss: 0.5950, Val Loss: 0.5942, Accuracy: 66.69%\n",
      "Epoch [100/100], Loss: 0.5934, Val Loss: 0.5945, Accuracy: 66.69%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6124, Val Loss: 0.6008, Accuracy: 67.46%\n",
      "Epoch [20/100], Loss: 0.6020, Val Loss: 0.5992, Accuracy: 67.78%\n",
      "Epoch [30/100], Loss: 0.5966, Val Loss: 0.5960, Accuracy: 67.01%\n",
      "Epoch [40/100], Loss: 0.5960, Val Loss: 0.5988, Accuracy: 67.52%\n",
      "Epoch [50/100], Loss: 0.5928, Val Loss: 0.5961, Accuracy: 67.65%\n",
      "Epoch [60/100], Loss: 0.5888, Val Loss: 0.5960, Accuracy: 67.39%\n",
      "Epoch [70/100], Loss: 0.5909, Val Loss: 0.5959, Accuracy: 67.26%\n",
      "Epoch [80/100], Loss: 0.5924, Val Loss: 0.5957, Accuracy: 67.20%\n",
      "Epoch [90/100], Loss: 0.5907, Val Loss: 0.5962, Accuracy: 67.26%\n",
      "Epoch [100/100], Loss: 0.5931, Val Loss: 0.5956, Accuracy: 67.46%\n",
      "Best cross-validated accuracy: 68.57%\n",
      "Epoch [10/100], Loss: 0.6034, Val Loss: 0.5769, Accuracy: 68.85%\n",
      "Epoch [20/100], Loss: 0.5976, Val Loss: 0.5762, Accuracy: 68.90%\n",
      "Epoch [30/100], Loss: 0.5970, Val Loss: 0.5753, Accuracy: 69.26%\n",
      "Epoch [40/100], Loss: 0.5948, Val Loss: 0.5756, Accuracy: 69.11%\n",
      "Epoch [50/100], Loss: 0.5982, Val Loss: 0.5755, Accuracy: 69.26%\n",
      "Epoch [60/100], Loss: 0.5956, Val Loss: 0.5754, Accuracy: 69.16%\n",
      "Epoch [70/100], Loss: 0.5961, Val Loss: 0.5751, Accuracy: 69.42%\n",
      "Epoch [80/100], Loss: 0.5958, Val Loss: 0.5754, Accuracy: 69.16%\n",
      "Epoch [90/100], Loss: 0.5959, Val Loss: 0.5756, Accuracy: 68.90%\n",
      "Epoch [100/100], Loss: 0.5920, Val Loss: 0.5756, Accuracy: 69.57%\n",
      "Final model accuracy on test set: 69.77%\n",
      "Accuracy 69.77% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6099, Val Loss: 0.5995, Accuracy: 67.67%\n",
      "Epoch [20/100], Loss: 0.6056, Val Loss: 0.5968, Accuracy: 67.22%\n",
      "Epoch [30/100], Loss: 0.6014, Val Loss: 0.5943, Accuracy: 67.99%\n",
      "Epoch [40/100], Loss: 0.6005, Val Loss: 0.5943, Accuracy: 67.80%\n",
      "Epoch [50/100], Loss: 0.6011, Val Loss: 0.5936, Accuracy: 67.93%\n",
      "Epoch [60/100], Loss: 0.6011, Val Loss: 0.5940, Accuracy: 67.99%\n",
      "Epoch [70/100], Loss: 0.5976, Val Loss: 0.5940, Accuracy: 68.31%\n",
      "Epoch [80/100], Loss: 0.5968, Val Loss: 0.5938, Accuracy: 67.86%\n",
      "Epoch [90/100], Loss: 0.5969, Val Loss: 0.5935, Accuracy: 67.61%\n",
      "Epoch [100/100], Loss: 0.5981, Val Loss: 0.5936, Accuracy: 67.61%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6109, Val Loss: 0.6070, Accuracy: 66.65%\n",
      "Epoch [20/100], Loss: 0.6010, Val Loss: 0.6051, Accuracy: 66.45%\n",
      "Epoch [30/100], Loss: 0.6005, Val Loss: 0.6036, Accuracy: 67.09%\n",
      "Epoch [40/100], Loss: 0.5964, Val Loss: 0.6033, Accuracy: 66.84%\n",
      "Epoch [50/100], Loss: 0.5932, Val Loss: 0.6028, Accuracy: 66.52%\n",
      "Epoch [60/100], Loss: 0.5854, Val Loss: 0.6030, Accuracy: 67.03%\n",
      "Epoch [70/100], Loss: 0.5889, Val Loss: 0.6031, Accuracy: 66.97%\n",
      "Epoch [80/100], Loss: 0.5856, Val Loss: 0.6027, Accuracy: 66.65%\n",
      "Epoch [90/100], Loss: 0.5878, Val Loss: 0.6037, Accuracy: 66.84%\n",
      "Epoch [100/100], Loss: 0.5896, Val Loss: 0.6028, Accuracy: 66.90%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6080, Val Loss: 0.6054, Accuracy: 65.92%\n",
      "Epoch [20/100], Loss: 0.6038, Val Loss: 0.6018, Accuracy: 66.30%\n",
      "Epoch [30/100], Loss: 0.5959, Val Loss: 0.6014, Accuracy: 66.30%\n",
      "Epoch [40/100], Loss: 0.5943, Val Loss: 0.6002, Accuracy: 66.43%\n",
      "Epoch [50/100], Loss: 0.5924, Val Loss: 0.6000, Accuracy: 66.18%\n",
      "Epoch [60/100], Loss: 0.5916, Val Loss: 0.5995, Accuracy: 66.18%\n",
      "Epoch [70/100], Loss: 0.5912, Val Loss: 0.5995, Accuracy: 66.24%\n",
      "Epoch [80/100], Loss: 0.5901, Val Loss: 0.5996, Accuracy: 65.92%\n",
      "Epoch [90/100], Loss: 0.5921, Val Loss: 0.5996, Accuracy: 65.98%\n",
      "Epoch [100/100], Loss: 0.5919, Val Loss: 0.5996, Accuracy: 66.18%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6103, Val Loss: 0.5976, Accuracy: 66.75%\n",
      "Epoch [20/100], Loss: 0.6017, Val Loss: 0.5978, Accuracy: 67.39%\n",
      "Epoch [30/100], Loss: 0.5981, Val Loss: 0.5949, Accuracy: 66.43%\n",
      "Epoch [40/100], Loss: 0.5966, Val Loss: 0.5951, Accuracy: 67.01%\n",
      "Epoch [50/100], Loss: 0.5949, Val Loss: 0.5956, Accuracy: 67.46%\n",
      "Epoch [60/100], Loss: 0.5961, Val Loss: 0.5952, Accuracy: 67.14%\n",
      "Epoch [70/100], Loss: 0.5984, Val Loss: 0.5951, Accuracy: 66.94%\n",
      "Epoch [80/100], Loss: 0.5999, Val Loss: 0.5954, Accuracy: 67.39%\n",
      "Epoch [90/100], Loss: 0.6024, Val Loss: 0.5949, Accuracy: 67.20%\n",
      "Epoch [100/100], Loss: 0.5931, Val Loss: 0.5953, Accuracy: 67.39%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6121, Val Loss: 0.6015, Accuracy: 67.46%\n",
      "Epoch [20/100], Loss: 0.6027, Val Loss: 0.5995, Accuracy: 68.35%\n",
      "Epoch [30/100], Loss: 0.5976, Val Loss: 0.5969, Accuracy: 67.97%\n",
      "Epoch [40/100], Loss: 0.5943, Val Loss: 0.5977, Accuracy: 67.52%\n",
      "Epoch [50/100], Loss: 0.5919, Val Loss: 0.5978, Accuracy: 66.94%\n",
      "Epoch [60/100], Loss: 0.5879, Val Loss: 0.5974, Accuracy: 67.46%\n",
      "Epoch [70/100], Loss: 0.5918, Val Loss: 0.5975, Accuracy: 67.39%\n",
      "Epoch [80/100], Loss: 0.5899, Val Loss: 0.5974, Accuracy: 67.33%\n",
      "Epoch [90/100], Loss: 0.5873, Val Loss: 0.5973, Accuracy: 67.58%\n",
      "Epoch [100/100], Loss: 0.5920, Val Loss: 0.5975, Accuracy: 67.39%\n",
      "Best cross-validated accuracy: 68.50%\n",
      "Epoch [10/100], Loss: 0.6021, Val Loss: 0.5780, Accuracy: 68.34%\n",
      "Epoch [20/100], Loss: 0.5958, Val Loss: 0.5764, Accuracy: 68.85%\n",
      "Epoch [30/100], Loss: 0.5926, Val Loss: 0.5749, Accuracy: 68.65%\n",
      "Epoch [40/100], Loss: 0.5923, Val Loss: 0.5760, Accuracy: 69.01%\n",
      "Epoch [50/100], Loss: 0.5877, Val Loss: 0.5755, Accuracy: 68.70%\n",
      "Epoch [60/100], Loss: 0.5875, Val Loss: 0.5757, Accuracy: 68.49%\n",
      "Epoch [70/100], Loss: 0.5901, Val Loss: 0.5755, Accuracy: 68.65%\n",
      "Epoch [80/100], Loss: 0.5889, Val Loss: 0.5755, Accuracy: 68.70%\n",
      "Epoch [90/100], Loss: 0.5889, Val Loss: 0.5756, Accuracy: 68.65%\n",
      "Epoch [100/100], Loss: 0.5890, Val Loss: 0.5753, Accuracy: 68.60%\n",
      "Final model accuracy on test set: 69.67%\n",
      "Accuracy 69.67% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6064, Val Loss: 0.5968, Accuracy: 67.67%\n",
      "Epoch [20/100], Loss: 0.5989, Val Loss: 0.5964, Accuracy: 67.48%\n",
      "Epoch [30/100], Loss: 0.5977, Val Loss: 0.5927, Accuracy: 67.73%\n",
      "Epoch [40/100], Loss: 0.5958, Val Loss: 0.5916, Accuracy: 67.99%\n",
      "Epoch [50/100], Loss: 0.5919, Val Loss: 0.5908, Accuracy: 68.25%\n",
      "Epoch [60/100], Loss: 0.5910, Val Loss: 0.5894, Accuracy: 68.18%\n",
      "Epoch [70/100], Loss: 0.5917, Val Loss: 0.5949, Accuracy: 67.86%\n",
      "Epoch [80/100], Loss: 0.5842, Val Loss: 0.5907, Accuracy: 67.41%\n",
      "Epoch [90/100], Loss: 0.5846, Val Loss: 0.5903, Accuracy: 68.05%\n",
      "Epoch [100/100], Loss: 0.5868, Val Loss: 0.5905, Accuracy: 67.54%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6066, Val Loss: 0.6071, Accuracy: 66.52%\n",
      "Epoch [20/100], Loss: 0.5996, Val Loss: 0.6034, Accuracy: 67.22%\n",
      "Epoch [30/100], Loss: 0.5982, Val Loss: 0.6015, Accuracy: 67.29%\n",
      "Epoch [40/100], Loss: 0.5941, Val Loss: 0.6017, Accuracy: 67.29%\n",
      "Epoch [50/100], Loss: 0.5926, Val Loss: 0.6014, Accuracy: 66.84%\n",
      "Epoch [60/100], Loss: 0.5932, Val Loss: 0.6022, Accuracy: 66.84%\n",
      "Epoch [70/100], Loss: 0.5859, Val Loss: 0.6016, Accuracy: 66.84%\n",
      "Epoch [80/100], Loss: 0.5914, Val Loss: 0.6014, Accuracy: 66.90%\n",
      "Epoch [90/100], Loss: 0.5936, Val Loss: 0.6013, Accuracy: 66.77%\n",
      "Epoch [100/100], Loss: 0.5917, Val Loss: 0.6018, Accuracy: 67.03%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6117, Val Loss: 0.6063, Accuracy: 65.41%\n",
      "Epoch [20/100], Loss: 0.5998, Val Loss: 0.6013, Accuracy: 65.98%\n",
      "Epoch [30/100], Loss: 0.6019, Val Loss: 0.6033, Accuracy: 65.60%\n",
      "Epoch [40/100], Loss: 0.5954, Val Loss: 0.5989, Accuracy: 66.18%\n",
      "Epoch [50/100], Loss: 0.5891, Val Loss: 0.5976, Accuracy: 65.98%\n",
      "Epoch [60/100], Loss: 0.5938, Val Loss: 0.5977, Accuracy: 66.24%\n",
      "Epoch [70/100], Loss: 0.5930, Val Loss: 0.5979, Accuracy: 66.43%\n",
      "Epoch [80/100], Loss: 0.5909, Val Loss: 0.5979, Accuracy: 66.24%\n",
      "Epoch [90/100], Loss: 0.5927, Val Loss: 0.5977, Accuracy: 66.37%\n",
      "Epoch [100/100], Loss: 0.5936, Val Loss: 0.5978, Accuracy: 66.50%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6123, Val Loss: 0.5963, Accuracy: 66.37%\n",
      "Epoch [20/100], Loss: 0.6052, Val Loss: 0.5967, Accuracy: 67.84%\n",
      "Epoch [30/100], Loss: 0.5997, Val Loss: 0.5933, Accuracy: 67.07%\n",
      "Epoch [40/100], Loss: 0.5974, Val Loss: 0.5950, Accuracy: 66.94%\n",
      "Epoch [50/100], Loss: 0.5925, Val Loss: 0.5954, Accuracy: 66.94%\n",
      "Epoch [60/100], Loss: 0.5908, Val Loss: 0.5959, Accuracy: 67.20%\n",
      "Epoch [70/100], Loss: 0.5955, Val Loss: 0.5958, Accuracy: 67.01%\n",
      "Epoch [80/100], Loss: 0.5898, Val Loss: 0.5956, Accuracy: 67.14%\n",
      "Epoch [90/100], Loss: 0.5868, Val Loss: 0.5957, Accuracy: 67.07%\n",
      "Epoch [100/100], Loss: 0.5880, Val Loss: 0.5957, Accuracy: 67.07%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6112, Val Loss: 0.5990, Accuracy: 67.65%\n",
      "Epoch [20/100], Loss: 0.6017, Val Loss: 0.5957, Accuracy: 67.84%\n",
      "Epoch [30/100], Loss: 0.5981, Val Loss: 0.6004, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5910, Val Loss: 0.5984, Accuracy: 66.75%\n",
      "Epoch [50/100], Loss: 0.5907, Val Loss: 0.5975, Accuracy: 66.82%\n",
      "Epoch [60/100], Loss: 0.5895, Val Loss: 0.5983, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5898, Val Loss: 0.5980, Accuracy: 67.14%\n",
      "Epoch [80/100], Loss: 0.5945, Val Loss: 0.5976, Accuracy: 67.26%\n",
      "Epoch [90/100], Loss: 0.5902, Val Loss: 0.5977, Accuracy: 67.14%\n",
      "Epoch [100/100], Loss: 0.5924, Val Loss: 0.5976, Accuracy: 67.14%\n",
      "Best cross-validated accuracy: 68.69%\n",
      "Epoch [10/100], Loss: 0.5901, Val Loss: 0.5774, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5889, Val Loss: 0.5775, Accuracy: 68.55%\n",
      "Epoch [30/100], Loss: 0.5858, Val Loss: 0.5753, Accuracy: 68.95%\n",
      "Epoch [40/100], Loss: 0.5880, Val Loss: 0.5762, Accuracy: 69.11%\n",
      "Epoch [50/100], Loss: 0.5852, Val Loss: 0.5755, Accuracy: 68.90%\n",
      "Epoch [60/100], Loss: 0.5832, Val Loss: 0.5755, Accuracy: 69.11%\n",
      "Epoch [70/100], Loss: 0.5834, Val Loss: 0.5751, Accuracy: 69.16%\n",
      "Epoch [80/100], Loss: 0.5843, Val Loss: 0.5760, Accuracy: 68.95%\n",
      "Epoch [90/100], Loss: 0.5832, Val Loss: 0.5756, Accuracy: 69.06%\n",
      "Epoch [100/100], Loss: 0.5851, Val Loss: 0.5756, Accuracy: 68.90%\n",
      "Final model accuracy on test set: 69.47%\n",
      "Accuracy 69.47% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6097, Val Loss: 0.5966, Accuracy: 67.73%\n",
      "Epoch [20/100], Loss: 0.6008, Val Loss: 0.5935, Accuracy: 67.99%\n",
      "Epoch [30/100], Loss: 0.5969, Val Loss: 0.5923, Accuracy: 68.50%\n",
      "Epoch [40/100], Loss: 0.5949, Val Loss: 0.5928, Accuracy: 68.12%\n",
      "Epoch [50/100], Loss: 0.5898, Val Loss: 0.5931, Accuracy: 68.05%\n",
      "Epoch [60/100], Loss: 0.5908, Val Loss: 0.5916, Accuracy: 67.48%\n",
      "Epoch [70/100], Loss: 0.5895, Val Loss: 0.5918, Accuracy: 68.12%\n",
      "Epoch [80/100], Loss: 0.5902, Val Loss: 0.5917, Accuracy: 68.12%\n",
      "Epoch [90/100], Loss: 0.5926, Val Loss: 0.5916, Accuracy: 67.80%\n",
      "Epoch [100/100], Loss: 0.5905, Val Loss: 0.5921, Accuracy: 68.12%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6107, Val Loss: 0.6056, Accuracy: 66.97%\n",
      "Epoch [20/100], Loss: 0.6029, Val Loss: 0.6021, Accuracy: 66.77%\n",
      "Epoch [30/100], Loss: 0.5996, Val Loss: 0.6007, Accuracy: 66.65%\n",
      "Epoch [40/100], Loss: 0.5923, Val Loss: 0.6000, Accuracy: 66.90%\n",
      "Epoch [50/100], Loss: 0.5909, Val Loss: 0.6008, Accuracy: 67.09%\n",
      "Epoch [60/100], Loss: 0.5881, Val Loss: 0.6013, Accuracy: 66.77%\n",
      "Epoch [70/100], Loss: 0.5872, Val Loss: 0.6019, Accuracy: 67.03%\n",
      "Epoch [80/100], Loss: 0.5833, Val Loss: 0.6012, Accuracy: 66.97%\n",
      "Epoch [90/100], Loss: 0.5845, Val Loss: 0.6015, Accuracy: 67.03%\n",
      "Epoch [100/100], Loss: 0.5885, Val Loss: 0.6017, Accuracy: 66.84%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6100, Val Loss: 0.6057, Accuracy: 65.73%\n",
      "Epoch [20/100], Loss: 0.6003, Val Loss: 0.6033, Accuracy: 66.50%\n",
      "Epoch [30/100], Loss: 0.5995, Val Loss: 0.6017, Accuracy: 65.98%\n",
      "Epoch [40/100], Loss: 0.5926, Val Loss: 0.6011, Accuracy: 65.92%\n",
      "Epoch [50/100], Loss: 0.5940, Val Loss: 0.6004, Accuracy: 66.75%\n",
      "Epoch [60/100], Loss: 0.5895, Val Loss: 0.6002, Accuracy: 66.62%\n",
      "Epoch [70/100], Loss: 0.5900, Val Loss: 0.5995, Accuracy: 66.05%\n",
      "Epoch [80/100], Loss: 0.5878, Val Loss: 0.5997, Accuracy: 66.43%\n",
      "Epoch [90/100], Loss: 0.5919, Val Loss: 0.5995, Accuracy: 66.11%\n",
      "Epoch [100/100], Loss: 0.5892, Val Loss: 0.5995, Accuracy: 66.56%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6131, Val Loss: 0.6006, Accuracy: 67.01%\n",
      "Epoch [20/100], Loss: 0.6001, Val Loss: 0.5954, Accuracy: 67.14%\n",
      "Epoch [30/100], Loss: 0.6007, Val Loss: 0.5999, Accuracy: 66.82%\n",
      "Epoch [40/100], Loss: 0.5942, Val Loss: 0.5962, Accuracy: 67.26%\n",
      "Epoch [50/100], Loss: 0.5939, Val Loss: 0.5958, Accuracy: 67.01%\n",
      "Epoch [60/100], Loss: 0.5963, Val Loss: 0.5966, Accuracy: 67.20%\n",
      "Epoch [70/100], Loss: 0.5959, Val Loss: 0.5959, Accuracy: 67.14%\n",
      "Epoch [80/100], Loss: 0.5930, Val Loss: 0.5960, Accuracy: 67.07%\n",
      "Epoch [90/100], Loss: 0.5953, Val Loss: 0.5958, Accuracy: 67.01%\n",
      "Epoch [100/100], Loss: 0.5939, Val Loss: 0.5960, Accuracy: 67.26%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6105, Val Loss: 0.6006, Accuracy: 67.91%\n",
      "Epoch [20/100], Loss: 0.6024, Val Loss: 0.5986, Accuracy: 67.52%\n",
      "Epoch [30/100], Loss: 0.5986, Val Loss: 0.5985, Accuracy: 67.52%\n",
      "Epoch [40/100], Loss: 0.5918, Val Loss: 0.5970, Accuracy: 67.20%\n",
      "Epoch [50/100], Loss: 0.5962, Val Loss: 0.5970, Accuracy: 67.26%\n",
      "Epoch [60/100], Loss: 0.5933, Val Loss: 0.5977, Accuracy: 67.14%\n",
      "Epoch [70/100], Loss: 0.5919, Val Loss: 0.5970, Accuracy: 67.26%\n",
      "Epoch [80/100], Loss: 0.5941, Val Loss: 0.5967, Accuracy: 67.20%\n",
      "Epoch [90/100], Loss: 0.5959, Val Loss: 0.5971, Accuracy: 67.39%\n",
      "Epoch [100/100], Loss: 0.5964, Val Loss: 0.5983, Accuracy: 67.26%\n",
      "Best cross-validated accuracy: 68.69%\n",
      "Epoch [10/100], Loss: 0.5935, Val Loss: 0.5812, Accuracy: 68.60%\n",
      "Epoch [20/100], Loss: 0.5937, Val Loss: 0.5811, Accuracy: 68.90%\n",
      "Epoch [30/100], Loss: 0.5901, Val Loss: 0.5793, Accuracy: 69.26%\n",
      "Epoch [40/100], Loss: 0.5892, Val Loss: 0.5760, Accuracy: 69.47%\n",
      "Epoch [50/100], Loss: 0.5890, Val Loss: 0.5758, Accuracy: 69.31%\n",
      "Epoch [60/100], Loss: 0.5882, Val Loss: 0.5764, Accuracy: 69.31%\n",
      "Epoch [70/100], Loss: 0.5887, Val Loss: 0.5770, Accuracy: 69.31%\n",
      "Epoch [80/100], Loss: 0.5869, Val Loss: 0.5769, Accuracy: 69.52%\n",
      "Epoch [90/100], Loss: 0.5863, Val Loss: 0.5763, Accuracy: 69.31%\n",
      "Epoch [100/100], Loss: 0.5878, Val Loss: 0.5765, Accuracy: 69.42%\n",
      "Final model accuracy on test set: 69.83%\n",
      "Accuracy 69.83% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6093, Val Loss: 0.5978, Accuracy: 67.80%\n",
      "Epoch [20/100], Loss: 0.6031, Val Loss: 0.5940, Accuracy: 68.57%\n",
      "Epoch [30/100], Loss: 0.5966, Val Loss: 0.5946, Accuracy: 67.80%\n",
      "Epoch [40/100], Loss: 0.5955, Val Loss: 0.5946, Accuracy: 68.12%\n",
      "Epoch [50/100], Loss: 0.5939, Val Loss: 0.5919, Accuracy: 67.16%\n",
      "Epoch [60/100], Loss: 0.5903, Val Loss: 0.5926, Accuracy: 68.12%\n",
      "Epoch [70/100], Loss: 0.5880, Val Loss: 0.5922, Accuracy: 68.05%\n",
      "Epoch [80/100], Loss: 0.5893, Val Loss: 0.5927, Accuracy: 67.99%\n",
      "Epoch [90/100], Loss: 0.5932, Val Loss: 0.5925, Accuracy: 67.80%\n",
      "Epoch [100/100], Loss: 0.5936, Val Loss: 0.5921, Accuracy: 67.54%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6148, Val Loss: 0.6058, Accuracy: 66.77%\n",
      "Epoch [20/100], Loss: 0.5967, Val Loss: 0.6011, Accuracy: 67.03%\n",
      "Epoch [30/100], Loss: 0.5993, Val Loss: 0.6003, Accuracy: 67.09%\n",
      "Epoch [40/100], Loss: 0.5928, Val Loss: 0.6006, Accuracy: 66.77%\n",
      "Epoch [50/100], Loss: 0.5896, Val Loss: 0.6004, Accuracy: 67.41%\n",
      "Epoch [60/100], Loss: 0.5905, Val Loss: 0.6010, Accuracy: 67.61%\n",
      "Epoch [70/100], Loss: 0.5902, Val Loss: 0.6011, Accuracy: 67.54%\n",
      "Epoch [80/100], Loss: 0.5912, Val Loss: 0.6016, Accuracy: 66.97%\n",
      "Epoch [90/100], Loss: 0.5906, Val Loss: 0.6009, Accuracy: 67.67%\n",
      "Epoch [100/100], Loss: 0.5890, Val Loss: 0.6010, Accuracy: 67.54%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6121, Val Loss: 0.6075, Accuracy: 66.05%\n",
      "Epoch [20/100], Loss: 0.6019, Val Loss: 0.6020, Accuracy: 66.75%\n",
      "Epoch [30/100], Loss: 0.5978, Val Loss: 0.6005, Accuracy: 66.50%\n",
      "Epoch [40/100], Loss: 0.5941, Val Loss: 0.5994, Accuracy: 66.30%\n",
      "Epoch [50/100], Loss: 0.5931, Val Loss: 0.5984, Accuracy: 66.50%\n",
      "Epoch [60/100], Loss: 0.5899, Val Loss: 0.5982, Accuracy: 67.01%\n",
      "Epoch [70/100], Loss: 0.5874, Val Loss: 0.5984, Accuracy: 66.69%\n",
      "Epoch [80/100], Loss: 0.5868, Val Loss: 0.5983, Accuracy: 66.94%\n",
      "Epoch [90/100], Loss: 0.5859, Val Loss: 0.5983, Accuracy: 66.30%\n",
      "Epoch [100/100], Loss: 0.5859, Val Loss: 0.5978, Accuracy: 66.56%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6094, Val Loss: 0.5958, Accuracy: 66.82%\n",
      "Epoch [20/100], Loss: 0.6028, Val Loss: 0.5951, Accuracy: 67.52%\n",
      "Epoch [30/100], Loss: 0.5966, Val Loss: 0.5930, Accuracy: 67.26%\n",
      "Epoch [40/100], Loss: 0.5934, Val Loss: 0.5938, Accuracy: 67.20%\n",
      "Epoch [50/100], Loss: 0.5968, Val Loss: 0.5942, Accuracy: 67.91%\n",
      "Epoch [60/100], Loss: 0.5917, Val Loss: 0.5943, Accuracy: 67.78%\n",
      "Epoch [70/100], Loss: 0.5938, Val Loss: 0.5939, Accuracy: 67.52%\n",
      "Epoch [80/100], Loss: 0.5912, Val Loss: 0.5942, Accuracy: 67.78%\n",
      "Epoch [90/100], Loss: 0.5927, Val Loss: 0.5940, Accuracy: 67.07%\n",
      "Epoch [100/100], Loss: 0.5971, Val Loss: 0.5941, Accuracy: 67.52%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6121, Val Loss: 0.5992, Accuracy: 67.46%\n",
      "Epoch [20/100], Loss: 0.6062, Val Loss: 0.5969, Accuracy: 67.97%\n",
      "Epoch [30/100], Loss: 0.5987, Val Loss: 0.6001, Accuracy: 66.69%\n",
      "Epoch [40/100], Loss: 0.5936, Val Loss: 0.5968, Accuracy: 67.52%\n",
      "Epoch [50/100], Loss: 0.5953, Val Loss: 0.5974, Accuracy: 67.01%\n",
      "Epoch [60/100], Loss: 0.6000, Val Loss: 0.5973, Accuracy: 67.01%\n",
      "Epoch [70/100], Loss: 0.5958, Val Loss: 0.5973, Accuracy: 66.94%\n",
      "Epoch [80/100], Loss: 0.5956, Val Loss: 0.5970, Accuracy: 67.26%\n",
      "Epoch [90/100], Loss: 0.5976, Val Loss: 0.5969, Accuracy: 67.65%\n",
      "Epoch [100/100], Loss: 0.5939, Val Loss: 0.5968, Accuracy: 67.33%\n",
      "Best cross-validated accuracy: 68.57%\n",
      "Epoch [10/100], Loss: 0.6002, Val Loss: 0.5778, Accuracy: 69.06%\n",
      "Epoch [20/100], Loss: 0.5964, Val Loss: 0.5771, Accuracy: 68.49%\n",
      "Epoch [30/100], Loss: 0.5935, Val Loss: 0.5765, Accuracy: 69.31%\n",
      "Epoch [40/100], Loss: 0.5915, Val Loss: 0.5753, Accuracy: 69.06%\n",
      "Epoch [50/100], Loss: 0.5871, Val Loss: 0.5757, Accuracy: 69.16%\n",
      "Epoch [60/100], Loss: 0.5833, Val Loss: 0.5755, Accuracy: 69.16%\n",
      "Epoch [70/100], Loss: 0.5871, Val Loss: 0.5749, Accuracy: 69.26%\n",
      "Epoch [80/100], Loss: 0.5888, Val Loss: 0.5750, Accuracy: 69.26%\n",
      "Epoch [90/100], Loss: 0.5872, Val Loss: 0.5750, Accuracy: 69.31%\n",
      "Epoch [100/100], Loss: 0.5846, Val Loss: 0.5750, Accuracy: 69.21%\n",
      "Final model accuracy on test set: 69.83%\n",
      "Accuracy 69.83% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6134, Val Loss: 0.5958, Accuracy: 68.37%\n",
      "Epoch [20/100], Loss: 0.6021, Val Loss: 0.5928, Accuracy: 68.18%\n",
      "Epoch [30/100], Loss: 0.5957, Val Loss: 0.5932, Accuracy: 68.18%\n",
      "Epoch [40/100], Loss: 0.5985, Val Loss: 0.5919, Accuracy: 68.37%\n",
      "Epoch [50/100], Loss: 0.5965, Val Loss: 0.5916, Accuracy: 67.61%\n",
      "Epoch [60/100], Loss: 0.5917, Val Loss: 0.5909, Accuracy: 67.86%\n",
      "Epoch [70/100], Loss: 0.5899, Val Loss: 0.5916, Accuracy: 67.67%\n",
      "Epoch [80/100], Loss: 0.5891, Val Loss: 0.5919, Accuracy: 67.86%\n",
      "Epoch [90/100], Loss: 0.5906, Val Loss: 0.5916, Accuracy: 67.99%\n",
      "Epoch [100/100], Loss: 0.5909, Val Loss: 0.5917, Accuracy: 67.93%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6054, Val Loss: 0.6041, Accuracy: 66.52%\n",
      "Epoch [20/100], Loss: 0.6016, Val Loss: 0.6007, Accuracy: 66.90%\n",
      "Epoch [30/100], Loss: 0.5960, Val Loss: 0.6007, Accuracy: 67.16%\n",
      "Epoch [40/100], Loss: 0.5930, Val Loss: 0.6010, Accuracy: 67.29%\n",
      "Epoch [50/100], Loss: 0.5896, Val Loss: 0.6010, Accuracy: 67.16%\n",
      "Epoch [60/100], Loss: 0.5933, Val Loss: 0.6007, Accuracy: 67.22%\n",
      "Epoch [70/100], Loss: 0.5908, Val Loss: 0.6005, Accuracy: 67.16%\n",
      "Epoch [80/100], Loss: 0.5916, Val Loss: 0.6009, Accuracy: 67.16%\n",
      "Epoch [90/100], Loss: 0.5900, Val Loss: 0.6011, Accuracy: 67.22%\n",
      "Epoch [100/100], Loss: 0.5891, Val Loss: 0.6012, Accuracy: 67.16%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6047, Val Loss: 0.6045, Accuracy: 65.28%\n",
      "Epoch [20/100], Loss: 0.6011, Val Loss: 0.6019, Accuracy: 65.53%\n",
      "Epoch [30/100], Loss: 0.5981, Val Loss: 0.5990, Accuracy: 66.18%\n",
      "Epoch [40/100], Loss: 0.5940, Val Loss: 0.5988, Accuracy: 65.79%\n",
      "Epoch [50/100], Loss: 0.5921, Val Loss: 0.5994, Accuracy: 66.05%\n",
      "Epoch [60/100], Loss: 0.5931, Val Loss: 0.5988, Accuracy: 66.37%\n",
      "Epoch [70/100], Loss: 0.5893, Val Loss: 0.5983, Accuracy: 65.92%\n",
      "Epoch [80/100], Loss: 0.5880, Val Loss: 0.5986, Accuracy: 66.30%\n",
      "Epoch [90/100], Loss: 0.5870, Val Loss: 0.5990, Accuracy: 66.43%\n",
      "Epoch [100/100], Loss: 0.5903, Val Loss: 0.5985, Accuracy: 66.43%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6084, Val Loss: 0.5978, Accuracy: 67.20%\n",
      "Epoch [20/100], Loss: 0.6043, Val Loss: 0.5951, Accuracy: 67.33%\n",
      "Epoch [30/100], Loss: 0.5937, Val Loss: 0.5947, Accuracy: 68.29%\n",
      "Epoch [40/100], Loss: 0.5958, Val Loss: 0.5955, Accuracy: 67.07%\n",
      "Epoch [50/100], Loss: 0.5947, Val Loss: 0.5953, Accuracy: 66.82%\n",
      "Epoch [60/100], Loss: 0.5945, Val Loss: 0.5952, Accuracy: 66.88%\n",
      "Epoch [70/100], Loss: 0.5976, Val Loss: 0.5952, Accuracy: 66.82%\n",
      "Epoch [80/100], Loss: 0.5977, Val Loss: 0.5953, Accuracy: 67.33%\n",
      "Epoch [90/100], Loss: 0.5929, Val Loss: 0.5955, Accuracy: 66.88%\n",
      "Epoch [100/100], Loss: 0.5955, Val Loss: 0.5951, Accuracy: 66.82%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6134, Val Loss: 0.6011, Accuracy: 67.52%\n",
      "Epoch [20/100], Loss: 0.6003, Val Loss: 0.5981, Accuracy: 67.33%\n",
      "Epoch [30/100], Loss: 0.5963, Val Loss: 0.5969, Accuracy: 67.39%\n",
      "Epoch [40/100], Loss: 0.5956, Val Loss: 0.5967, Accuracy: 67.39%\n",
      "Epoch [50/100], Loss: 0.5933, Val Loss: 0.5973, Accuracy: 67.46%\n",
      "Epoch [60/100], Loss: 0.5974, Val Loss: 0.5970, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5929, Val Loss: 0.5969, Accuracy: 67.65%\n",
      "Epoch [80/100], Loss: 0.5945, Val Loss: 0.5970, Accuracy: 67.26%\n",
      "Epoch [90/100], Loss: 0.5974, Val Loss: 0.5969, Accuracy: 67.01%\n",
      "Epoch [100/100], Loss: 0.5958, Val Loss: 0.5972, Accuracy: 67.33%\n",
      "Best cross-validated accuracy: 68.76%\n",
      "Epoch [10/100], Loss: 0.5965, Val Loss: 0.5756, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5912, Val Loss: 0.5760, Accuracy: 69.01%\n",
      "Epoch [30/100], Loss: 0.5931, Val Loss: 0.5754, Accuracy: 69.31%\n",
      "Epoch [40/100], Loss: 0.5918, Val Loss: 0.5761, Accuracy: 68.85%\n",
      "Epoch [50/100], Loss: 0.5897, Val Loss: 0.5757, Accuracy: 68.95%\n",
      "Epoch [60/100], Loss: 0.5902, Val Loss: 0.5759, Accuracy: 68.80%\n",
      "Epoch [70/100], Loss: 0.5926, Val Loss: 0.5754, Accuracy: 68.85%\n",
      "Epoch [80/100], Loss: 0.5898, Val Loss: 0.5756, Accuracy: 68.90%\n",
      "Epoch [90/100], Loss: 0.5934, Val Loss: 0.5756, Accuracy: 68.75%\n",
      "Epoch [100/100], Loss: 0.5924, Val Loss: 0.5761, Accuracy: 68.85%\n",
      "Final model accuracy on test set: 69.47%\n",
      "Accuracy 69.47% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6124, Val Loss: 0.5970, Accuracy: 67.67%\n",
      "Epoch [20/100], Loss: 0.6010, Val Loss: 0.5938, Accuracy: 67.41%\n",
      "Epoch [30/100], Loss: 0.5998, Val Loss: 0.5926, Accuracy: 67.86%\n",
      "Epoch [40/100], Loss: 0.5952, Val Loss: 0.5941, Accuracy: 67.86%\n",
      "Epoch [50/100], Loss: 0.5931, Val Loss: 0.5931, Accuracy: 67.61%\n",
      "Epoch [60/100], Loss: 0.5913, Val Loss: 0.5926, Accuracy: 67.54%\n",
      "Epoch [70/100], Loss: 0.5899, Val Loss: 0.5925, Accuracy: 67.54%\n",
      "Epoch [80/100], Loss: 0.5866, Val Loss: 0.5930, Accuracy: 67.86%\n",
      "Epoch [90/100], Loss: 0.5901, Val Loss: 0.5924, Accuracy: 67.73%\n",
      "Epoch [100/100], Loss: 0.5933, Val Loss: 0.5926, Accuracy: 67.73%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6086, Val Loss: 0.6066, Accuracy: 66.90%\n",
      "Epoch [20/100], Loss: 0.6012, Val Loss: 0.6035, Accuracy: 67.16%\n",
      "Epoch [30/100], Loss: 0.5986, Val Loss: 0.6016, Accuracy: 66.77%\n",
      "Epoch [40/100], Loss: 0.5928, Val Loss: 0.6029, Accuracy: 67.09%\n",
      "Epoch [50/100], Loss: 0.5904, Val Loss: 0.6015, Accuracy: 66.90%\n",
      "Epoch [60/100], Loss: 0.5929, Val Loss: 0.6015, Accuracy: 67.22%\n",
      "Epoch [70/100], Loss: 0.5914, Val Loss: 0.6014, Accuracy: 67.16%\n",
      "Epoch [80/100], Loss: 0.5916, Val Loss: 0.6012, Accuracy: 67.09%\n",
      "Epoch [90/100], Loss: 0.5911, Val Loss: 0.6013, Accuracy: 67.29%\n",
      "Epoch [100/100], Loss: 0.5880, Val Loss: 0.6009, Accuracy: 67.22%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6088, Val Loss: 0.6053, Accuracy: 65.02%\n",
      "Epoch [20/100], Loss: 0.6022, Val Loss: 0.6007, Accuracy: 65.92%\n",
      "Epoch [30/100], Loss: 0.6008, Val Loss: 0.5999, Accuracy: 66.30%\n",
      "Epoch [40/100], Loss: 0.5928, Val Loss: 0.5977, Accuracy: 66.24%\n",
      "Epoch [50/100], Loss: 0.5914, Val Loss: 0.5987, Accuracy: 66.82%\n",
      "Epoch [60/100], Loss: 0.5893, Val Loss: 0.5974, Accuracy: 66.56%\n",
      "Epoch [70/100], Loss: 0.5884, Val Loss: 0.5976, Accuracy: 66.30%\n",
      "Epoch [80/100], Loss: 0.5891, Val Loss: 0.5979, Accuracy: 66.18%\n",
      "Epoch [90/100], Loss: 0.5890, Val Loss: 0.5981, Accuracy: 66.50%\n",
      "Epoch [100/100], Loss: 0.5875, Val Loss: 0.5979, Accuracy: 65.86%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6096, Val Loss: 0.5951, Accuracy: 67.01%\n",
      "Epoch [20/100], Loss: 0.6038, Val Loss: 0.5929, Accuracy: 67.20%\n",
      "Epoch [30/100], Loss: 0.5960, Val Loss: 0.5930, Accuracy: 67.26%\n",
      "Epoch [40/100], Loss: 0.5986, Val Loss: 0.5935, Accuracy: 67.65%\n",
      "Epoch [50/100], Loss: 0.5966, Val Loss: 0.5939, Accuracy: 67.52%\n",
      "Epoch [60/100], Loss: 0.5950, Val Loss: 0.5937, Accuracy: 67.39%\n",
      "Epoch [70/100], Loss: 0.5958, Val Loss: 0.5937, Accuracy: 67.46%\n",
      "Epoch [80/100], Loss: 0.5986, Val Loss: 0.5936, Accuracy: 67.26%\n",
      "Epoch [90/100], Loss: 0.5938, Val Loss: 0.5936, Accuracy: 67.20%\n",
      "Epoch [100/100], Loss: 0.5952, Val Loss: 0.5935, Accuracy: 67.14%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6059, Val Loss: 0.6021, Accuracy: 66.69%\n",
      "Epoch [20/100], Loss: 0.5983, Val Loss: 0.6001, Accuracy: 66.88%\n",
      "Epoch [30/100], Loss: 0.5962, Val Loss: 0.5970, Accuracy: 67.84%\n",
      "Epoch [40/100], Loss: 0.5903, Val Loss: 0.5980, Accuracy: 67.97%\n",
      "Epoch [50/100], Loss: 0.5925, Val Loss: 0.5981, Accuracy: 67.97%\n",
      "Epoch [60/100], Loss: 0.5900, Val Loss: 0.5981, Accuracy: 68.03%\n",
      "Epoch [70/100], Loss: 0.5949, Val Loss: 0.5979, Accuracy: 67.84%\n",
      "Epoch [80/100], Loss: 0.5916, Val Loss: 0.5977, Accuracy: 67.65%\n",
      "Epoch [90/100], Loss: 0.5914, Val Loss: 0.5980, Accuracy: 67.78%\n",
      "Epoch [100/100], Loss: 0.5944, Val Loss: 0.5982, Accuracy: 67.97%\n",
      "Best cross-validated accuracy: 68.48%\n",
      "Epoch [10/100], Loss: 0.6015, Val Loss: 0.5773, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5944, Val Loss: 0.5773, Accuracy: 69.16%\n",
      "Epoch [30/100], Loss: 0.5927, Val Loss: 0.5761, Accuracy: 69.21%\n",
      "Epoch [40/100], Loss: 0.5916, Val Loss: 0.5762, Accuracy: 69.26%\n",
      "Epoch [50/100], Loss: 0.5908, Val Loss: 0.5761, Accuracy: 69.26%\n",
      "Epoch [60/100], Loss: 0.5929, Val Loss: 0.5767, Accuracy: 69.06%\n",
      "Epoch [70/100], Loss: 0.5900, Val Loss: 0.5770, Accuracy: 69.21%\n",
      "Epoch [80/100], Loss: 0.5905, Val Loss: 0.5761, Accuracy: 69.16%\n",
      "Epoch [90/100], Loss: 0.5885, Val Loss: 0.5768, Accuracy: 69.06%\n",
      "Epoch [100/100], Loss: 0.5880, Val Loss: 0.5763, Accuracy: 69.21%\n",
      "Final model accuracy on test set: 69.57%\n",
      "Accuracy 69.57% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6098, Val Loss: 0.5980, Accuracy: 69.21%\n",
      "Epoch [20/100], Loss: 0.6054, Val Loss: 0.5948, Accuracy: 67.80%\n",
      "Epoch [30/100], Loss: 0.5966, Val Loss: 0.5951, Accuracy: 68.25%\n",
      "Epoch [40/100], Loss: 0.5951, Val Loss: 0.5928, Accuracy: 67.80%\n",
      "Epoch [50/100], Loss: 0.5946, Val Loss: 0.5908, Accuracy: 67.93%\n",
      "Epoch [60/100], Loss: 0.5920, Val Loss: 0.5912, Accuracy: 67.48%\n",
      "Epoch [70/100], Loss: 0.5882, Val Loss: 0.5910, Accuracy: 67.48%\n",
      "Epoch [80/100], Loss: 0.5884, Val Loss: 0.5909, Accuracy: 67.22%\n",
      "Epoch [90/100], Loss: 0.5892, Val Loss: 0.5912, Accuracy: 67.41%\n",
      "Epoch [100/100], Loss: 0.5891, Val Loss: 0.5910, Accuracy: 67.22%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6162, Val Loss: 0.6053, Accuracy: 66.77%\n",
      "Epoch [20/100], Loss: 0.6019, Val Loss: 0.6017, Accuracy: 67.54%\n",
      "Epoch [30/100], Loss: 0.5971, Val Loss: 0.5999, Accuracy: 67.29%\n",
      "Epoch [40/100], Loss: 0.5928, Val Loss: 0.6000, Accuracy: 66.90%\n",
      "Epoch [50/100], Loss: 0.5916, Val Loss: 0.6008, Accuracy: 67.22%\n",
      "Epoch [60/100], Loss: 0.5914, Val Loss: 0.6014, Accuracy: 67.54%\n",
      "Epoch [70/100], Loss: 0.5897, Val Loss: 0.6018, Accuracy: 67.61%\n",
      "Epoch [80/100], Loss: 0.5894, Val Loss: 0.6015, Accuracy: 67.41%\n",
      "Epoch [90/100], Loss: 0.5912, Val Loss: 0.6019, Accuracy: 67.86%\n",
      "Epoch [100/100], Loss: 0.5914, Val Loss: 0.6015, Accuracy: 67.67%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6104, Val Loss: 0.6078, Accuracy: 65.41%\n",
      "Epoch [20/100], Loss: 0.6036, Val Loss: 0.6045, Accuracy: 65.41%\n",
      "Epoch [30/100], Loss: 0.5977, Val Loss: 0.6013, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5951, Val Loss: 0.5996, Accuracy: 65.73%\n",
      "Epoch [50/100], Loss: 0.5916, Val Loss: 0.5986, Accuracy: 65.86%\n",
      "Epoch [60/100], Loss: 0.5917, Val Loss: 0.5988, Accuracy: 65.60%\n",
      "Epoch [70/100], Loss: 0.5929, Val Loss: 0.5986, Accuracy: 66.11%\n",
      "Epoch [80/100], Loss: 0.5909, Val Loss: 0.5988, Accuracy: 65.86%\n",
      "Epoch [90/100], Loss: 0.5917, Val Loss: 0.5984, Accuracy: 65.79%\n",
      "Epoch [100/100], Loss: 0.5900, Val Loss: 0.5986, Accuracy: 65.60%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6075, Val Loss: 0.5981, Accuracy: 66.24%\n",
      "Epoch [20/100], Loss: 0.6035, Val Loss: 0.5969, Accuracy: 67.33%\n",
      "Epoch [30/100], Loss: 0.5976, Val Loss: 0.5951, Accuracy: 66.88%\n",
      "Epoch [40/100], Loss: 0.5979, Val Loss: 0.5946, Accuracy: 66.88%\n",
      "Epoch [50/100], Loss: 0.5983, Val Loss: 0.5953, Accuracy: 67.33%\n",
      "Epoch [60/100], Loss: 0.5973, Val Loss: 0.5946, Accuracy: 66.82%\n",
      "Epoch [70/100], Loss: 0.5981, Val Loss: 0.5948, Accuracy: 66.62%\n",
      "Epoch [80/100], Loss: 0.5949, Val Loss: 0.5947, Accuracy: 66.75%\n",
      "Epoch [90/100], Loss: 0.5955, Val Loss: 0.5950, Accuracy: 67.07%\n",
      "Epoch [100/100], Loss: 0.5951, Val Loss: 0.5946, Accuracy: 66.75%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6102, Val Loss: 0.6010, Accuracy: 67.65%\n",
      "Epoch [20/100], Loss: 0.6041, Val Loss: 0.5984, Accuracy: 68.35%\n",
      "Epoch [30/100], Loss: 0.5959, Val Loss: 0.5981, Accuracy: 67.97%\n",
      "Epoch [40/100], Loss: 0.5921, Val Loss: 0.5968, Accuracy: 67.46%\n",
      "Epoch [50/100], Loss: 0.5983, Val Loss: 0.5978, Accuracy: 67.33%\n",
      "Epoch [60/100], Loss: 0.5909, Val Loss: 0.5971, Accuracy: 67.39%\n",
      "Epoch [70/100], Loss: 0.5921, Val Loss: 0.5973, Accuracy: 67.20%\n",
      "Epoch [80/100], Loss: 0.5943, Val Loss: 0.5972, Accuracy: 67.20%\n",
      "Epoch [90/100], Loss: 0.5942, Val Loss: 0.5973, Accuracy: 67.33%\n",
      "Epoch [100/100], Loss: 0.5943, Val Loss: 0.5973, Accuracy: 67.14%\n",
      "Best cross-validated accuracy: 69.21%\n",
      "Epoch [10/100], Loss: 0.5984, Val Loss: 0.5782, Accuracy: 68.55%\n",
      "Epoch [20/100], Loss: 0.5950, Val Loss: 0.5777, Accuracy: 68.49%\n",
      "Epoch [30/100], Loss: 0.5942, Val Loss: 0.5750, Accuracy: 69.52%\n",
      "Epoch [40/100], Loss: 0.5903, Val Loss: 0.5742, Accuracy: 69.83%\n",
      "Epoch [50/100], Loss: 0.5901, Val Loss: 0.5765, Accuracy: 68.85%\n",
      "Epoch [60/100], Loss: 0.5852, Val Loss: 0.5760, Accuracy: 68.95%\n",
      "Epoch [70/100], Loss: 0.5887, Val Loss: 0.5756, Accuracy: 69.11%\n",
      "Epoch [80/100], Loss: 0.5888, Val Loss: 0.5760, Accuracy: 69.01%\n",
      "Epoch [90/100], Loss: 0.5859, Val Loss: 0.5756, Accuracy: 69.06%\n",
      "Epoch [100/100], Loss: 0.5886, Val Loss: 0.5765, Accuracy: 69.06%\n",
      "Final model accuracy on test set: 69.88%\n",
      "Accuracy 69.88% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6117, Val Loss: 0.5968, Accuracy: 67.99%\n",
      "Epoch [20/100], Loss: 0.6059, Val Loss: 0.5953, Accuracy: 67.99%\n",
      "Epoch [30/100], Loss: 0.5973, Val Loss: 0.5933, Accuracy: 68.05%\n",
      "Epoch [40/100], Loss: 0.5941, Val Loss: 0.5921, Accuracy: 67.99%\n",
      "Epoch [50/100], Loss: 0.5954, Val Loss: 0.5911, Accuracy: 68.37%\n",
      "Epoch [60/100], Loss: 0.5935, Val Loss: 0.5906, Accuracy: 68.44%\n",
      "Epoch [70/100], Loss: 0.5948, Val Loss: 0.5908, Accuracy: 68.50%\n",
      "Epoch [80/100], Loss: 0.5908, Val Loss: 0.5911, Accuracy: 68.50%\n",
      "Epoch [90/100], Loss: 0.5953, Val Loss: 0.5907, Accuracy: 68.44%\n",
      "Epoch [100/100], Loss: 0.5956, Val Loss: 0.5910, Accuracy: 68.37%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6093, Val Loss: 0.6087, Accuracy: 66.33%\n",
      "Epoch [20/100], Loss: 0.6020, Val Loss: 0.6018, Accuracy: 67.22%\n",
      "Epoch [30/100], Loss: 0.5963, Val Loss: 0.6031, Accuracy: 66.90%\n",
      "Epoch [40/100], Loss: 0.5922, Val Loss: 0.6030, Accuracy: 66.90%\n",
      "Epoch [50/100], Loss: 0.5910, Val Loss: 0.6018, Accuracy: 66.71%\n",
      "Epoch [60/100], Loss: 0.5882, Val Loss: 0.6011, Accuracy: 66.90%\n",
      "Epoch [70/100], Loss: 0.5883, Val Loss: 0.6014, Accuracy: 67.22%\n",
      "Epoch [80/100], Loss: 0.5908, Val Loss: 0.6023, Accuracy: 66.97%\n",
      "Epoch [90/100], Loss: 0.5890, Val Loss: 0.6018, Accuracy: 66.90%\n",
      "Epoch [100/100], Loss: 0.5885, Val Loss: 0.6016, Accuracy: 66.77%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6138, Val Loss: 0.6043, Accuracy: 65.92%\n",
      "Epoch [20/100], Loss: 0.6047, Val Loss: 0.6014, Accuracy: 66.18%\n",
      "Epoch [30/100], Loss: 0.5977, Val Loss: 0.6006, Accuracy: 66.82%\n",
      "Epoch [40/100], Loss: 0.5959, Val Loss: 0.5991, Accuracy: 65.73%\n",
      "Epoch [50/100], Loss: 0.5958, Val Loss: 0.5989, Accuracy: 66.56%\n",
      "Epoch [60/100], Loss: 0.5909, Val Loss: 0.5984, Accuracy: 66.88%\n",
      "Epoch [70/100], Loss: 0.5881, Val Loss: 0.5984, Accuracy: 66.50%\n",
      "Epoch [80/100], Loss: 0.5844, Val Loss: 0.5980, Accuracy: 66.94%\n",
      "Epoch [90/100], Loss: 0.5889, Val Loss: 0.5981, Accuracy: 66.82%\n",
      "Epoch [100/100], Loss: 0.5869, Val Loss: 0.5985, Accuracy: 66.82%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6129, Val Loss: 0.5994, Accuracy: 66.69%\n",
      "Epoch [20/100], Loss: 0.6060, Val Loss: 0.5974, Accuracy: 67.01%\n",
      "Epoch [30/100], Loss: 0.5997, Val Loss: 0.5958, Accuracy: 67.14%\n",
      "Epoch [40/100], Loss: 0.5951, Val Loss: 0.5964, Accuracy: 67.01%\n",
      "Epoch [50/100], Loss: 0.5935, Val Loss: 0.5959, Accuracy: 67.14%\n",
      "Epoch [60/100], Loss: 0.5905, Val Loss: 0.5957, Accuracy: 67.14%\n",
      "Epoch [70/100], Loss: 0.5906, Val Loss: 0.5958, Accuracy: 67.14%\n",
      "Epoch [80/100], Loss: 0.5954, Val Loss: 0.5960, Accuracy: 66.82%\n",
      "Epoch [90/100], Loss: 0.5951, Val Loss: 0.5956, Accuracy: 66.75%\n",
      "Epoch [100/100], Loss: 0.5931, Val Loss: 0.5957, Accuracy: 66.69%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6059, Val Loss: 0.5985, Accuracy: 67.97%\n",
      "Epoch [20/100], Loss: 0.6023, Val Loss: 0.5970, Accuracy: 67.58%\n",
      "Epoch [30/100], Loss: 0.5945, Val Loss: 0.5954, Accuracy: 68.23%\n",
      "Epoch [40/100], Loss: 0.5987, Val Loss: 0.5957, Accuracy: 67.39%\n",
      "Epoch [50/100], Loss: 0.5932, Val Loss: 0.5954, Accuracy: 67.84%\n",
      "Epoch [60/100], Loss: 0.5973, Val Loss: 0.5960, Accuracy: 67.58%\n",
      "Epoch [70/100], Loss: 0.5945, Val Loss: 0.5959, Accuracy: 67.58%\n",
      "Epoch [80/100], Loss: 0.5997, Val Loss: 0.5957, Accuracy: 67.52%\n",
      "Epoch [90/100], Loss: 0.5997, Val Loss: 0.5962, Accuracy: 67.52%\n",
      "Epoch [100/100], Loss: 0.6008, Val Loss: 0.5954, Accuracy: 67.71%\n",
      "Best cross-validated accuracy: 68.57%\n",
      "Epoch [10/100], Loss: 0.5979, Val Loss: 0.5752, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5941, Val Loss: 0.5726, Accuracy: 69.26%\n",
      "Epoch [30/100], Loss: 0.5877, Val Loss: 0.5760, Accuracy: 69.26%\n",
      "Epoch [40/100], Loss: 0.5876, Val Loss: 0.5743, Accuracy: 69.31%\n",
      "Epoch [50/100], Loss: 0.5878, Val Loss: 0.5746, Accuracy: 69.16%\n",
      "Epoch [60/100], Loss: 0.5909, Val Loss: 0.5747, Accuracy: 68.95%\n",
      "Epoch [70/100], Loss: 0.5880, Val Loss: 0.5748, Accuracy: 68.70%\n",
      "Epoch [80/100], Loss: 0.5883, Val Loss: 0.5742, Accuracy: 69.26%\n",
      "Epoch [90/100], Loss: 0.5870, Val Loss: 0.5746, Accuracy: 68.95%\n",
      "Epoch [100/100], Loss: 0.5889, Val Loss: 0.5741, Accuracy: 69.36%\n",
      "Final model accuracy on test set: 69.62%\n",
      "Accuracy 69.62% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6142, Val Loss: 0.5978, Accuracy: 68.05%\n",
      "Epoch [20/100], Loss: 0.6044, Val Loss: 0.5950, Accuracy: 67.73%\n",
      "Epoch [30/100], Loss: 0.6001, Val Loss: 0.5914, Accuracy: 68.44%\n",
      "Epoch [40/100], Loss: 0.5971, Val Loss: 0.5946, Accuracy: 68.44%\n",
      "Epoch [50/100], Loss: 0.5951, Val Loss: 0.5920, Accuracy: 68.12%\n",
      "Epoch [60/100], Loss: 0.5952, Val Loss: 0.5927, Accuracy: 68.12%\n",
      "Epoch [70/100], Loss: 0.5942, Val Loss: 0.5920, Accuracy: 67.93%\n",
      "Epoch [80/100], Loss: 0.5926, Val Loss: 0.5920, Accuracy: 68.12%\n",
      "Epoch [90/100], Loss: 0.5937, Val Loss: 0.5917, Accuracy: 68.18%\n",
      "Epoch [100/100], Loss: 0.5950, Val Loss: 0.5925, Accuracy: 68.31%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6089, Val Loss: 0.6049, Accuracy: 66.90%\n",
      "Epoch [20/100], Loss: 0.6070, Val Loss: 0.6012, Accuracy: 67.41%\n",
      "Epoch [30/100], Loss: 0.6000, Val Loss: 0.6034, Accuracy: 67.61%\n",
      "Epoch [40/100], Loss: 0.5964, Val Loss: 0.5999, Accuracy: 67.35%\n",
      "Epoch [50/100], Loss: 0.5923, Val Loss: 0.6004, Accuracy: 67.48%\n",
      "Epoch [60/100], Loss: 0.5937, Val Loss: 0.6004, Accuracy: 67.54%\n",
      "Epoch [70/100], Loss: 0.5917, Val Loss: 0.6005, Accuracy: 67.54%\n",
      "Epoch [80/100], Loss: 0.5915, Val Loss: 0.6006, Accuracy: 67.41%\n",
      "Epoch [90/100], Loss: 0.5938, Val Loss: 0.6002, Accuracy: 67.35%\n",
      "Epoch [100/100], Loss: 0.5907, Val Loss: 0.6000, Accuracy: 67.22%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6118, Val Loss: 0.6056, Accuracy: 65.66%\n",
      "Epoch [20/100], Loss: 0.6005, Val Loss: 0.6022, Accuracy: 65.79%\n",
      "Epoch [30/100], Loss: 0.5981, Val Loss: 0.5996, Accuracy: 66.37%\n",
      "Epoch [40/100], Loss: 0.5931, Val Loss: 0.6009, Accuracy: 66.24%\n",
      "Epoch [50/100], Loss: 0.5880, Val Loss: 0.5983, Accuracy: 66.18%\n",
      "Epoch [60/100], Loss: 0.5919, Val Loss: 0.5985, Accuracy: 66.05%\n",
      "Epoch [70/100], Loss: 0.5913, Val Loss: 0.5985, Accuracy: 66.11%\n",
      "Epoch [80/100], Loss: 0.5884, Val Loss: 0.5989, Accuracy: 65.66%\n",
      "Epoch [90/100], Loss: 0.5916, Val Loss: 0.5986, Accuracy: 65.79%\n",
      "Epoch [100/100], Loss: 0.5915, Val Loss: 0.5985, Accuracy: 65.73%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6095, Val Loss: 0.5963, Accuracy: 67.46%\n",
      "Epoch [20/100], Loss: 0.6019, Val Loss: 0.5970, Accuracy: 66.50%\n",
      "Epoch [30/100], Loss: 0.5982, Val Loss: 0.5949, Accuracy: 66.62%\n",
      "Epoch [40/100], Loss: 0.5956, Val Loss: 0.5956, Accuracy: 67.39%\n",
      "Epoch [50/100], Loss: 0.5948, Val Loss: 0.5957, Accuracy: 67.26%\n",
      "Epoch [60/100], Loss: 0.5990, Val Loss: 0.5956, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5962, Val Loss: 0.5958, Accuracy: 67.26%\n",
      "Epoch [80/100], Loss: 0.5952, Val Loss: 0.5957, Accuracy: 67.07%\n",
      "Epoch [90/100], Loss: 0.6017, Val Loss: 0.5958, Accuracy: 67.84%\n",
      "Epoch [100/100], Loss: 0.5947, Val Loss: 0.5957, Accuracy: 67.52%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6120, Val Loss: 0.5991, Accuracy: 67.97%\n",
      "Epoch [20/100], Loss: 0.6023, Val Loss: 0.5982, Accuracy: 67.71%\n",
      "Epoch [30/100], Loss: 0.5984, Val Loss: 0.5965, Accuracy: 67.58%\n",
      "Epoch [40/100], Loss: 0.5951, Val Loss: 0.5967, Accuracy: 67.46%\n",
      "Epoch [50/100], Loss: 0.5975, Val Loss: 0.5966, Accuracy: 68.10%\n",
      "Epoch [60/100], Loss: 0.5934, Val Loss: 0.5968, Accuracy: 67.71%\n",
      "Epoch [70/100], Loss: 0.5968, Val Loss: 0.5969, Accuracy: 67.52%\n",
      "Epoch [80/100], Loss: 0.5954, Val Loss: 0.5967, Accuracy: 67.84%\n",
      "Epoch [90/100], Loss: 0.5923, Val Loss: 0.5963, Accuracy: 67.84%\n",
      "Epoch [100/100], Loss: 0.5950, Val Loss: 0.5963, Accuracy: 67.91%\n",
      "Best cross-validated accuracy: 69.01%\n",
      "Epoch [10/100], Loss: 0.5962, Val Loss: 0.5756, Accuracy: 69.26%\n",
      "Epoch [20/100], Loss: 0.5925, Val Loss: 0.5777, Accuracy: 68.65%\n",
      "Epoch [30/100], Loss: 0.5886, Val Loss: 0.5748, Accuracy: 68.90%\n",
      "Epoch [40/100], Loss: 0.5862, Val Loss: 0.5754, Accuracy: 68.55%\n",
      "Epoch [50/100], Loss: 0.5905, Val Loss: 0.5758, Accuracy: 68.65%\n",
      "Epoch [60/100], Loss: 0.5859, Val Loss: 0.5752, Accuracy: 68.39%\n",
      "Epoch [70/100], Loss: 0.5859, Val Loss: 0.5750, Accuracy: 69.26%\n",
      "Epoch [80/100], Loss: 0.5859, Val Loss: 0.5750, Accuracy: 69.21%\n",
      "Epoch [90/100], Loss: 0.5884, Val Loss: 0.5751, Accuracy: 68.60%\n",
      "Epoch [100/100], Loss: 0.5856, Val Loss: 0.5748, Accuracy: 69.21%\n",
      "Final model accuracy on test set: 69.52%\n",
      "Accuracy 69.52% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6157, Val Loss: 0.5968, Accuracy: 67.86%\n",
      "Epoch [20/100], Loss: 0.6044, Val Loss: 0.5931, Accuracy: 68.37%\n",
      "Epoch [30/100], Loss: 0.6018, Val Loss: 0.5917, Accuracy: 68.31%\n",
      "Epoch [40/100], Loss: 0.5976, Val Loss: 0.5936, Accuracy: 68.18%\n",
      "Epoch [50/100], Loss: 0.5930, Val Loss: 0.5937, Accuracy: 67.54%\n",
      "Epoch [60/100], Loss: 0.5952, Val Loss: 0.5895, Accuracy: 68.12%\n",
      "Epoch [70/100], Loss: 0.5856, Val Loss: 0.5925, Accuracy: 67.41%\n",
      "Epoch [80/100], Loss: 0.5859, Val Loss: 0.5913, Accuracy: 67.86%\n",
      "Epoch [90/100], Loss: 0.5896, Val Loss: 0.5908, Accuracy: 67.67%\n",
      "Epoch [100/100], Loss: 0.5889, Val Loss: 0.5907, Accuracy: 67.86%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6051, Val Loss: 0.6108, Accuracy: 65.88%\n",
      "Epoch [20/100], Loss: 0.5993, Val Loss: 0.6004, Accuracy: 67.03%\n",
      "Epoch [30/100], Loss: 0.5968, Val Loss: 0.6025, Accuracy: 67.09%\n",
      "Epoch [40/100], Loss: 0.5946, Val Loss: 0.6006, Accuracy: 67.48%\n",
      "Epoch [50/100], Loss: 0.5885, Val Loss: 0.6014, Accuracy: 66.97%\n",
      "Epoch [60/100], Loss: 0.5938, Val Loss: 0.6007, Accuracy: 67.61%\n",
      "Epoch [70/100], Loss: 0.5936, Val Loss: 0.6004, Accuracy: 67.41%\n",
      "Epoch [80/100], Loss: 0.5928, Val Loss: 0.6007, Accuracy: 67.67%\n",
      "Epoch [90/100], Loss: 0.5918, Val Loss: 0.6007, Accuracy: 67.35%\n",
      "Epoch [100/100], Loss: 0.5939, Val Loss: 0.6006, Accuracy: 67.41%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6059, Val Loss: 0.6075, Accuracy: 66.37%\n",
      "Epoch [20/100], Loss: 0.6017, Val Loss: 0.6028, Accuracy: 66.30%\n",
      "Epoch [30/100], Loss: 0.5992, Val Loss: 0.5999, Accuracy: 66.30%\n",
      "Epoch [40/100], Loss: 0.5961, Val Loss: 0.6004, Accuracy: 66.05%\n",
      "Epoch [50/100], Loss: 0.5922, Val Loss: 0.6025, Accuracy: 65.66%\n",
      "Epoch [60/100], Loss: 0.5887, Val Loss: 0.5998, Accuracy: 66.37%\n",
      "Epoch [70/100], Loss: 0.5868, Val Loss: 0.5991, Accuracy: 66.11%\n",
      "Epoch [80/100], Loss: 0.5875, Val Loss: 0.5990, Accuracy: 66.24%\n",
      "Epoch [90/100], Loss: 0.5878, Val Loss: 0.5990, Accuracy: 65.92%\n",
      "Epoch [100/100], Loss: 0.5869, Val Loss: 0.5993, Accuracy: 65.98%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6146, Val Loss: 0.5966, Accuracy: 67.20%\n",
      "Epoch [20/100], Loss: 0.6076, Val Loss: 0.5990, Accuracy: 66.82%\n",
      "Epoch [30/100], Loss: 0.5994, Val Loss: 0.5960, Accuracy: 66.94%\n",
      "Epoch [40/100], Loss: 0.5992, Val Loss: 0.5954, Accuracy: 66.30%\n",
      "Epoch [50/100], Loss: 0.5971, Val Loss: 0.5957, Accuracy: 67.01%\n",
      "Epoch [60/100], Loss: 0.5993, Val Loss: 0.5955, Accuracy: 66.82%\n",
      "Epoch [70/100], Loss: 0.5962, Val Loss: 0.5956, Accuracy: 66.30%\n",
      "Epoch [80/100], Loss: 0.5952, Val Loss: 0.5956, Accuracy: 66.82%\n",
      "Epoch [90/100], Loss: 0.5993, Val Loss: 0.5955, Accuracy: 66.24%\n",
      "Epoch [100/100], Loss: 0.5966, Val Loss: 0.5958, Accuracy: 66.94%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6135, Val Loss: 0.5996, Accuracy: 67.20%\n",
      "Epoch [20/100], Loss: 0.6018, Val Loss: 0.5947, Accuracy: 67.97%\n",
      "Epoch [30/100], Loss: 0.5974, Val Loss: 0.5988, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5950, Val Loss: 0.5967, Accuracy: 66.56%\n",
      "Epoch [50/100], Loss: 0.5954, Val Loss: 0.5963, Accuracy: 66.50%\n",
      "Epoch [60/100], Loss: 0.5955, Val Loss: 0.5960, Accuracy: 67.46%\n",
      "Epoch [70/100], Loss: 0.5913, Val Loss: 0.5959, Accuracy: 67.39%\n",
      "Epoch [80/100], Loss: 0.5927, Val Loss: 0.5964, Accuracy: 66.88%\n",
      "Epoch [90/100], Loss: 0.5926, Val Loss: 0.5967, Accuracy: 66.69%\n",
      "Epoch [100/100], Loss: 0.5936, Val Loss: 0.5962, Accuracy: 66.94%\n",
      "Best cross-validated accuracy: 68.57%\n",
      "Epoch [10/100], Loss: 0.5927, Val Loss: 0.5768, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5880, Val Loss: 0.5778, Accuracy: 68.29%\n",
      "Epoch [30/100], Loss: 0.5869, Val Loss: 0.5778, Accuracy: 69.16%\n",
      "Epoch [40/100], Loss: 0.5852, Val Loss: 0.5774, Accuracy: 69.06%\n",
      "Epoch [50/100], Loss: 0.5818, Val Loss: 0.5772, Accuracy: 68.70%\n",
      "Epoch [60/100], Loss: 0.5849, Val Loss: 0.5774, Accuracy: 68.90%\n",
      "Epoch [70/100], Loss: 0.5833, Val Loss: 0.5769, Accuracy: 68.70%\n",
      "Epoch [80/100], Loss: 0.5860, Val Loss: 0.5779, Accuracy: 69.31%\n",
      "Epoch [90/100], Loss: 0.5820, Val Loss: 0.5773, Accuracy: 69.26%\n",
      "Epoch [100/100], Loss: 0.5830, Val Loss: 0.5775, Accuracy: 68.95%\n",
      "Final model accuracy on test set: 69.47%\n",
      "Accuracy 69.47% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6131, Val Loss: 0.5986, Accuracy: 67.73%\n",
      "Epoch [20/100], Loss: 0.6026, Val Loss: 0.5943, Accuracy: 68.12%\n",
      "Epoch [30/100], Loss: 0.5972, Val Loss: 0.5931, Accuracy: 68.05%\n",
      "Epoch [40/100], Loss: 0.5932, Val Loss: 0.5925, Accuracy: 67.86%\n",
      "Epoch [50/100], Loss: 0.5932, Val Loss: 0.5924, Accuracy: 67.93%\n",
      "Epoch [60/100], Loss: 0.5963, Val Loss: 0.5928, Accuracy: 67.73%\n",
      "Epoch [70/100], Loss: 0.5954, Val Loss: 0.5925, Accuracy: 67.54%\n",
      "Epoch [80/100], Loss: 0.5944, Val Loss: 0.5924, Accuracy: 67.73%\n",
      "Epoch [90/100], Loss: 0.5935, Val Loss: 0.5928, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5944, Val Loss: 0.5923, Accuracy: 67.86%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6171, Val Loss: 0.6081, Accuracy: 65.94%\n",
      "Epoch [20/100], Loss: 0.6012, Val Loss: 0.6035, Accuracy: 67.09%\n",
      "Epoch [30/100], Loss: 0.6015, Val Loss: 0.6007, Accuracy: 66.52%\n",
      "Epoch [40/100], Loss: 0.5916, Val Loss: 0.6002, Accuracy: 66.58%\n",
      "Epoch [50/100], Loss: 0.5928, Val Loss: 0.6013, Accuracy: 67.29%\n",
      "Epoch [60/100], Loss: 0.5885, Val Loss: 0.6015, Accuracy: 66.90%\n",
      "Epoch [70/100], Loss: 0.5907, Val Loss: 0.6020, Accuracy: 66.77%\n",
      "Epoch [80/100], Loss: 0.5901, Val Loss: 0.6017, Accuracy: 66.65%\n",
      "Epoch [90/100], Loss: 0.5881, Val Loss: 0.6014, Accuracy: 67.03%\n",
      "Epoch [100/100], Loss: 0.5902, Val Loss: 0.6018, Accuracy: 66.90%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6116, Val Loss: 0.6057, Accuracy: 65.73%\n",
      "Epoch [20/100], Loss: 0.6013, Val Loss: 0.6023, Accuracy: 66.24%\n",
      "Epoch [30/100], Loss: 0.5981, Val Loss: 0.6008, Accuracy: 66.30%\n",
      "Epoch [40/100], Loss: 0.5967, Val Loss: 0.6000, Accuracy: 65.98%\n",
      "Epoch [50/100], Loss: 0.5913, Val Loss: 0.5985, Accuracy: 66.50%\n",
      "Epoch [60/100], Loss: 0.5923, Val Loss: 0.5987, Accuracy: 66.62%\n",
      "Epoch [70/100], Loss: 0.5890, Val Loss: 0.5985, Accuracy: 66.18%\n",
      "Epoch [80/100], Loss: 0.5904, Val Loss: 0.5984, Accuracy: 66.24%\n",
      "Epoch [90/100], Loss: 0.5895, Val Loss: 0.5984, Accuracy: 66.69%\n",
      "Epoch [100/100], Loss: 0.5876, Val Loss: 0.5983, Accuracy: 66.82%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6094, Val Loss: 0.5946, Accuracy: 66.94%\n",
      "Epoch [20/100], Loss: 0.6036, Val Loss: 0.5933, Accuracy: 66.94%\n",
      "Epoch [30/100], Loss: 0.5985, Val Loss: 0.5961, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5989, Val Loss: 0.5940, Accuracy: 67.01%\n",
      "Epoch [50/100], Loss: 0.5978, Val Loss: 0.5940, Accuracy: 66.94%\n",
      "Epoch [60/100], Loss: 0.5978, Val Loss: 0.5942, Accuracy: 67.20%\n",
      "Epoch [70/100], Loss: 0.5949, Val Loss: 0.5940, Accuracy: 67.01%\n",
      "Epoch [80/100], Loss: 0.5986, Val Loss: 0.5940, Accuracy: 66.62%\n",
      "Epoch [90/100], Loss: 0.5939, Val Loss: 0.5944, Accuracy: 67.39%\n",
      "Epoch [100/100], Loss: 0.5952, Val Loss: 0.5940, Accuracy: 67.26%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6091, Val Loss: 0.5998, Accuracy: 67.65%\n",
      "Epoch [20/100], Loss: 0.6021, Val Loss: 0.5971, Accuracy: 67.84%\n",
      "Epoch [30/100], Loss: 0.5995, Val Loss: 0.5968, Accuracy: 67.52%\n",
      "Epoch [40/100], Loss: 0.5951, Val Loss: 0.5971, Accuracy: 67.78%\n",
      "Epoch [50/100], Loss: 0.5930, Val Loss: 0.5971, Accuracy: 68.03%\n",
      "Epoch [60/100], Loss: 0.5915, Val Loss: 0.5969, Accuracy: 67.78%\n",
      "Epoch [70/100], Loss: 0.5943, Val Loss: 0.5971, Accuracy: 68.03%\n",
      "Epoch [80/100], Loss: 0.5862, Val Loss: 0.5969, Accuracy: 67.71%\n",
      "Epoch [90/100], Loss: 0.5893, Val Loss: 0.5969, Accuracy: 68.03%\n",
      "Epoch [100/100], Loss: 0.5911, Val Loss: 0.5973, Accuracy: 67.71%\n",
      "Best cross-validated accuracy: 68.63%\n",
      "Epoch [10/100], Loss: 0.5979, Val Loss: 0.5761, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5962, Val Loss: 0.5769, Accuracy: 68.95%\n",
      "Epoch [30/100], Loss: 0.5910, Val Loss: 0.5766, Accuracy: 68.90%\n",
      "Epoch [40/100], Loss: 0.5933, Val Loss: 0.5763, Accuracy: 69.47%\n",
      "Epoch [50/100], Loss: 0.5872, Val Loss: 0.5752, Accuracy: 69.16%\n",
      "Epoch [60/100], Loss: 0.5858, Val Loss: 0.5751, Accuracy: 69.11%\n",
      "Epoch [70/100], Loss: 0.5863, Val Loss: 0.5754, Accuracy: 69.26%\n",
      "Epoch [80/100], Loss: 0.5833, Val Loss: 0.5756, Accuracy: 69.21%\n",
      "Epoch [90/100], Loss: 0.5866, Val Loss: 0.5745, Accuracy: 68.85%\n",
      "Epoch [100/100], Loss: 0.5840, Val Loss: 0.5758, Accuracy: 68.95%\n",
      "Final model accuracy on test set: 69.62%\n",
      "Accuracy 69.62% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6104, Val Loss: 0.5985, Accuracy: 67.67%\n",
      "Epoch [20/100], Loss: 0.6076, Val Loss: 0.5938, Accuracy: 67.99%\n",
      "Epoch [30/100], Loss: 0.5973, Val Loss: 0.5939, Accuracy: 67.86%\n",
      "Epoch [40/100], Loss: 0.5965, Val Loss: 0.5954, Accuracy: 67.93%\n",
      "Epoch [50/100], Loss: 0.5928, Val Loss: 0.5905, Accuracy: 67.41%\n",
      "Epoch [60/100], Loss: 0.5900, Val Loss: 0.5914, Accuracy: 67.54%\n",
      "Epoch [70/100], Loss: 0.5926, Val Loss: 0.5916, Accuracy: 67.41%\n",
      "Epoch [80/100], Loss: 0.5883, Val Loss: 0.5915, Accuracy: 67.54%\n",
      "Epoch [90/100], Loss: 0.5877, Val Loss: 0.5916, Accuracy: 67.48%\n",
      "Epoch [100/100], Loss: 0.5879, Val Loss: 0.5915, Accuracy: 67.41%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6102, Val Loss: 0.6066, Accuracy: 66.65%\n",
      "Epoch [20/100], Loss: 0.6012, Val Loss: 0.6067, Accuracy: 66.45%\n",
      "Epoch [30/100], Loss: 0.5980, Val Loss: 0.6015, Accuracy: 66.97%\n",
      "Epoch [40/100], Loss: 0.5948, Val Loss: 0.6026, Accuracy: 67.22%\n",
      "Epoch [50/100], Loss: 0.5898, Val Loss: 0.6014, Accuracy: 66.97%\n",
      "Epoch [60/100], Loss: 0.5914, Val Loss: 0.6018, Accuracy: 66.97%\n",
      "Epoch [70/100], Loss: 0.5896, Val Loss: 0.6020, Accuracy: 66.77%\n",
      "Epoch [80/100], Loss: 0.5898, Val Loss: 0.6029, Accuracy: 67.09%\n",
      "Epoch [90/100], Loss: 0.5918, Val Loss: 0.6017, Accuracy: 67.29%\n",
      "Epoch [100/100], Loss: 0.5908, Val Loss: 0.6033, Accuracy: 66.71%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6117, Val Loss: 0.6058, Accuracy: 65.79%\n",
      "Epoch [20/100], Loss: 0.6018, Val Loss: 0.6029, Accuracy: 66.43%\n",
      "Epoch [30/100], Loss: 0.5967, Val Loss: 0.6000, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5942, Val Loss: 0.5987, Accuracy: 65.53%\n",
      "Epoch [50/100], Loss: 0.5936, Val Loss: 0.6005, Accuracy: 65.73%\n",
      "Epoch [60/100], Loss: 0.5912, Val Loss: 0.5985, Accuracy: 66.24%\n",
      "Epoch [70/100], Loss: 0.5916, Val Loss: 0.5985, Accuracy: 66.24%\n",
      "Epoch [80/100], Loss: 0.5877, Val Loss: 0.5987, Accuracy: 66.18%\n",
      "Epoch [90/100], Loss: 0.5907, Val Loss: 0.5988, Accuracy: 66.11%\n",
      "Epoch [100/100], Loss: 0.5870, Val Loss: 0.5988, Accuracy: 66.18%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6143, Val Loss: 0.5980, Accuracy: 66.43%\n",
      "Epoch [20/100], Loss: 0.6016, Val Loss: 0.5938, Accuracy: 66.82%\n",
      "Epoch [30/100], Loss: 0.5994, Val Loss: 0.5955, Accuracy: 67.33%\n",
      "Epoch [40/100], Loss: 0.5977, Val Loss: 0.5946, Accuracy: 67.46%\n",
      "Epoch [50/100], Loss: 0.5956, Val Loss: 0.5945, Accuracy: 67.39%\n",
      "Epoch [60/100], Loss: 0.5966, Val Loss: 0.5948, Accuracy: 67.78%\n",
      "Epoch [70/100], Loss: 0.5960, Val Loss: 0.5946, Accuracy: 67.39%\n",
      "Epoch [80/100], Loss: 0.5948, Val Loss: 0.5946, Accuracy: 67.58%\n",
      "Epoch [90/100], Loss: 0.5974, Val Loss: 0.5943, Accuracy: 67.65%\n",
      "Epoch [100/100], Loss: 0.5973, Val Loss: 0.5940, Accuracy: 67.26%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6069, Val Loss: 0.5986, Accuracy: 67.58%\n",
      "Epoch [20/100], Loss: 0.5994, Val Loss: 0.5959, Accuracy: 68.16%\n",
      "Epoch [30/100], Loss: 0.5960, Val Loss: 0.5958, Accuracy: 67.71%\n",
      "Epoch [40/100], Loss: 0.5881, Val Loss: 0.5965, Accuracy: 68.10%\n",
      "Epoch [50/100], Loss: 0.5936, Val Loss: 0.5962, Accuracy: 67.91%\n",
      "Epoch [60/100], Loss: 0.5956, Val Loss: 0.5965, Accuracy: 67.91%\n",
      "Epoch [70/100], Loss: 0.5971, Val Loss: 0.5970, Accuracy: 67.91%\n",
      "Epoch [80/100], Loss: 0.5926, Val Loss: 0.5966, Accuracy: 67.91%\n",
      "Epoch [90/100], Loss: 0.5905, Val Loss: 0.5966, Accuracy: 68.03%\n",
      "Epoch [100/100], Loss: 0.5931, Val Loss: 0.5967, Accuracy: 67.91%\n",
      "Best cross-validated accuracy: 68.69%\n",
      "Epoch [10/100], Loss: 0.5968, Val Loss: 0.5785, Accuracy: 69.11%\n",
      "Epoch [20/100], Loss: 0.5935, Val Loss: 0.5748, Accuracy: 69.67%\n",
      "Final model accuracy on test set: 69.93%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == .5).any(axis=1)]\n",
    "# df = df[~(df == -20).any(axis=1)]\n",
    "# df = df[(df['surface_Hard'] == 1.0)]\n",
    "\n",
    "# df = df.drop(df.columns[df.columns.str.contains('_rd')], axis=1)\n",
    "\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set target accuracy\n",
    "target_accuracy = 0.699\n",
    "\n",
    "final_acc = 0.0\n",
    "while final_acc < target_accuracy:\n",
    "    best_acc, best_model_weights = cross_validate(OutcomeProbabilityV6, X_train, y_train, epochs=100, target_accuracy=target_accuracy)\n",
    "    print(f\"Best cross-validated accuracy: {best_acc*100:.2f}%\")\n",
    "\n",
    "    # Final training on full training data\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    val_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = OutcomeProbabilityV6(input_dim=X.shape[1])\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    final_acc, _ = train_and_evaluate(model, train_loader, val_loader, epochs=100, target_accuracy=target_accuracy)\n",
    "    print(f\"Final model accuracy on test set: {final_acc*100:.2f}%\")\n",
    "\n",
    "    if final_acc < target_accuracy:\n",
    "        print(f\"Accuracy {final_acc*100:.2f}% not met, restarting the process.\")\n",
    "    # Quick train break\n",
    "    # break\n",
    "\n",
    "# Evaluate and store predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_test_np = y_test_tensor.numpy()\n",
    "    odds_test = odds_df.loc[idx_test].values\n",
    "\n",
    "    # Create DataFrame with predictions and actual values\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test_np.flatten(),\n",
    "        'Predicted': y_pred.flatten(),\n",
    "        'A_Odds': odds_test[:, 0],\n",
    "        'B_Odds': odds_test[:, 1]\n",
    "    })\n",
    "\n",
    "    # Optionally save to CSV\n",
    "    results_df.to_csv('predictions_with_odds.csv', index=False)\n",
    "\n",
    "# Plot ROC curve\n",
    "with torch.no_grad():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_tensor, y_pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  A_Odds  B_Odds\n",
      "0        0.0   0.472227    1.53    2.45\n",
      "1        0.0   0.697720    1.63    2.25\n",
      "2        0.0   0.406320    2.76    1.42\n",
      "3        1.0   0.761667    1.19    4.53\n",
      "4        0.0   0.466682    2.78    1.43\n",
      "...      ...        ...     ...     ...\n",
      "1947     0.0   0.310614    3.03    1.36\n",
      "1948     1.0   0.488794    1.58    2.33\n",
      "1949     0.0   0.728144    1.33    3.24\n",
      "1950     1.0   0.784030    1.36    3.12\n",
      "1951     0.0   0.469624    3.10    1.36\n",
      "\n",
      "[1952 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    corrected = vegas_odds - 1\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = calculated_probability - ((1 - calculated_probability)/corrected)\n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total returned on Starting $10 bankroll: 9.74 on a total # bets: 116 from a total of 1952 games\n",
      "ROI : -0.0 X\n",
      "Avg Bankroll Bet % : 0.244 %\n",
      "Amount of differing favorites %: 0.119\n",
      "Amount of upset bets correct % : 0.502 with Unit $10 won $55.78 on 203 bets\n",
      "Amount of incorrect bet % : 0.1552\n",
      "Correct Bet %: 0.8448\n",
      "Model % Correct : 0.6993 Vegas Correct % : 0.6988\n"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "avg_bet = 0\n",
    "\n",
    "confidence_pct = .8\n",
    "confidence_top_pct = 1\n",
    "\n",
    "START_UNIT = 10\n",
    "UNIT = START_UNIT\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "    current = START_UNIT\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :\n",
    "        kelly = (kelly_criterion(row['A_Odds'], row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['A_Odds'], row['Predicted'])\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['A_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :\n",
    "        kelly = (kelly_criterion(row['B_Odds'], 1-row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['B_Odds'], 1-row['Predicted'])\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['B_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        kelly_A  = (kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        kelly_B  = (kelly_criterion(row['B_Odds'],1-row['Predicted']) * UNIT)\n",
    "\n",
    "        upset_predict += 1 if (kelly_A > 0 and round(row['Predicted']) == 1) or (kelly_B > 0 and round(row['Predicted']) == 0) else 0\n",
    "\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_correct += 1 if kelly_A > 0 else 0\n",
    "                upset_won += (row['A_Odds']-1) * kelly_A\n",
    "            else:\n",
    "                upset_correct += 1 if kelly_B > 0 else 0\n",
    "                upset_won += (row['B_Odds']-1) * kelly_B\n",
    "        elif round(row['Predicted']) == 1:\n",
    "            upset_won -= kelly_A\n",
    "        else:\n",
    "            upset_won -= kelly_B\n",
    "            \n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total returned on Starting ${UNIT} bankroll: {START_UNIT:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"ROI : {((START_UNIT-UNIT)/UNIT):.1f} X\")\n",
    "print(f\"Avg Bankroll Bet % : {(avg_bet/better):.3f} %\")\n",
    "print(f\"Amount of differing favorites %: {(diff_fav/length):.3f}\")\n",
    "print(f\"Amount of upset bets correct % : {(upset_correct/upset_predict):.3f} with Unit ${UNIT} won ${upset_won:.2f} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bet % : {(wrong/better):.4f}\")\n",
    "print(f\"Correct Bet %: {(bet_correct/better):.4f}\")\n",
    "print(f\"Model % Correct : {(model_correct/length):.4f} Vegas Correct % : {(vegas_correct/length):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
