{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20120101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32483\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "RD_CUTOFF = 125\n",
    "\n",
    "df = pd.read_csv('../testcsvs/glickoUpdatedTest.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "df = df[(df['a_surface_glicko_rd'] <= RD_CUTOFF) & (df['b_surface_glicko_rd'] <= RD_CUTOFF) & (df['a_glicko_rd'] <= RD_CUTOFF) & (df['b_glicko_rd'] <= RD_CUTOFF)]\n",
    "\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_age</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>a_player_rank_points</th>\n",
       "      <th>b_player_age</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>b_player_rank_points</th>\n",
       "      <th>rank_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_second_won_glicko_rd</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1509.676357</td>\n",
       "      <td>1525.177533</td>\n",
       "      <td>64.968960</td>\n",
       "      <td>61.353283</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1493.441526</td>\n",
       "      <td>1520.481105</td>\n",
       "      <td>70.605742</td>\n",
       "      <td>62.024125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1506.545429</td>\n",
       "      <td>1507.882055</td>\n",
       "      <td>65.145579</td>\n",
       "      <td>63.927775</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1534.732931</td>\n",
       "      <td>1517.206849</td>\n",
       "      <td>62.140547</td>\n",
       "      <td>62.872428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1535.923504</td>\n",
       "      <td>1494.807275</td>\n",
       "      <td>62.904123</td>\n",
       "      <td>66.485111</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  tourney_level  tourney_round  a_player_age  a_player_rank  \\\n",
       "5373      3.0            2.0            0.8          28.0           74.0   \n",
       "5375      3.0            2.0            0.8          25.0           46.0   \n",
       "5378      3.0            2.0            0.8          26.0           83.0   \n",
       "5381      3.0            2.0            0.8          27.0           38.0   \n",
       "5382      3.0            2.0            0.8          27.0           38.0   \n",
       "\n",
       "      a_player_rank_points  b_player_age  b_player_rank  b_player_rank_points  \\\n",
       "5373                 671.0          23.0           15.0                1925.0   \n",
       "5375                 920.0          28.0           65.0                 755.0   \n",
       "5378                 640.0          24.0           48.0                 915.0   \n",
       "5381                1015.0          28.0           65.0                 755.0   \n",
       "5382                1015.0          29.0           57.0                 828.0   \n",
       "\n",
       "      rank_diff  ...  a_surface_return_second_won_glicko_rating  \\\n",
       "5373       59.0  ...                                1509.676357   \n",
       "5375      -19.0  ...                                1493.441526   \n",
       "5378       35.0  ...                                1506.545429   \n",
       "5381      -27.0  ...                                1534.732931   \n",
       "5382      -19.0  ...                                1535.923504   \n",
       "\n",
       "      b_surface_second_won_glicko_rating  \\\n",
       "5373                         1525.177533   \n",
       "5375                         1520.481105   \n",
       "5378                         1507.882055   \n",
       "5381                         1517.206849   \n",
       "5382                         1494.807275   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rd  b_surface_second_won_glicko_rd  \\\n",
       "5373                              64.968960                       61.353283   \n",
       "5375                              70.605742                       62.024125   \n",
       "5378                              65.145579                       63.927775   \n",
       "5381                              62.140547                       62.872428   \n",
       "5382                              62.904123                       66.485111   \n",
       "\n",
       "      a_odds  b_odds  a_b_win  surface_Clay  surface_Grass  surface_Hard  \n",
       "5373    3.59    1.28      0.0           0.0            0.0           1.0  \n",
       "5375     NaN     NaN      0.0           0.0            0.0           1.0  \n",
       "5378    1.54    2.40      1.0           0.0            0.0           1.0  \n",
       "5381     NaN     NaN      1.0           0.0            0.0           1.0  \n",
       "5382    1.56    2.34      1.0           0.0            0.0           1.0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.shortcut = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn(self.fc(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "class OutcomeProbabilityV6(nn.Module):\n",
    "    def __init__(self, input_dim=172, dropout_prob=0.33):\n",
    "        hidden_dim1=input_dim * 2\n",
    "        hidden_dim2=input_dim\n",
    "        hidden_dim3=round(input_dim/2) \n",
    "        super(OutcomeProbabilityV6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(hidden_dim1, hidden_dim1)\n",
    "        self.res_block2 = ResidualBlock(hidden_dim1, hidden_dim2)\n",
    "        self.res_block3 = ResidualBlock(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        \n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, epochs=100, learning_rate=0.0001, weight_decay=1e-5, target_auc=0.75):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    best_auc = -np.inf\n",
    "    best_weights = None\n",
    "    early_stopping_patience = 20\n",
    "    early_stopping_counter = 0\n",
    "    current_epoch = 0\n",
    "    best_acc = 0.0\n",
    "\n",
    "    while best_auc < target_auc and current_epoch < epochs:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                y_pred = model(X_batch)\n",
    "                val_loss += loss_fn(y_pred, y_batch).item() * X_batch.size(0)\n",
    "                all_preds.append(y_pred.numpy())\n",
    "                all_labels.append(y_batch.numpy())\n",
    "                predicted = y_pred.round()\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "        acc = correct / total\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if (current_epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{current_epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, AUC: {auc:.4f}, Accuracy: {acc*100:.2f}%')\n",
    "\n",
    "        current_epoch += 1\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_auc, best_acc, best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model_class, X, y, k=5, epochs=100, target_auc=0.75, learning_rate=0.0001, weight_decay=1e-5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    best_auc = -np.inf\n",
    "    best_model_weights = None\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        X_train_fold, y_train_fold = X[train_idx], y[train_idx]\n",
    "        X_val_fold, y_val_fold = X[val_idx], y[val_idx]\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
    "        X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "        val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "        model = model_class(input_dim=X.shape[1])\n",
    "        auc, acc, model_weights = train_and_evaluate(model, train_loader, val_loader, epochs=epochs, learning_rate=learning_rate, weight_decay=weight_decay, target_auc=target_auc)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_acc = acc\n",
    "            best_model_weights = model_weights\n",
    "\n",
    "        print(f'Fold {fold + 1}/{k}, AUC: {auc:.4f}, Accuracy: {acc*100:.2f}%')\n",
    "\n",
    "    return best_auc, best_acc, best_model_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9936\n",
      "Fold 1/5, AUC: 0.8552, Accuracy: 76.54%\n",
      "Epoch [10/100], Loss: 0.5247, Val Loss: 0.6015, AUC: 0.7662, Accuracy: 67.90%\n",
      "Epoch [20/100], Loss: 0.5051, Val Loss: 0.6130, AUC: 0.7645, Accuracy: 67.49%\n",
      "Epoch [30/100], Loss: 0.4899, Val Loss: 0.6085, AUC: 0.7654, Accuracy: 68.31%\n",
      "Epoch [40/100], Loss: 0.5030, Val Loss: 0.6092, AUC: 0.7658, Accuracy: 68.31%\n",
      "Epoch [50/100], Loss: 0.4982, Val Loss: 0.6081, AUC: 0.7658, Accuracy: 67.90%\n",
      "Epoch [60/100], Loss: 0.5062, Val Loss: 0.6088, AUC: 0.7660, Accuracy: 68.31%\n",
      "Epoch [70/100], Loss: 0.4940, Val Loss: 0.6082, AUC: 0.7656, Accuracy: 68.31%\n",
      "Epoch [80/100], Loss: 0.4991, Val Loss: 0.6084, AUC: 0.7653, Accuracy: 68.31%\n",
      "Epoch [90/100], Loss: 0.5204, Val Loss: 0.6123, AUC: 0.7660, Accuracy: 68.31%\n",
      "Epoch [100/100], Loss: 0.5056, Val Loss: 0.6080, AUC: 0.7657, Accuracy: 67.90%\n",
      "Fold 2/5, AUC: 0.7671, Accuracy: 68.31%\n",
      "Epoch [10/100], Loss: 0.5265, Val Loss: 0.5068, AUC: 0.8248, Accuracy: 74.79%\n",
      "Fold 3/5, AUC: 0.8253, Accuracy: 74.38%\n",
      "Epoch [10/100], Loss: 0.5347, Val Loss: 0.5292, AUC: 0.8179, Accuracy: 73.97%\n",
      "Fold 4/5, AUC: 0.8251, Accuracy: 73.97%\n",
      "Epoch [10/100], Loss: 0.5251, Val Loss: 0.5744, AUC: 0.7693, Accuracy: 68.60%\n",
      "Epoch [20/100], Loss: 0.5195, Val Loss: 0.5777, AUC: 0.7729, Accuracy: 69.83%\n",
      "Epoch [30/100], Loss: 0.5197, Val Loss: 0.5775, AUC: 0.7735, Accuracy: 69.42%\n",
      "Epoch [40/100], Loss: 0.5187, Val Loss: 0.5752, AUC: 0.7736, Accuracy: 69.42%\n",
      "Epoch [50/100], Loss: 0.5150, Val Loss: 0.5775, AUC: 0.7738, Accuracy: 69.42%\n",
      "Epoch [60/100], Loss: 0.5093, Val Loss: 0.5762, AUC: 0.7735, Accuracy: 69.42%\n",
      "Epoch [70/100], Loss: 0.5106, Val Loss: 0.5760, AUC: 0.7736, Accuracy: 69.42%\n",
      "Epoch [80/100], Loss: 0.5224, Val Loss: 0.5773, AUC: 0.7730, Accuracy: 69.42%\n",
      "Epoch [90/100], Loss: 0.5048, Val Loss: 0.5772, AUC: 0.7736, Accuracy: 69.83%\n",
      "Epoch [100/100], Loss: 0.5139, Val Loss: 0.5758, AUC: 0.7737, Accuracy: 69.42%\n",
      "Fold 5/5, AUC: 0.7742, Accuracy: 69.42%\n",
      "Best cross-validated AUC: 0.8552\n",
      "Best cross-validated accuracy: 76.54%\n",
      "Epoch [10/100], Loss: 0.5366, Val Loss: 0.5288, AUC: 0.8191, Accuracy: 75.91%\n",
      "Epoch [20/100], Loss: 0.5192, Val Loss: 0.5261, AUC: 0.8232, Accuracy: 75.91%\n",
      "Epoch [30/100], Loss: 0.5100, Val Loss: 0.5287, AUC: 0.8215, Accuracy: 75.25%\n",
      "Epoch [40/100], Loss: 0.5090, Val Loss: 0.5305, AUC: 0.8210, Accuracy: 74.92%\n",
      "Epoch [50/100], Loss: 0.5037, Val Loss: 0.5300, AUC: 0.8215, Accuracy: 74.92%\n",
      "Epoch [60/100], Loss: 0.5106, Val Loss: 0.5300, AUC: 0.8215, Accuracy: 74.92%\n",
      "Epoch [70/100], Loss: 0.5072, Val Loss: 0.5300, AUC: 0.8215, Accuracy: 74.92%\n",
      "Epoch [80/100], Loss: 0.5176, Val Loss: 0.5301, AUC: 0.8217, Accuracy: 74.59%\n",
      "Epoch [90/100], Loss: 0.5234, Val Loss: 0.5292, AUC: 0.8221, Accuracy: 74.59%\n",
      "Epoch [100/100], Loss: 0.5056, Val Loss: 0.5302, AUC: 0.8218, Accuracy: 74.92%\n",
      "Final model AUC on test set: 0.8234\n",
      "Final model accuracy on test set: 75.91%\n",
      "AUC 0.8234 not met, restarting the process.\n",
      "Fold 1/5, AUC: 0.8357, Accuracy: 72.02%\n",
      "Epoch [10/100], Loss: 0.5169, Val Loss: 0.6015, AUC: 0.7609, Accuracy: 68.31%\n",
      "Epoch [20/100], Loss: 0.4986, Val Loss: 0.6059, AUC: 0.7601, Accuracy: 66.67%\n",
      "Epoch [30/100], Loss: 0.4915, Val Loss: 0.6043, AUC: 0.7630, Accuracy: 67.08%\n",
      "Epoch [40/100], Loss: 0.4932, Val Loss: 0.6059, AUC: 0.7661, Accuracy: 67.49%\n",
      "Epoch [50/100], Loss: 0.4834, Val Loss: 0.6080, AUC: 0.7683, Accuracy: 67.08%\n",
      "Epoch [60/100], Loss: 0.4939, Val Loss: 0.6003, AUC: 0.7681, Accuracy: 67.90%\n",
      "Epoch [70/100], Loss: 0.4894, Val Loss: 0.6016, AUC: 0.7679, Accuracy: 67.90%\n",
      "Epoch [80/100], Loss: 0.4842, Val Loss: 0.6055, AUC: 0.7687, Accuracy: 67.49%\n",
      "Epoch [90/100], Loss: 0.4857, Val Loss: 0.6053, AUC: 0.7689, Accuracy: 67.49%\n",
      "Epoch [100/100], Loss: 0.4845, Val Loss: 0.6086, AUC: 0.7687, Accuracy: 67.49%\n",
      "Fold 2/5, AUC: 0.7699, Accuracy: 67.49%\n",
      "Epoch [10/100], Loss: 0.5547, Val Loss: 0.5102, AUC: 0.8230, Accuracy: 74.38%\n",
      "Fold 3/5, AUC: 0.8262, Accuracy: 75.62%\n",
      "Fold 4/5, AUC: 0.8252, Accuracy: 75.62%\n",
      "Epoch [10/100], Loss: 0.5237, Val Loss: 0.5760, AUC: 0.7676, Accuracy: 69.01%\n",
      "Epoch [20/100], Loss: 0.5169, Val Loss: 0.5775, AUC: 0.7689, Accuracy: 70.25%\n",
      "Epoch [30/100], Loss: 0.5227, Val Loss: 0.5778, AUC: 0.7685, Accuracy: 69.42%\n",
      "Epoch [40/100], Loss: 0.5097, Val Loss: 0.5780, AUC: 0.7684, Accuracy: 70.25%\n",
      "Epoch [50/100], Loss: 0.5174, Val Loss: 0.5769, AUC: 0.7688, Accuracy: 70.25%\n",
      "Epoch [60/100], Loss: 0.5230, Val Loss: 0.5773, AUC: 0.7687, Accuracy: 70.25%\n",
      "Epoch [70/100], Loss: 0.5025, Val Loss: 0.5788, AUC: 0.7692, Accuracy: 69.83%\n",
      "Epoch [80/100], Loss: 0.5129, Val Loss: 0.5773, AUC: 0.7694, Accuracy: 70.25%\n",
      "Epoch [90/100], Loss: 0.5176, Val Loss: 0.5785, AUC: 0.7687, Accuracy: 69.83%\n",
      "Epoch [100/100], Loss: 0.5104, Val Loss: 0.5785, AUC: 0.7690, Accuracy: 69.83%\n",
      "Fold 5/5, AUC: 0.7698, Accuracy: 70.25%\n",
      "Best cross-validated AUC: 0.8357\n",
      "Best cross-validated accuracy: 72.02%\n",
      "Epoch [10/100], Loss: 0.5412, Val Loss: 0.5332, AUC: 0.8157, Accuracy: 75.58%\n",
      "Epoch [20/100], Loss: 0.5159, Val Loss: 0.5332, AUC: 0.8181, Accuracy: 75.25%\n",
      "Epoch [30/100], Loss: 0.5035, Val Loss: 0.5336, AUC: 0.8173, Accuracy: 75.25%\n",
      "Epoch [40/100], Loss: 0.5206, Val Loss: 0.5329, AUC: 0.8180, Accuracy: 75.25%\n",
      "Epoch [50/100], Loss: 0.5069, Val Loss: 0.5335, AUC: 0.8174, Accuracy: 74.92%\n",
      "Epoch [60/100], Loss: 0.5250, Val Loss: 0.5333, AUC: 0.8182, Accuracy: 74.92%\n",
      "Epoch [70/100], Loss: 0.5116, Val Loss: 0.5329, AUC: 0.8176, Accuracy: 75.25%\n",
      "Epoch [80/100], Loss: 0.5125, Val Loss: 0.5328, AUC: 0.8185, Accuracy: 74.92%\n",
      "Epoch [90/100], Loss: 0.5119, Val Loss: 0.5330, AUC: 0.8181, Accuracy: 74.92%\n",
      "Epoch [100/100], Loss: 0.5114, Val Loss: 0.5338, AUC: 0.8178, Accuracy: 74.92%\n",
      "Final model AUC on test set: 0.8201\n",
      "Final model accuracy on test set: 74.59%\n",
      "AUC 0.8201 not met, restarting the process.\n",
      "Fold 1/5, AUC: 0.8426, Accuracy: 76.13%\n",
      "Epoch [10/100], Loss: 0.5078, Val Loss: 0.5949, AUC: 0.7647, Accuracy: 68.31%\n",
      "Epoch [20/100], Loss: 0.5042, Val Loss: 0.5972, AUC: 0.7639, Accuracy: 67.08%\n",
      "Epoch [30/100], Loss: 0.5030, Val Loss: 0.6090, AUC: 0.7665, Accuracy: 67.49%\n",
      "Epoch [40/100], Loss: 0.4915, Val Loss: 0.6084, AUC: 0.7660, Accuracy: 67.49%\n",
      "Epoch [50/100], Loss: 0.5048, Val Loss: 0.6113, AUC: 0.7668, Accuracy: 67.49%\n",
      "Epoch [60/100], Loss: 0.5050, Val Loss: 0.6082, AUC: 0.7657, Accuracy: 67.49%\n",
      "Epoch [70/100], Loss: 0.5065, Val Loss: 0.6081, AUC: 0.7664, Accuracy: 67.90%\n",
      "Epoch [80/100], Loss: 0.5043, Val Loss: 0.6088, AUC: 0.7662, Accuracy: 67.49%\n",
      "Epoch [90/100], Loss: 0.4935, Val Loss: 0.6078, AUC: 0.7664, Accuracy: 67.49%\n",
      "Epoch [100/100], Loss: 0.5119, Val Loss: 0.6104, AUC: 0.7665, Accuracy: 67.49%\n",
      "Fold 2/5, AUC: 0.7668, Accuracy: 67.49%\n",
      "Fold 3/5, AUC: 0.8355, Accuracy: 71.90%\n",
      "Epoch [10/100], Loss: 0.5294, Val Loss: 0.5279, AUC: 0.8206, Accuracy: 75.21%\n",
      "Fold 4/5, AUC: 0.8254, Accuracy: 75.21%\n",
      "Epoch [10/100], Loss: 0.5399, Val Loss: 0.5686, AUC: 0.7769, Accuracy: 70.66%\n",
      "Epoch [20/100], Loss: 0.5172, Val Loss: 0.5747, AUC: 0.7752, Accuracy: 69.42%\n",
      "Epoch [30/100], Loss: 0.5143, Val Loss: 0.5722, AUC: 0.7765, Accuracy: 70.66%\n",
      "Epoch [40/100], Loss: 0.5147, Val Loss: 0.5718, AUC: 0.7770, Accuracy: 71.07%\n",
      "Epoch [50/100], Loss: 0.5130, Val Loss: 0.5709, AUC: 0.7775, Accuracy: 71.49%\n",
      "Epoch [60/100], Loss: 0.5192, Val Loss: 0.5707, AUC: 0.7776, Accuracy: 71.49%\n",
      "Epoch [70/100], Loss: 0.5122, Val Loss: 0.5716, AUC: 0.7770, Accuracy: 71.07%\n",
      "Epoch [80/100], Loss: 0.5151, Val Loss: 0.5717, AUC: 0.7770, Accuracy: 69.83%\n",
      "Epoch [90/100], Loss: 0.5137, Val Loss: 0.5719, AUC: 0.7768, Accuracy: 71.07%\n",
      "Epoch [100/100], Loss: 0.5081, Val Loss: 0.5723, AUC: 0.7765, Accuracy: 69.42%\n",
      "Fold 5/5, AUC: 0.7906, Accuracy: 60.74%\n",
      "Best cross-validated AUC: 0.8426\n",
      "Best cross-validated accuracy: 76.13%\n",
      "Epoch [10/100], Loss: 0.5367, Val Loss: 0.5399, AUC: 0.8104, Accuracy: 73.93%\n",
      "Epoch [20/100], Loss: 0.5306, Val Loss: 0.5359, AUC: 0.8146, Accuracy: 75.25%\n",
      "Epoch [30/100], Loss: 0.5145, Val Loss: 0.5373, AUC: 0.8136, Accuracy: 75.25%\n",
      "Epoch [40/100], Loss: 0.5128, Val Loss: 0.5373, AUC: 0.8153, Accuracy: 74.59%\n",
      "Epoch [50/100], Loss: 0.5120, Val Loss: 0.5368, AUC: 0.8154, Accuracy: 74.92%\n",
      "Epoch [60/100], Loss: 0.5128, Val Loss: 0.5366, AUC: 0.8152, Accuracy: 75.25%\n",
      "Epoch [70/100], Loss: 0.5119, Val Loss: 0.5369, AUC: 0.8154, Accuracy: 74.92%\n",
      "Epoch [80/100], Loss: 0.5067, Val Loss: 0.5364, AUC: 0.8153, Accuracy: 74.92%\n",
      "Epoch [90/100], Loss: 0.5154, Val Loss: 0.5374, AUC: 0.8154, Accuracy: 75.25%\n",
      "Epoch [100/100], Loss: 0.5120, Val Loss: 0.5365, AUC: 0.8157, Accuracy: 74.92%\n",
      "Final model AUC on test set: 0.8161\n",
      "Final model accuracy on test set: 75.25%\n",
      "AUC 0.8161 not met, restarting the process.\n",
      "Fold 1/5, AUC: 0.8491, Accuracy: 75.31%\n",
      "Epoch [10/100], Loss: 0.5168, Val Loss: 0.6018, AUC: 0.7667, Accuracy: 66.67%\n",
      "Epoch [20/100], Loss: 0.5056, Val Loss: 0.6129, AUC: 0.7653, Accuracy: 66.67%\n",
      "Epoch [30/100], Loss: 0.4968, Val Loss: 0.6086, AUC: 0.7655, Accuracy: 66.67%\n",
      "Epoch [40/100], Loss: 0.4921, Val Loss: 0.6082, AUC: 0.7649, Accuracy: 67.08%\n",
      "Epoch [50/100], Loss: 0.4992, Val Loss: 0.6108, AUC: 0.7657, Accuracy: 67.08%\n",
      "Epoch [60/100], Loss: 0.4929, Val Loss: 0.6090, AUC: 0.7651, Accuracy: 67.08%\n",
      "Epoch [70/100], Loss: 0.5059, Val Loss: 0.6091, AUC: 0.7654, Accuracy: 66.67%\n",
      "Epoch [80/100], Loss: 0.4924, Val Loss: 0.6129, AUC: 0.7658, Accuracy: 67.49%\n",
      "Epoch [90/100], Loss: 0.4912, Val Loss: 0.6095, AUC: 0.7653, Accuracy: 67.08%\n",
      "Epoch [100/100], Loss: 0.5026, Val Loss: 0.6103, AUC: 0.7653, Accuracy: 67.08%\n",
      "Fold 2/5, AUC: 0.7680, Accuracy: 66.67%\n",
      "Epoch [10/100], Loss: 0.5341, Val Loss: 0.5074, AUC: 0.8242, Accuracy: 73.97%\n",
      "Fold 3/5, AUC: 0.8272, Accuracy: 73.55%\n",
      "Fold 4/5, AUC: 0.8269, Accuracy: 75.62%\n",
      "Epoch [10/100], Loss: 0.5296, Val Loss: 0.5762, AUC: 0.7637, Accuracy: 67.36%\n",
      "Epoch [20/100], Loss: 0.5132, Val Loss: 0.5809, AUC: 0.7672, Accuracy: 68.18%\n",
      "Epoch [30/100], Loss: 0.5163, Val Loss: 0.5824, AUC: 0.7672, Accuracy: 68.60%\n",
      "Epoch [40/100], Loss: 0.5306, Val Loss: 0.5828, AUC: 0.7676, Accuracy: 67.77%\n",
      "Epoch [50/100], Loss: 0.5140, Val Loss: 0.5823, AUC: 0.7668, Accuracy: 68.18%\n",
      "Epoch [60/100], Loss: 0.5235, Val Loss: 0.5827, AUC: 0.7666, Accuracy: 68.18%\n",
      "Epoch [70/100], Loss: 0.5192, Val Loss: 0.5811, AUC: 0.7677, Accuracy: 68.60%\n",
      "Epoch [80/100], Loss: 0.5274, Val Loss: 0.5819, AUC: 0.7668, Accuracy: 68.60%\n",
      "Epoch [90/100], Loss: 0.5145, Val Loss: 0.5811, AUC: 0.7679, Accuracy: 68.60%\n",
      "Epoch [100/100], Loss: 0.5108, Val Loss: 0.5824, AUC: 0.7670, Accuracy: 68.18%\n",
      "Fold 5/5, AUC: 0.7681, Accuracy: 68.60%\n",
      "Best cross-validated AUC: 0.8491\n",
      "Best cross-validated accuracy: 75.31%\n",
      "Epoch [10/100], Loss: 0.5184, Val Loss: 0.5336, AUC: 0.8156, Accuracy: 75.25%\n",
      "Epoch [20/100], Loss: 0.5215, Val Loss: 0.5323, AUC: 0.8182, Accuracy: 75.58%\n",
      "Epoch [30/100], Loss: 0.5246, Val Loss: 0.5323, AUC: 0.8182, Accuracy: 75.25%\n",
      "Epoch [40/100], Loss: 0.5256, Val Loss: 0.5335, AUC: 0.8179, Accuracy: 74.92%\n",
      "Epoch [50/100], Loss: 0.5158, Val Loss: 0.5316, AUC: 0.8176, Accuracy: 75.25%\n",
      "Epoch [60/100], Loss: 0.5225, Val Loss: 0.5318, AUC: 0.8178, Accuracy: 75.58%\n",
      "Epoch [70/100], Loss: 0.5188, Val Loss: 0.5317, AUC: 0.8182, Accuracy: 75.25%\n",
      "Epoch [80/100], Loss: 0.5112, Val Loss: 0.5335, AUC: 0.8176, Accuracy: 74.92%\n",
      "Epoch [90/100], Loss: 0.5138, Val Loss: 0.5332, AUC: 0.8175, Accuracy: 74.92%\n",
      "Epoch [100/100], Loss: 0.5222, Val Loss: 0.5334, AUC: 0.8177, Accuracy: 74.92%\n",
      "Final model AUC on test set: 0.8186\n",
      "Final model accuracy on test set: 75.25%\n",
      "AUC 0.8186 not met, restarting the process.\n",
      "Fold 1/5, AUC: 0.8536, Accuracy: 71.19%\n",
      "Epoch [10/100], Loss: 0.5142, Val Loss: 0.5986, AUC: 0.7692, Accuracy: 69.96%\n",
      "Epoch [20/100], Loss: 0.5066, Val Loss: 0.6012, AUC: 0.7662, Accuracy: 68.31%\n",
      "Epoch [30/100], Loss: 0.4891, Val Loss: 0.6065, AUC: 0.7693, Accuracy: 67.90%\n",
      "Epoch [40/100], Loss: 0.4898, Val Loss: 0.6051, AUC: 0.7687, Accuracy: 68.72%\n",
      "Epoch [50/100], Loss: 0.4985, Val Loss: 0.6047, AUC: 0.7681, Accuracy: 68.72%\n",
      "Epoch [60/100], Loss: 0.4979, Val Loss: 0.6059, AUC: 0.7683, Accuracy: 68.72%\n",
      "Epoch [70/100], Loss: 0.4867, Val Loss: 0.6055, AUC: 0.7679, Accuracy: 68.31%\n",
      "Epoch [80/100], Loss: 0.5012, Val Loss: 0.6051, AUC: 0.7678, Accuracy: 68.31%\n",
      "Epoch [90/100], Loss: 0.4967, Val Loss: 0.6083, AUC: 0.7683, Accuracy: 68.72%\n",
      "Epoch [100/100], Loss: 0.4949, Val Loss: 0.6045, AUC: 0.7681, Accuracy: 68.31%\n",
      "Fold 2/5, AUC: 0.7702, Accuracy: 69.55%\n",
      "Fold 3/5, AUC: 0.8253, Accuracy: 74.38%\n",
      "Epoch [10/100], Loss: 0.5477, Val Loss: 0.5214, AUC: 0.8252, Accuracy: 75.21%\n",
      "Fold 4/5, AUC: 0.8252, Accuracy: 75.21%\n",
      "Epoch [10/100], Loss: 0.5222, Val Loss: 0.5652, AUC: 0.7751, Accuracy: 68.18%\n",
      "Epoch [20/100], Loss: 0.5194, Val Loss: 0.5711, AUC: 0.7756, Accuracy: 69.83%\n",
      "Epoch [30/100], Loss: 0.5112, Val Loss: 0.5700, AUC: 0.7757, Accuracy: 71.07%\n",
      "Epoch [40/100], Loss: 0.5048, Val Loss: 0.5694, AUC: 0.7758, Accuracy: 71.07%\n",
      "Epoch [50/100], Loss: 0.5082, Val Loss: 0.5711, AUC: 0.7757, Accuracy: 70.66%\n",
      "Epoch [60/100], Loss: 0.5145, Val Loss: 0.5702, AUC: 0.7759, Accuracy: 71.07%\n",
      "Epoch [70/100], Loss: 0.5126, Val Loss: 0.5706, AUC: 0.7756, Accuracy: 70.66%\n",
      "Epoch [80/100], Loss: 0.5109, Val Loss: 0.5699, AUC: 0.7758, Accuracy: 71.49%\n",
      "Epoch [90/100], Loss: 0.5040, Val Loss: 0.5706, AUC: 0.7757, Accuracy: 70.25%\n",
      "Epoch [100/100], Loss: 0.5118, Val Loss: 0.5715, AUC: 0.7761, Accuracy: 70.25%\n",
      "Fold 5/5, AUC: 0.7765, Accuracy: 70.25%\n",
      "Best cross-validated AUC: 0.8536\n",
      "Best cross-validated accuracy: 71.19%\n",
      "Final model AUC on test set: 0.8254\n",
      "Final model accuracy on test set: 76.24%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABMnElEQVR4nO3deXxM1/8/8NdkmUlENiKLmIqdWCshX0usaUNbSxeilAillqB8aGNL7KFqa2kVJaVU7I3SKEqLprUrtYfUmpAiicg6c35/9JepkcVMzJK5eT0fj3m0c+bce99zkjHvnHsWmRBCgIiIiEgirMwdABEREZEhMbkhIiIiSWFyQ0RERJLC5IaIiIgkhckNERERSQqTGyIiIpIUJjdEREQkKUxuiIiISFKY3BAREZGkMLkhKgUfHx8MHDjQ3GGUOx06dECHDh3MHcZzTZs2DTKZDKmpqeYOpcyRyWSYNm2aQc6VlJQEmUyGmJgYg5yPpIPJDZU5MTExkMlkmoeNjQ28vb0xcOBA3L5929zhlWmZmZmYOXMmmjRpggoVKsDZ2RmBgYFYu3YtLGWnlfPnz2PatGlISkoydyiFqFQqrFmzBh06dEClSpWgUCjg4+ODsLAwHD9+3NzhGcSGDRuwePFic4ehpSzGRGWbjbkDICrOjBkzUKNGDWRnZ+P3339HTEwMDh8+jHPnzsHOzs6ssV26dAlWVmXrb4OUlBR07twZFy5cQJ8+fRAeHo7s7Gxs3boVoaGh2L17N9avXw9ra2tzh1qi8+fPY/r06ejQoQN8fHy0Xvvpp5/MExSArKwsvPXWW4iPj0e7du0wadIkVKpUCUlJSdi0aRO++eYb3LhxA9WqVTNbjIawYcMGnDt3Dh9++KFRzp+VlQUbG/2+eoqLqXr16sjKyoKtra0BIyQpYHJDZVbXrl3h7+8PAHj//ffh5uaGefPmIS4uDr179zZrbAqFwuTXzM7OhlwuLzapCg0NxYULF7B9+3Z0795dUz569GhMmDABn376KV5++WV8/PHHpgoZwL+9SQ4ODgY5l1wuN8h5SmPChAmIj4/HokWLCn3JRkVFYdGiRSaNRwiB7Oxs2Nvbm/S6paFWq5Gbmws7OzuD/mEik8nM/ocOlVGCqIxZs2aNACCOHTumVf7DDz8IAGLOnDla5RcuXBBvv/22cHV1FQqFQvj5+Ynvv/++0HkfPnwoPvzwQ1G9enUhl8uFt7e36N+/v7h//76mTnZ2toiMjBS1atUScrlcVKtWTUyYMEFkZ2drnat69eoiNDRUCCHEsWPHBAARExNT6Jrx8fECgNi5c6em7NatWyIsLEy4u7sLuVwufH19xddff6113IEDBwQA8d1334nJkyeLqlWrCplMJh4+fFhkmyUkJAgAYtCgQUW+npeXJ+rUqSNcXV3FkydPhBBCXL9+XQAQ8+fPFwsXLhQvvfSSsLOzE+3atRNnz54tdA5d2rngZ3fw4EExfPhwUaVKFeHi4iKEECIpKUkMHz5c1K1bV9jZ2YlKlSqJd955R1y/fr3Q8c8+Dhw4IIQQon379qJ9+/aF2ik2NlbMmjVLeHt7C4VCITp16iSuXLlS6D0sXbpU1KhRQ9jZ2YkWLVqIX3/9tdA5i3Lz5k1hY2MjXnnllRLrFYiKihIAxJUrV0RoaKhwdnYWTk5OYuDAgSIzM1Or7urVq0XHjh1FlSpVhFwuFw0aNBBffPFFoXNWr15dvP766yI+Pl74+fkJhUIhFi1apNc5hBBi9+7dol27dqJixYrC0dFR+Pv7i/Xr1wsh/m3fZ9u+evXqmmN1/XwAECNHjhTffvut8PX1FTY2NmL79u2a16KiojR109PTxZgxYzSfyypVqoigoCBx4sSJ58ZU8Du8Zs0aretfuHBB9OrVS7i5uQk7OztRt25dMWnSJJ2vSZaPPTdkMQrGYLi6umrK/vrrL7Rp0wbe3t6IiIiAg4MDNm3ahJ49e2Lr1q148803AQCPHz9GYGAgLly4gEGDBqF58+ZITU1FXFwcbt26BTc3N6jVanTv3h2HDx/G0KFD0aBBA5w9exaLFi3C5cuXsWPHjiLj8vf3R82aNbFp0yaEhoZqvRYbGwtXV1cEBwcD+PfW0f/93/9BJpMhPDwcVapUwY8//ojBgwcjPT29UI/AzJkzIZfLMX78eOTk5BTbc7Fz504AwIABA4p83cbGBn379sX06dNx5MgRBAUFaV5bu3YtMjIyMHLkSGRnZ2PJkiXo1KkTzp49Cw8PD73aucCIESNQpUoVREZGIjMzEwBw7Ngx/Pbbb+jTpw+qVauGpKQkfPnll+jQoQPOnz+PChUqoF27dhg9ejQ+++wzTJo0CQ0aNAAAzX+LM3fuXFhZWWH8+PFIS0vDJ598gn79+uGPP/7Q1Pnyyy8RHh6OwMBAjB07FklJSejZsydcXV2feyvpxx9/RH5+Pvr3719ivWf17t0bNWrUQHR0NE6ePIlVq1bB3d0d8+bN04qrYcOG6N69O2xsbLBz506MGDECarUaI0eO1DrfpUuX8O677+KDDz7AkCFDUK9ePb3OERMTg0GDBqFhw4aYOHEiXFxccOrUKcTHx6Nv376YPHky0tLScOvWLU1PVMWKFQFA78/Hzz//jE2bNiE8PBxubm6FbjEWGDZsGLZs2YLw8HD4+vrin3/+weHDh3HhwgU0b968xJiK8ueffyIwMBC2trYYOnQofHx8kJiYiJ07d2L27Nk6XZMkwNzZFdGzCv5637dvn7h//764efOm2LJli6hSpYpQKBTi5s2bmrqdO3cWjRs31vrLUa1Wi9atW4s6depoyiIjIwUAsW3btkLXU6vVQggh1q1bJ6ysrMShQ4e0Xl++fLkAII4cOaIpe7rnRgghJk6cKGxtbcWDBw80ZTk5OcLFxUWrN2Xw4MHCy8tLpKamal2jT58+wtnZWdOrUtAjUbNmTU1ZSXr27CkAFNuzI4QQ27ZtEwDEZ599JoT4769ee3t7cevWLU29P/74QwAQY8eO1ZTp2s4FP7u2bduK/Px8resX9T4KepzWrl2rKdu8ebNWb83Tiuu5adCggcjJydGUL1myRADQ9EDl5OSIypUrixYtWoi8vDxNvZiYGAHguT03Y8eOFQDEqVOnSqxXoKDn5tmetDfffFNUrlxZq6yodgkODhY1a9bUKqtevboAIOLj4wvV1+Ucjx49Eo6OjiIgIEBkZWVp1S34DAghxOuvv67VW1NAn88HAGFlZSX++uuvQufBMz03zs7OYuTIkYXqPa24mIrquWnXrp1wdHQUf//9d7HvUZdrkmUrWyMiiZ4SFBSEKlWqQKlU4p133oGDgwPi4uI0f2U/ePAAP//8M3r37o2MjAykpqYiNTUV//zzD4KDg3HlyhXN7KqtW7eiadOmhXoYgH/v2wPA5s2b0aBBA9SvX19zrtTUVHTq1AkAcODAgWJjDQkJQV5eHrZt26Yp++mnn/Do0SOEhIQA+HeMxNatW9GtWzcIIbSuERwcjLS0NJw8eVLrvKGhoTqNqcjIyAAAODo6Flun4LX09HSt8p49e8Lb21vzvGXLlggICMDu3bsB6NfOBYYMGVJo4PLT7yMvLw///PMPateuDRcXl0LvW19hYWFavVqBgYEAgGvXrgEAjh8/jn/++QdDhgzRGszar18/rZ7A4hS0WUntW5Rhw4ZpPQ8MDMQ///yj9TN4ul3S0tKQmpqK9u3b49q1a0hLS9M6vkaNGppewKfpco69e/ciIyMDERERhcapFHwGSqLv56N9+/bw9fV97nldXFzwxx9/4M6dO8+t+zz379/Hr7/+ikGDBuGll17Seu3p92jIa1LZxNtSVGYtW7YMdevWRVpaGlavXo1ff/1VayDv1atXIYTA1KlTMXXq1CLPce/ePXh7eyMxMRFvv/12ide7cuUKLly4gCpVqhR7ruI0bdoU9evXR2xsLAYPHgzg31tSbm5umn/879+/j0ePHmHFihVYsWKFTteoUaNGiTEXKPjSzcjIgIuLS5F1ikuA6tSpU6hu3bp1sWnTJgD6tXNJcWdlZSE6Ohpr1qzB7du3taamP/slrq9nv8gKEpaHDx8CAP7++28AQO3atbXq2djYFHu75GlOTk4A/mtDQ8RVcM4jR44gKioKCQkJePLkiVb9tLQ0ODs7a54X9/ugyzkSExMBAI0aNdLrPRTQ9/Oh6+/uJ598gtDQUCiVSvj5+eG1117DgAEDULNmTb1jLEhmn/ceDXlNKpuY3FCZ1bJlS81sqZ49e6Jt27bo27cvLl26hIoVK0KtVgMAxo8fX+Rfs0DhL7OSqNVqNG7cGAsXLizydaVSWeLxISEhmD17NlJTU+Ho6Ii4uDi8++67mp6Cgnjfe++9QmNzCjRp0kTrua4zYRo0aIAdO3bgzz//RLt27Yqs8+effwKATn9NP6007VxU3KNGjcKaNWvw4YcfolWrVnB2doZMJkOfPn001yit4qa3CwOt7VO/fn0AwNmzZ9GsWTOdj3teXImJiejcuTPq16+PhQsXQqlUQi6XY/fu3Vi0aFGhdimqXfU9R2np+/nQ9Xe3d+/eCAwMxPbt2/HTTz9h/vz5mDdvHrZt24auXbu+cNxl5ZpkWkxuyCJYW1sjOjoaHTt2xNKlSxEREaH5K8vW1lZrgGxRatWqhXPnzj23zpkzZ9C5c2eduumfFRISgunTp2Pr1q3w8PBAeno6+vTpo3m9SpUqcHR0hEqlem68+nrjjTcQHR2NtWvXFpncqFQqbNiwAa6urmjTpo3Wa1euXClU//Lly5oeDX3auSRbtmxBaGgoFixYoCnLzs7Go0ePtOqVpu2fp3r16gD+7YXq2LGjpjw/Px9JSUmFkspnde3aFdbW1vj222/1HlRckp07dyInJwdxcXFavTwl3QIt7Tlq1aoFADh37lyJSX9x7f+in4+SeHl5YcSIERgxYgTu3buH5s2bY/bs2ZpEQ9frFfyuPu+zrss1ybJxzA1ZjA4dOqBly5ZYvHgxsrOz4e7ujg4dOuCrr77C3bt3C9W/f/++5v/ffvttnDlzBtu3by9Ur+Cv6N69e+P27dtYuXJloTpZWVmaWT/FadCgARo3bozY2FjExsbCy8tLK9GwtrbG22+/ja1btxb5j+/T8eqrdevWCAoKwpo1a/DDDz8Uen3y5Mm4fPkyPvroo0J/Ue/YsUNrzMzRo0fxxx9/aP6R16edS2JtbV2oJ+Xzzz+HSqXSKitYE+fZpOdF+Pv7o3Llyli5ciXy8/M15evXr9fcuiqJUqnEkCFD8NNPP+Hzzz8v9LparcaCBQtw69YtveIq6Nl59hbdmjVrDH6OV199FY6OjoiOjkZ2drbWa08f6+DgUORtwhf9fBRFpVIVupa7uzuqVq2KnJyc58b0rCpVqqBdu3ZYvXo1bty4ofVawXvU9Zpk2dhzQxZlwoQJ6NWrF2JiYjBs2DAsW7YMbdu2RePGjTFkyBDUrFkTKSkpSEhIwK1bt3DmzBnNcVu2bEGvXr0waNAg+Pn54cGDB4iLi8Py5cvRtGlT9O/fH5s2bcKwYcNw4MABtGnTBiqVChcvXsSmTZuwZ88ezW2y4oSEhCAyMhJ2dnYYPHhwoQX35s6diwMHDiAgIABDhgyBr68vHjx4gJMnT2Lfvn148OBBqdtm7dq16Ny5M3r06IG+ffsiMDAQOTk52LZtGw4ePIiQkBBMmDCh0HG1a9dG27ZtMXz4cOTk5GDx4sWoXLkyPvroI00dXdu5JG+88QbWrVsHZ2dn+Pr6IiEhAfv27UPlypW16jVr1gzW1taYN28e0tLSoFAo0KlTJ7i7u5e6beRyOaZNm4ZRo0ahU6dO6N27N5KSkhATE4NatWrp1DOwYMECJCYmYvTo0di2bRveeOMNuLq64saNG9i8eTMuXryo1VOni1dffRVyuRzdunXDBx98gMePH2PlypVwd3cvMpF8kXM4OTlh0aJFeP/999GiRQv07dsXrq6uOHPmDJ48eYJvvvkGAODn54fY2FiMGzcOLVq0QMWKFdGtWzeDfD6elZGRgWrVquGdd95B06ZNUbFiRezbtw/Hjh3T6uErLqaifPbZZ2jbti2aN2+OoUOHokaNGkhKSsKuXbtw+vRpna9JFs4sc7SISlDcIn5CCKFSqUStWrVErVq1NFONExMTxYABA4Snp6ewtbUV3t7e4o033hBbtmzROvaff/4R4eHhwtvbW7MAWWhoqNa07NzcXDFv3jzRsGFDoVAohKurq/Dz8xPTp08XaWlpmnrPTgUvcOXKFc1CY4cPHy7y/aWkpIiRI0cKpVIpbG1thaenp+jcubNYsWKFpk7BFOfNmzfr1XYZGRli2rRpomHDhsLe3l44OjqKNm3aiJiYGK2psEJoL+K3YMECoVQqhUKhEIGBgeLMmTOFzq1LO5f0s3v48KEICwsTbm5uomLFiiI4OFhcvHixyLZcuXKlqFmzprC2ttZpEb9n26m4xd0+++wzUb16daFQKETLli3FkSNHhJ+fn+jSpYsOrStEfn6+WLVqlQgMDBTOzs7C1tZWVK9eXYSFhWlNEy+YCv70ApFPt8/TCxfGxcWJJk2aCDs7O+Hj4yPmzZsnVq9eXahewSJ+RdH1HAV1W7duLezt7YWTk5No2bKl+O677zSvP378WPTt21e4uLgUWsRP188H/v8ifkXBU1PBc3JyxIQJE0TTpk2Fo6OjcHBwEE2bNi20AGFxMRX3cz537px48803hYuLi7CzsxP16tUTU6dO1euaZNlkQljIbnpEZFBJSUmoUaMG5s+fj/Hjx5s7HLNQq9WoUqUK3nrrrSJvtxCRZeKYGyIqF7KzswuN+Vm7di0ePHiADh06mCcoIjIKjrkhonLh999/x9ixY9GrVy9UrlwZJ0+exNdff41GjRqhV69e5g6PiAyIyQ0RlQs+Pj5QKpX47LPP8ODBA1SqVAkDBgzA3LlzzbrbOBEZHsfcEBERkaRwzA0RERFJCpMbIiIikpRyN+ZGrVbjzp07cHR0NMoy70RERGR4QghkZGSgatWqhRZIfVa5S27u3Lnz3A0QiYiIqGy6efMmqlWrVmKdcpfcODo6Avi3cZycnMwcDREREekiPT0dSqVS8z1eknKX3BTcinJycmJyQ0REZGF0GVLCAcVEREQkKUxuiIiISFKY3BAREZGkMLkhIiIiSWFyQ0RERJLC5IaIiIgkhckNERERSQqTGyIiIpIUJjdEREQkKUxuiIiISFLMmtz8+uuv6NatG6pWrQqZTIYdO3Y895iDBw+iefPmUCgUqF27NmJiYoweJxEREVkOsyY3mZmZaNq0KZYtW6ZT/evXr+P1119Hx44dcfr0aXz44Yd4//33sWfPHiNHSkRERJbCrBtndu3aFV27dtW5/vLly1GjRg0sWLAAANCgQQMcPnwYixYtQnBwsLHCJCIikjwhBLLyVAY7n72ttU6bXBqDRe0KnpCQgKCgIK2y4OBgfPjhh8Uek5OTg5ycHM3z9PR0Y4VHRERkkYQQeGd5Ak78/dBg5zw/IxgV5OZJMywquUlOToaHh4dWmYeHB9LT05GVlQV7e/tCx0RHR2P69OmmCpGIiMgoDN2z8rQnuSqDJjbmZlHJTWlMnDgR48aN0zxPT0+HUqk0Y0RERET6MUbPSnGOTwlCBbn1C5/H3vbFz1FaFpXceHp6IiUlRassJSUFTk5ORfbaAIBCoYBCoTBFeEREVAYYs4fDXEzVs+Jf3RWVHeRmGytjKBaV3LRq1Qq7d+/WKtu7dy9atWplpoiIiKgsMWUPh7kYqmelKOYcBGxIZk1uHj9+jKtXr2qeX79+HadPn0alSpXw0ksvYeLEibh9+zbWrl0LABg2bBiWLl2Kjz76CIMGDcLPP/+MTZs2YdeuXeZ6C0REVIZk5Ulr7MizpNKzYmxmTW6OHz+Ojh07ap4XjI0JDQ1FTEwM7t69ixs3bmher1GjBnbt2oWxY8diyZIlqFatGlatWsVp4EREZYS5bwk9yf3v2sbs4TAXqfSsGJtMCCHMHYQppaenw9nZGWlpaXBycjJ3OEREklHWbgmZcyoyGZ4+39/8qRMRSZypelPK0nRi/+quZp2tQ+bF5IaISMLM1Zti7ltCvH1TvjG5ISKSMHMMsOWgVzI3JjdEROWEqXpT2GtC5sbkhojIhEw9m+jp2UMV5NYcYEvlAn/LiYhMpKzNJiKSKitzB0BEVF6Yc4E5zh6i8oQ9N0REZmDq2UQcB0PlCZMbIiIz4PgXIuPhJ4uISE+lHRT89OBeIjIeJjdERHrgoGCiso8DiomI9GCIQcEc3EtkXOy5ISIqpdIOCubgXiLjYnJDRFRKHBRMVDbxthQRERFJCv/kICJ6yvNmQnHGE1HZx+SGiOj/40woImngbSkiov9Pn5lQnPFEVHax54aIqAjPmwnFGU9EZReTGyKiInAmFJHl4ieXiCShtFsiPI2DhYmkgckNEVk8DgQmoqdxQDERWTxDbInwNA4WJrJs7LkhIkkp7ZYIT+NgYSLLxuSGiCxWwTibp8fKcCAwEfFfACKySBxnQ0TF4ZgbIrJIRY2z4VgZIgLYc0NEElAwzoZjZYgIYHJDRBLAcTZE9DTeliIiIiJJYXJDREREksJ+XCIqk563nQK3SiCi4jC5IaIyh9O8iehFMLkhIqMp7WaWT3J1306B07+J6FlMbojIKAzV+/K87RQ4/ZuInsXkhoh0pk9PjD69L8Xxr+6Kyg5yJi9EpBcmN0SkkxfpiSntZpbslSGi0mByQ0Q6KWq7A12w94WITI3JDRHpTZ+eGPa+EJGpMbkhIr1xuwMiKsu4QjERERFJCpMbIiIikhT2KxNRIUVN+eZ2B0RkKZjcEJEWbn1ARJaOyQ0RAfivt+Z5i+9xuwMiKuuY3BBRsb01RU355tRuIirrmNwQlWMl9dZw8T0islRMbojKqef11rCHhogsFZMbonKGvTVEJHVMbojKEfbWEFF5wOSGqBwpavNL9tYQkdQwuSEqB56+FVWAvTVEJFVMbogkrrhbUdz8koikiv+yEUnU8wYOcyE+IpIqJjdEEsSBw0RUnjG5IZIQTvMmIgKszB3AsmXL4OPjAzs7OwQEBODo0aMl1l+8eDHq1asHe3t7KJVKjB07FtnZ2SaKlqjsKuit8Y3cA/9Z+zTlx6cE4fyMYGwe1oqJDRGVC2btuYmNjcW4ceOwfPlyBAQEYPHixQgODsalS5fg7u5eqP6GDRsQERGB1atXo3Xr1rh8+TIGDhwImUyGhQsXmuEdED1fQW+KsbG3hojoXzIhhDDXxQMCAtCiRQssXboUAKBWq6FUKjFq1ChEREQUqh8eHo4LFy5g//79mrL//e9/+OOPP3D48GGdrpmeng5nZ2ekpaXBycnJMG+EqBjFjX0xNo6tISKp0ef722y3pXJzc3HixAkEBQX9F4yVFYKCgpCQkFDkMa1bt8aJEyc0t66uXbuG3bt347XXXiv2Ojk5OUhPT9d6EOlLCIEnufl6P/7JzDV5YlPQW1NBbsPEhojKJbPdlkpNTYVKpYKHh4dWuYeHBy5evFjkMX379kVqairatm0LIQTy8/MxbNgwTJo0qdjrREdHY/r06QaNncoXQ/W+FPSmGBt7a4iovDP7gGJ9HDx4EHPmzMEXX3yBkydPYtu2bdi1axdmzpxZ7DETJ05EWlqa5nHz5k0TRkxSUNSWBfp6ujfF2A8mNkRU3pmt58bNzQ3W1tZISUnRKk9JSYGnp2eRx0ydOhX9+/fH+++/DwBo3LgxMjMzMXToUEyePBlWVoVzNYVCAYVCYfg3QOVSaXtf2JtCRGQ6Zuu5kcvl8PPz0xocrFarsX//frRq1arIY548eVIogbG2/veLxozjoqkcKdiygL0pRERll1mngo8bNw6hoaHw9/dHy5YtsXjxYmRmZiIsLAwAMGDAAHh7eyM6OhoA0K1bNyxcuBAvv/wyAgICcPXqVUydOhXdunXTJDlERERUvpk1uQkJCcH9+/cRGRmJ5ORkNGvWDPHx8ZpBxjdu3NDqqZkyZQpkMhmmTJmC27dvo0qVKujWrRtmz55trrdAREREZYxZ17kxB65zQ/p6kpsP38g9AIDzM4K5kzYRkRlYxDo3RERERMbA5IaIiIgkhckNERERSQqTGyIiIpIUjowkKkbBbt5Pco2/ozcRERkOkxuiIphrN28iInpxvC1FVISi9pPyr+4Ke1suFklEVNax54boOQr2k+L+UEREloHJDZV7BWNrnvb0OJuC/aSIiMgy8F9sKtc4toaISHqY3FC5UVwPTUmJDcfZEBFZHiY3VC7o0kNTMLbmaRxnQ0RkeZjcUJlXVI+LvnTpoansIGciQ0QkAUxuqEwzxpgY9tAQEUkbkxsq04pab+ZFsIeGiEj6mNyQxSiqx0Vf7KEhIpI+JjdkMbjeDBER6YLbLxAREZGkMLkhIiIiSWEfP5VJBdO/n94GgYiISBdMbqjM4ZYIRET0InhbisqcoqZ/cxsEIiLSFXtuqEwrmP7NKdxERKQrJjdUpnH6NxER6Yu3pYiIiEhSmNwQERGRpLC/n8oMTv8mIiJDYHJDZQKnfxMRkaEwuSGzerq3htO/iYjIEJjckNkU11vD6d9ERPQimNyQ2RS3WF9lBzmTGiIiKjUmN1QmsLeGiIgMhckNmVxRs6K4WB8RERnKC32bZGdnw87OzlCxUDnAWVFERGRsei/ip1arMXPmTHh7e6NixYq4du0aAGDq1Kn4+uuvDR4gSQs3xSQiImPTO7mZNWsWYmJi8Mknn0Aul2vKGzVqhFWrVhk0OJK241OCcH5GMDYPa8VxNkREZDB6Jzdr167FihUr0K9fP1hb//fXdtOmTXHx4kWDBkfSVjDOhokNEREZkt7Jze3bt1G7du1C5Wq1Gnl5eQYJioiIiKi09E5ufH19cejQoULlW7Zswcsvv2yQoIiIiIhKS+/ZUpGRkQgNDcXt27ehVquxbds2XLp0CWvXrsUPP/xgjBjJghVM+y7ATTGJiMjY9E5uevTogZ07d2LGjBlwcHBAZGQkmjdvjp07d+KVV14xRoxkoTjtm4iIzKFU69wEBgZi7969ho6FJKaoad8FOP2biIiMRe/kpmbNmjh27BgqV66sVf7o0SM0b95cs+4N0dMKtlcowG0WiIjIWPRObpKSkqBSFR43kZOTg9u3bxskKJIebq9ARESmovO3TVxcnOb/9+zZA2dnZ81zlUqF/fv3w8fHx6DBEREREelL5+SmZ8+eAACZTIbQ0FCt12xtbeHj44MFCxYYNDgiIiIifemc3KjVagBAjRo1cOzYMbi5uRktKLIMz07zfhanfRMRkTnoPQji+vXrxoiDLAyneRMRUVlVqhGemZmZ+OWXX3Djxg3k5uZqvTZ69GiDBEZlW0nTvJ/Fad9ERGRKeic3p06dwmuvvYYnT54gMzMTlSpVQmpqKipUqAB3d3cmN+XQs9O8n8Vp30REZEp67y01duxYdOvWDQ8fPoS9vT1+//13/P333/Dz88Onn35qjBipjCuY5l3cg4kNERGZkt7JzenTp/G///0PVlZWsLa2Rk5ODpRKJT755BNMmjTJGDESERER6Uzv5MbW1hZWVv8e5u7ujhs3bgAAnJ2dcfPmTcNGR0RERKQnvcfcvPzyyzh27Bjq1KmD9u3bIzIyEqmpqVi3bh0aNWpkjBiJiIiIdKZ3z82cOXPg5eUFAJg9ezZcXV0xfPhw3L9/H1999ZXBA6SyRQiBJ7n5XMOGiIjKLL17bvz9/TX/7+7ujvj4eIMGRGUX17YhIiJLoHfPTXFOnjyJN954Q+/jli1bBh8fH9jZ2SEgIABHjx4tsf6jR48wcuRIeHl5QaFQoG7duti9e3dpwyY9FLW2DdewISKiskavnps9e/Zg7969kMvleP/991GzZk1cvHgRERER2LlzJ4KDg/W6eGxsLMaNG4fly5cjICAAixcvRnBwMC5dugR3d/dC9XNzc/HKK6/A3d0dW7Zsgbe3N/7++2+4uLjodV16cQVr23ANGyIiKmt0Tm6+/vprDBkyBJUqVcLDhw+xatUqLFy4EKNGjUJISAjOnTuHBg0a6HXxhQsXYsiQIQgLCwMALF++HLt27cLq1asRERFRqP7q1avx4MED/Pbbb7C1tQUA7kRuJgVr2xAREZU1Ot+WWrJkCebNm4fU1FRs2rQJqamp+OKLL3D27FksX75c78QmNzcXJ06cQFBQ0H/BWFkhKCgICQkJRR4TFxeHVq1aYeTIkfDw8ECjRo0wZ84cqFTFD27NyclBenq61oOIiIikS+fkJjExEb169QIAvPXWW7CxscH8+fNRrVq1Ul04NTUVKpUKHh4eWuUeHh5ITk4u8phr165hy5YtUKlU2L17N6ZOnYoFCxZg1qxZxV4nOjoazs7OmodSqSxVvERERGQZdE5usrKyUKFCBQCATCaDQqHQTAk3FbVaDXd3d6xYsQJ+fn4ICQnB5MmTsXz58mKPmThxItLS0jQPLjRIREQkbXoNmli1ahUqVqwIAMjPz0dMTAzc3Ny06ui6caabmxusra2RkpKiVZ6SkgJPT88ij/Hy8oKtrS2srf+bndOgQQMkJycjNzcXcrm80DEKhQIKhUKnmIiIiMjy6ZzcvPTSS1i5cqXmuaenJ9atW6dVRyaT6ZzcyOVy+Pn5Yf/+/ejZsyeAf3tm9u/fj/Dw8CKPadOmDTZs2AC1Wq3ZAuLy5cvw8vIqMrEhIiKi8kfn5CYpKcngFx83bhxCQ0Ph7++Pli1bYvHixcjMzNTMnhowYAC8vb0RHR0NABg+fDiWLl2KMWPGYNSoUbhy5QrmzJmjc0JFRERE0mfWubwhISG4f/8+IiMjkZycjGbNmiE+Pl4zyPjGjRuaHhoAUCqV2LNnD8aOHYsmTZrA29sbY8aMwccff2yut0BERERljEwIIcwdhCmlp6fD2dkZaWlpcHJyMnc4FuVJbj58I/cAAM7PCOY6N0REZDL6fH8bbPsFIiIiorKAf3rTcwkhkJWn4k7gRERkEZjcUIm4EzgREVmaUt2WSkxMxJQpU/Duu+/i3r17AIAff/wRf/31l0GDI/MRQuBJbj7+yczlTuBERGRR9O65+eWXX9C1a1e0adMGv/76K2bPng13d3ecOXMGX3/9NbZs2WKMOMmEiuut4U7gRERkCfTuuYmIiMCsWbOwd+9erYXzOnXqhN9//92gwZF5ZOWpiuytqewgRwW5DRMbIiIq0/TuuTl79iw2bNhQqNzd3R2pqakGCYrKDvbWEBGRpdG758bFxQV3794tVH7q1Cl4e3sbJCgqOyrIrdlbQ0REFkXv5KZPnz74+OOPkZycDJlMBrVajSNHjmD8+PEYMGCAMWIkIiIi0pneyc2cOXNQv359KJVKPH78GL6+vmjXrh1at26NKVOmGCNGMpGCGVJcz4aIiCyZ3mNu5HI5Vq5cialTp+LcuXN4/PgxXn75ZdSpU8cY8ZGJcD0bIiKSCr2Tm8OHD6Nt27Z46aWX8NJLLxkjJjKD4mZIcT0bIiKyNHonN506dYK3tzfeffddvPfee/D19TVGXGRGnCFFRESWTO8xN3fu3MH//vc//PLLL2jUqBGaNWuG+fPn49atW8aIj8yAM6SIiMiS6Z3cuLm5ITw8HEeOHEFiYiJ69eqFb775Bj4+PujUqZMxYiQiIiLSWan2lipQo0YNREREYO7cuWjcuDF++eUXQ8VFREREVCqlTm6OHDmCESNGwMvLC3379kWjRo2wa9cuQ8ZGREREpDe9BxRPnDgRGzduxJ07d/DKK69gyZIl6NGjBypUqGCM+IiIiIj0ondy8+uvv2LChAno3bs33NzcjBETmZAQAll5Ki7cR0REkqF3cnPkyBFjxEFmwIX7iIhIinRKbuLi4tC1a1fY2toiLi6uxLrdu3c3SGBkfFy4j4iIpEin5KZnz55ITk6Gu7s7evbsWWw9mUwGlYq3NywRF+4jIiKp0Cm5UavVRf4/SUfBwn1ERESWTu+p4GvXrkVOTk6h8tzcXKxdu9YgQRERERGVlt7JTVhYGNLS0gqVZ2RkICwszCBBEREREZWW3smNEKLIMRm3bt2Cs7OzQYIiIiIiKi2dB1m8/PLLkMlkkMlk6Ny5M2xs/jtUpVLh+vXr6NKli1GCJCIiItKVzslNwSyp06dPIzg4GBUrVtS8JpfL4ePjg7ffftvgARIRERHpQ+fkJioqCgDg4+ODkJAQ2NnZGS0oIiIiotLSe+5vaGioMeIgE+KWC0REJGU6JTeVKlXC5cuX4ebmBldX1xIXeXvw4IHBgiPD45YLREQkdTolN4sWLYKjo6Pm/7mCreXilgtERCR1OiU3T9+KGjhwoLFiIRPjlgtERCRFeq9zc/LkSZw9e1bz/Pvvv0fPnj0xadIk5ObmGjQ4Mq6CLReY2BARkZTondx88MEHuHz5MgDg2rVrCAkJQYUKFbB582Z89NFHBg+QiIiISB96JzeXL19Gs2bNAACbN29G+/btsWHDBsTExGDr1q2Gjo+IiIhIL6XafqFgZ/B9+/bhtddeAwAolUqkpqYaNjoiIiIiPemd3Pj7+2PWrFlYt24dfvnlF7z++usAgOvXr8PDw8PgARIRERHpQ+/kZvHixTh58iTCw8MxefJk1K5dGwCwZcsWtG7d2uABkmEIIfAkN58L9xERkeTpvUJxkyZNtGZLFZg/fz6srblWSlnEhfuIiKg80Tu5KXDixAlcuHABAODr64vmzZsbLCgyLC7cR0RE5Yneyc29e/cQEhKCX375BS4uLgCAR48eoWPHjti4cSOqVKli6BjJgLhwHxERSZ3eY25GjRqFx48f46+//sKDBw/w4MEDnDt3Dunp6Rg9erQxYiQD4sJ9REQkdXr33MTHx2Pfvn1o0KCBpszX1xfLli3Dq6++atDgiIiIiPSld8+NWq2Gra1toXJbW1vN+jdERERE5qJ3ctOpUyeMGTMGd+7c0ZTdvn0bY8eORefOnQ0aHOnvvynfTz84/ZuIiMoPvW9LLV26FN27d4ePjw+USiUA4ObNm2jUqBG+/fZbgwdIuuOUbyIiolIkN0qlEidPnsT+/fs1U8EbNGiAoKAggwdHuhFCICtPhSe5had8P43Tv4mIqDzQK7mJjY1FXFwccnNz0blzZ4waNcpYcZGOiuutKZjy/TRO/yYiovJA5+Tmyy+/xMiRI1GnTh3Y29tj27ZtSExMxPz5840ZHz1HcQv0VXaQM5EhIqJySSaEELpUbNiwIXr37o2oqCgAwLfffosPPvgAmZmZRg3Q0NLT0+Hs7Iy0tDQ4OTmZO5wX9iQ3H76RewBwgT4iIpIufb6/dZ4tde3aNYSGhmqe9+3bF/n5+bh7927pIyWD4gJ9REREeiQ3OTk5cHBw+O9AKyvI5XJkZWUZJTAiIiKi0tBrQPHUqVNRoUIFzfPc3FzMnj0bzs7OmrKFCxcaLjoiIiIiPemc3LRr1w6XLl3SKmvdujWuXbumec7bIURERGRuOic3Bw8eNGIYRERERIah9/YLxrBs2TL4+PjAzs4OAQEBOHr0qE7Hbdy4ETKZDD179jRugERERGQxzJ7cxMbGYty4cYiKisLJkyfRtGlTBAcH4969eyUel5SUhPHjxyMwMNBEkRIREZElMHtys3DhQgwZMgRhYWHw9fXF8uXLUaFCBaxevbrYY1QqFfr164fp06ejZs2aJoyWiIiIyjqzJje5ubk4ceKE1r5UVlZWCAoKQkJCQrHHzZgxA+7u7hg8eLApwiQiIiILovfGmYaUmpoKlUoFDw8PrXIPDw9cvHixyGMOHz6Mr7/+GqdPn9bpGjk5OcjJydE8T09PL3W8ZcnTm2USERHRf0rVc3Po0CG89957aNWqFW7fvg0AWLduHQ4fPmzQ4J6VkZGB/v37Y+XKlXBzc9PpmOjoaDg7O2seSqXSqDGaQsFmmb6Re+A/a5+5wyEiIipT9E5utm7diuDgYNjb2+PUqVOaXpG0tDTMmTNHr3O5ubnB2toaKSkpWuUpKSnw9PQsVD8xMRFJSUno1q0bbGxsYGNjg7Vr1yIuLg42NjZITEwsdMzEiRORlpamedy8eVOvGMui4jbLtLe1LuYIIiKi8kPv21KzZs3C8uXLMWDAAGzcuFFT3qZNG8yaNUuvc8nlcvj5+WH//v2a6dxqtRr79+9HeHh4ofr169fH2bNntcqmTJmCjIwMLFmypMheGYVCAYVCoVdcloSbZRIREWnTO7m5dOkS2rVrV6jc2dkZjx490juAcePGITQ0FP7+/mjZsiUWL16MzMxMhIWFAQAGDBgAb29vREdHw87ODo0aNdI63sXFBQAKlZcXBZtlEhER0b/0/lb09PTE1atX4ePjo1V++PDhUk3LDgkJwf379xEZGYnk5GQ0a9YM8fHxmkHGN27cgJWV2WesExERkYXQO7kZMmQIxowZg9WrV0Mmk+HOnTtISEjA+PHjMXXq1FIFER4eXuRtKOD52z7ExMSU6ppEREQkTXonNxEREVCr1ejcuTOePHmCdu3aQaFQYPz48Rg1apQxYqT/j9O/iYiInk8mhBClOTA3NxdXr17F48eP4evri4oVKxo6NqNIT0+Hs7Mz0tLS4OTkZO5wdFYw/fvZWVLnZwRzzA0REUmePt/fpf5WlMvl8PX1Le3hpKOne2s4/ZuIiOj59E5uOnbsWOKU459//vmFAqL/FNdbw+nfRERExdM7uWnWrJnW87y8PJw+fRrnzp1DaGiooeIiFL9YX2UHOZMaIiKiYuid3CxatKjI8mnTpuHx48cvHBAVjb01REREujHYAjLvvfceVq9ebajT0TMKFutjYkNERFQygyU3CQkJsLOzM9TpiIiIiEpF79tSb731ltZzIQTu3r2L48ePl3oRPyIiIiJD0Tu5cXZ21npuZWWFevXqYcaMGXj11VcNFhgRERFRaeiV3KhUKoSFhaFx48ZwdXU1VkxEREREpabXmBtra2u8+uqrpdr9m4iIiMgU9B5Q3KhRI1y7ds0YsRARERG9ML2Tm1mzZmH8+PH44YcfcPfuXaSnp2s9iIiIiMxJ5zE3M2bMwP/+9z+89tprAIDu3btrrbkihIBMJoNKxR2riYiIyHx0Tm6mT5+OYcOG4cCBA8aMh4iIiOiF6JzcCCEAAO3btzdaMEREREQvSq8xN1z6n4iIiMo6vda5qVu37nMTnAcPHrxQQPRvL1lWngpPcjl+iYiISF96JTfTp08vtEIxGZYQAu8sT8CJvx+aOxQiIiKLpFdy06dPH7i7uxsrFgKQlacqlNj4V3eFva21mSIiIiKyLDonNxxvY3rHpwShgtwa9rbWbH8iIiId6T1bikyngtwaFeR6721KRERUrun8zalWq40ZBxEREZFBsFugjOAMKSIiIsNgclMGcIYUERGR4ei9cSYZHmdIERERGQ57bsoYzpAiIiJ6MUxuyhjOkCIiInoxvC1FREREksLkhoiIiCSFyQ0RERFJCpMbIiIikhQmN0RERCQpTG6IiIhIUpjcEBERkaQwuSEiIiJJYXJDREREksLkhoiIiCSFyQ0RERFJCpMbIiIikhQmN0RERCQpTG6IiIhIUpjcEBERkaTYmDuA8kwIgaw8FZ7kqswdChERkWQwuTETIQTeWZ6AE38/NHcoREREksLbUmaSlacqlNj4V3eFva21mSIiIiKSBvbclAHHpwShgtwa9rbWkMlk5g6HiIjIojG5KQMqyK1RQc4fBRERkSHwthQRERFJCpMbIiIikhQmN0RERCQpTG6IiIhIUpjcEBERkaQwuSEiIiJJYXJDREREklImkptly5bBx8cHdnZ2CAgIwNGjR4utu3LlSgQGBsLV1RWurq4ICgoqsT4RERGVL2ZPbmJjYzFu3DhERUXh5MmTaNq0KYKDg3Hv3r0i6x88eBDvvvsuDhw4gISEBCiVSrz66qu4ffu2iSMnIiKiskgmhBDmDCAgIAAtWrTA0qVLAQBqtRpKpRKjRo1CRETEc49XqVRwdXXF0qVLMWDAgOfWT09Ph7OzM9LS0uDk5PTC8ZfWk9x8+EbuAQCcnxHMFYqJiIhKoM/3t1l7bnJzc3HixAkEBQVpyqysrBAUFISEhASdzvHkyRPk5eWhUqVKxgqTiIiILIhZuwtSU1OhUqng4eGhVe7h4YGLFy/qdI6PP/4YVatW1UqQnpaTk4OcnBzN8/T09NIHTERERGWe2cfcvIi5c+di48aN2L59O+zs7IqsEx0dDWdnZ81DqVSaOEoiIiIyJbMmN25ubrC2tkZKSopWeUpKCjw9PUs89tNPP8XcuXPx008/oUmTJsXWmzhxItLS0jSPmzdvGiR2IiIiKpvMmtzI5XL4+flh//79mjK1Wo39+/ejVatWxR73ySefYObMmYiPj4e/v3+J11AoFHByctJ6EBERkXSZfYrOuHHjEBoaCn9/f7Rs2RKLFy9GZmYmwsLCAAADBgyAt7c3oqOjAQDz5s1DZGQkNmzYAB8fHyQnJwMAKlasiIoVK5rtfRAREVHZYPbkJiQkBPfv30dkZCSSk5PRrFkzxMfHawYZ37hxA1ZW/3Uwffnll8jNzcU777yjdZ6oqChMmzbNlKETERFRGWT2dW5MjevcEBERWR6LWeeGiIiIyNDYXWBiQghk5anwJFdl7lCIiIgkicmNCQkh8M7yBJz4+6G5QyEiIpIs3pYyoaw8VaHExr+6K+xtrc0UERERkfSw58ZMjk8JQgW5NextrSGTycwdDhERkWQwuTGTCnJrzpAiIiIyAt6WIiIiIklhckNERESSwuSGiIiIJIXJDREREUkKkxsiIiKSFCY3REREJClMboiIiEhSmNwQERGRpDC5ISIiIklhckNERESSwuSGiIiIJIXJDREREUkKkxsiIiKSFCY3REREJClMboiIiEhSmNwQERGRpDC5ISIiIklhckNERESSwuSGiIiIJIXJDREREUkKkxsiIiKSFCY3REREJClMboiIiEhSmNwQERGRpDC5ISIiIklhckNERESSwuSGiIiIJIXJDREREUkKkxsiIiKSFCY3REREJClMboiIiEhSmNwQERGRpDC5ISIiIklhckNERESSwuSGiIiIJIXJDREREUkKkxsiIiKSFBtzB1AeCCGQlafCk1yVuUMhIiKSPCY3RiaEwDvLE3Di74fmDoWIiKhc4G0pI8vKUxVKbPyru8Le1tpMEREREUkbe25M6PiUIFSQW8Pe1hoymczc4RAREUkSkxsTqiC3RgU5m5yIiMiYeFuKiIiIJIXJDREREUkK75EYCad/ExERmQeTGyPg9G8iIiLz4W0pI+D0byIiIvNhz42Rcfo3ERGRaTG5MTJO/yYiIjIt3pYiIiIiSWFyQ0RERJJSJpKbZcuWwcfHB3Z2dggICMDRo0dLrL9582bUr18fdnZ2aNy4MXbv3m2iSImIiKisM3tyExsbi3HjxiEqKgonT55E06ZNERwcjHv37hVZ/7fffsO7776LwYMH49SpU+jZsyd69uyJc+fOmThyIiIiKotkQghhzgACAgLQokULLF26FACgVquhVCoxatQoREREFKofEhKCzMxM/PDDD5qy//u//0OzZs2wfPny514vPT0dzs7OSEtLg5OTk8HeR8GifQDwJFcF/1n7AADnZwRzQDEREdEL0uf726zfurm5uThx4gQmTpyoKbOyskJQUBASEhKKPCYhIQHjxo3TKgsODsaOHTuKrJ+Tk4OcnBzN8/T09BcPvAhZeSr4Ru4xyrmJiIhId2a9LZWamgqVSgUPDw+tcg8PDyQnJxd5THJysl71o6Oj4ezsrHkolUrDBK8DLtxHRERkepK/XzJx4kStnp709HSjJDj2ttY4PyO4UBkX7iMiIjItsyY3bm5usLa2RkpKilZ5SkoKPD09izzG09NTr/oKhQIKhcIwAZdAJpNxbA0REVEZYNbbUnK5HH5+fti/f7+mTK1WY//+/WjVqlWRx7Rq1UqrPgDs3bu32PpERERUvpi9q2HcuHEIDQ2Fv78/WrZsicWLFyMzMxNhYWEAgAEDBsDb2xvR0dEAgDFjxqB9+/ZYsGABXn/9dWzcuBHHjx/HihUrzPk2iIiIqIwwe3ITEhKC+/fvIzIyEsnJyWjWrBni4+M1g4Zv3LgBK6v/Ophat26NDRs2YMqUKZg0aRLq1KmDHTt2oFGjRuZ6C0RERFSGmH2dG1Mz1jo3REREZDz6fH+bfYViIiIiIkNickNERESSwuSGiIiIJIXJDREREUkKkxsiIiKSFCY3REREJClMboiIiEhSmNwQERGRpDC5ISIiIkkx+/YLplawIHN6erqZIyEiIiJdFXxv67KxQrlLbjIyMgAASqXSzJEQERGRvjIyMuDs7FxinXK3t5RarcadO3fg6OgImUxm0HOnp6dDqVTi5s2b3LfKiNjOpsF2Ng22s+mwrU3DWO0shEBGRgaqVq2qtaF2Ucpdz42VlRWqVatm1Gs4OTnxg2MCbGfTYDubBtvZdNjWpmGMdn5ej00BDigmIiIiSWFyQ0RERJLC5MaAFAoFoqKioFAozB2KpLGdTYPtbBpsZ9NhW5tGWWjncjegmIiIiKSNPTdEREQkKUxuiIiISFKY3BAREZGkMLkhIiIiSWFyo6dly5bBx8cHdnZ2CAgIwNGjR0usv3nzZtSvXx92dnZo3Lgxdu/ebaJILZs+7bxy5UoEBgbC1dUVrq6uCAoKeu7Phf6l7+9zgY0bN0Imk6Fnz57GDVAi9G3nR48eYeTIkfDy8oJCoUDdunX5b4cO9G3nxYsXo169erC3t4dSqcTYsWORnZ1tomgt06+//opu3bqhatWqkMlk2LFjx3OPOXjwIJo3bw6FQoHatWsjJibG6HFCkM42btwo5HK5WL16tfjrr7/EkCFDhIuLi0hJSSmy/pEjR4S1tbX45JNPxPnz58WUKVOEra2tOHv2rIkjtyz6tnPfvn3FsmXLxKlTp8SFCxfEwIEDhbOzs7h165aJI7cs+rZzgevXrwtvb28RGBgoevToYZpgLZi+7ZyTkyP8/f3Fa6+9Jg4fPiyuX78uDh48KE6fPm3iyC2Lvu28fv16oVAoxPr168X169fFnj17hJeXlxg7dqyJI7csu3fvFpMnTxbbtm0TAMT27dtLrH/t2jVRoUIFMW7cOHH+/Hnx+eefC2traxEfH2/UOJnc6KFly5Zi5MiRmucqlUpUrVpVREdHF1m/d+/e4vXXX9cqCwgIEB988IFR47R0+rbzs/Lz84Wjo6P45ptvjBWiJJSmnfPz80Xr1q3FqlWrRGhoKJMbHejbzl9++aWoWbOmyM3NNVWIkqBvO48cOVJ06tRJq2zcuHGiTZs2Ro1TSnRJbj766CPRsGFDrbKQkBARHBxsxMiE4G0pHeXm5uLEiRMICgrSlFlZWSEoKAgJCQlFHpOQkKBVHwCCg4OLrU+la+dnPXnyBHl5eahUqZKxwrR4pW3nGTNmwN3dHYMHDzZFmBavNO0cFxeHVq1aYeTIkfDw8ECjRo0wZ84cqFQqU4VtcUrTzq1bt8aJEyc0t66uXbuG3bt347XXXjNJzOWFub4Hy93GmaWVmpoKlUoFDw8PrXIPDw9cvHixyGOSk5OLrJ+cnGy0OC1dadr5WR9//DGqVq1a6ANF/ylNOx8+fBhff/01Tp8+bYIIpaE07Xzt2jX8/PPP6NevH3bv3o2rV69ixIgRyMvLQ1RUlCnCtjilaee+ffsiNTUVbdu2hRAC+fn5GDZsGCZNmmSKkMuN4r4H09PTkZWVBXt7e6Nclz03JClz587Fxo0bsX37dtjZ2Zk7HMnIyMhA//79sXLlSri5uZk7HElTq9Vwd3fHihUr4Ofnh5CQEEyePBnLly83d2iScvDgQcyZMwdffPEFTp48iW3btmHXrl2YOXOmuUMjA2DPjY7c3NxgbW2NlJQUrfKUlBR4enoWeYynp6de9al07Vzg008/xdy5c7Fv3z40adLEmGFaPH3bOTExEUlJSejWrZumTK1WAwBsbGxw6dIl1KpVy7hBW6DS/D57eXnB1tYW1tbWmrIGDRogOTkZubm5kMvlRo3ZEpWmnadOnYr+/fvj/fffBwA0btwYmZmZGDp0KCZPngwrK/7tbwjFfQ86OTkZrdcGYM+NzuRyOfz8/LB//35NmVqtxv79+9GqVasij2nVqpVWfQDYu3dvsfWpdO0MAJ988glmzpyJ+Ph4+Pv7myJUi6ZvO9evXx9nz57F6dOnNY/u3bujY8eOOH36NJRKpSnDtxil+X1u06YNrl69qkkeAeDy5cvw8vJiYlOM0rTzkydPCiUwBQml4JaLBmO270GjDleWmI0bNwqFQiFiYmLE+fPnxdChQ4WLi4tITk4WQgjRv39/ERERoal/5MgRYWNjIz799FNx4cIFERUVxangOtC3nefOnSvkcrnYsmWLuHv3ruaRkZFhrrdgEfRt52dxtpRu9G3nGzduCEdHRxEeHi4uXbokfvjhB+Hu7i5mzZplrrdgEfRt56ioKOHo6Ci+++47ce3aNfHTTz+JWrVqid69e5vrLViEjIwMcerUKXHq1CkBQCxcuFCcOnVK/P3330IIISIiIkT//v019Qumgk+YMEFcuHBBLFu2jFPBy6LPP/9cvPTSS0Iul4uWLVuK33//XfNa+/btRWhoqFb9TZs2ibp16wq5XC4aNmwodu3aZeKILZM+7Vy9enUBoNAjKirK9IFbGH1/n5/G5EZ3+rbzb7/9JgICAoRCoRA1a9YUs2fPFvn5+SaO2vLo0855eXli2rRpolatWsLOzk4olUoxYsQI8fDhQ9MHbkEOHDhQ5L+3BW0bGhoq2rdvX+iYZs2aCblcLmrWrCnWrFlj9DhlQrD/jYiIiKSDY26IiIhIUpjcEBERkaQwuSEiIiJJYXJDREREksLkhoiIiCSFyQ0RERFJCpMbIiIikhQmN0SkJSYmBi4uLuYOo9RkMhl27NhRYp2BAweiZ8+eJomHiEyPyQ2RBA0cOBAymazQ4+rVq+YODTExMZp4rKysUK1aNYSFheHevXsGOf/du3fRtWtXAEBSUhJkMhlOnz6tVWfJkiWIiYkxyPWKM23aNM37tLa2hlKpxNChQ/HgwQO9zsNEjEh/3BWcSKK6dOmCNWvWaJVVqVLFTNFoc3JywqVLl6BWq3HmzBmEhYXhzp072LNnzwuf+3m7xwOAs7PzC19HFw0bNsS+ffugUqlw4cIFDBo0CGlpaYiNjTXJ9YnKK/bcEEmUQqGAp6en1sPa2hoLFy5E48aN4eDgAKVSiREjRuDx48fFnufMmTPo2LEjHB0d4eTkBD8/Pxw/flzz+uHDhxEYGAh7e3solUqMHj0amZmZJcYmk8ng6emJqlWromvXrhg9ejT27duHrKwsqNVqzJgxA9WqVYNCoUCzZs0QHx+vOTY3Nxfh4eHw8vKCnZ0dqlevjujoaK1zF9yWqlGjBgDg5ZdfhkwmQ4cOHQBo94asWLECVatW1dqFGwB69OiBQYMGaZ5///33aN68Oezs7FCzZk1Mnz4d+fn5Jb5PGxsbeHp6wtvbG0FBQejVqxf27t2reV2lUmHw4MGoUaMG7O3tUa9ePSxZskTz+rRp0/DNN9/g+++/1/QCHTx4EABw8+ZN9O7dGy4uLqhUqRJ69OiBpKSkEuMhKi+Y3BCVM1ZWVvjss8/w119/4ZtvvsHPP/+Mjz76qNj6/fr1Q7Vq1XDs2DGcOHECERERsLW1BQAkJiaiS5cuePvtt/Hnn38iNjYWhw8fRnh4uF4x2dvbQ61WIz8/H0uWLMGCBQvw6aef4s8//0RwcDC6d++OK1euAAA+++wzxMXFYdOmTbh06RLWr18PHx+fIs979OhRAMC+fftw9+5dbNu2rVCdXr164Z9//sGBAwc0ZQ8ePEB8fDz69esHADh06BAGDBiAMWPG4Pz58/jqq68QExOD2bNn6/wek5KSsGfPHsjlck2ZWq1GtWrVsHnzZpw/fx6RkZGYNGkSNm3aBAAYP348evfujS5duuDu3bu4e/cuWrdujby8PAQHB8PR0RGHDh3CkSNHULFiRXTp0gW5ubk6x0QkWUbfmpOITC40NFRYW1sLBwcHzeOdd94psu7mzZtF5cqVNc/XrFkjnJ2dNc8dHR1FTExMkccOHjxYDB06VKvs0KFDwsrKSmRlZRV5zLPnv3z5sqhbt67w9/cXQghRtWpVMXv2bK1jWrRoIUaMGCGEEGLUqFGiU6dOQq1WF3l+AGL79u1CCCGuX78uAIhTp05p1Xl2R/MePXqIQYMGaZ5/9dVXomrVqkKlUgkhhOjcubOYM2eO1jnWrVsnvLy8ioxBCCGioqKElZWVcHBwEHZ2dprdkxcuXFjsMUIIMXLkSPH2228XG2vBtevVq6fVBjk5OcLe3l7s2bOnxPMTlQccc0MkUR07dsSXX36pee7g4ADg316M6OhoXLx4Eenp6cjPz0d2djaePHmCChUqFDrPuHHj8P7772PdunWaWyu1atUC8O8tqz///BPr16/X1BdCQK1W4/r162jQoEGRsaWlpaFixYpQq9XIzs5G27ZtsWrVKqSnp+POnTto06aNVv02bdrgzJkzAP69pfTKK6+gXr166NKlC9544w28+uqrL9RW/fr1w5AhQ/DFF19AoVBg/fr16NOnD6ysrDTv88iRI1o9NSqVqsR2A4B69eohLi4O2dnZ+Pbbb3H69GmMGjVKq86yZcuwevVq3LhxA1lZWcjNzUWzZs1KjPfMmTO4evUqHB0dtcqzs7ORmJhYihYgkhYmN0QS5eDggNq1a2uVJSUl4Y033sDw4cMxe/ZsVKpUCYcPH8bgwYORm5tb5Jf0tGnT0LdvX+zatQs//vgjoqKisHHjRrz55pt4/PgxPvjgA4wePbrQcS+99FKxsTk6OuLkyZOwsrKCl5cX7O3tAQDp6enPfV/NmzfH9evX8eOPP2Lfvn3o3bs3goKCsGXLluceW5xu3bpBCIFdu3ahRYsWOHToEBYtWqR5/fHjx5g+fTreeuutQsfa2dkVe165XK75GcydOxevv/46pk+fjpkzZwIANm7ciPHjx2PBggVo1aoVHB0dMX/+fPzxxx8lxvv48WP4+flpJZUFysqgcSJzYnJDVI6cOHECarUaCxYs0PRKFIzvKEndunVRt25djB07Fu+++y7WrFmDN998E82bN8f58+cLJVHPY2VlVeQxTk5OqFq1Ko4cOYL27dtryo8cOYKWLVtq1QsJCUFISAjeeecddOnSBQ8ePEClSpW0zlcwvkWlUpUYj52dHd566y2sX78eV69eRb169dC8eXPN682bN8elS5f0fp/PmjJlCjp16oThw4dr3mfr1q0xYsQITZ1ne17kcnmh+Js3b47Y2Fi4u7vDycnphWIikiIOKCYqR2rXro28vDx8/vnnuHbtGtatW4fly5cXWz8rKwvh4eE4ePAg/v77bxw5cgTHjh3T3G76+OOP8dtvvyE8PBynT5/GlStX8P333+s9oPhpEyZMwLx58xAbG4tLly4hIiICp0+fxpgxYwAACxcuxHfffYeLFy/i8uXL2Lx5Mzw9PYtceNDd3R329vaIj49HSkoK0tLSir1uv379sGvXLqxevVozkLhAZGQk1q5di+nTp+Ovv/7ChQsXsHHjRkyZMkWv99aqVSs0adIEc+bMAQDUqVMHx48fx549e3D58mVMnToVx44d0zrGx8cHf/75Jy5duoTU1FTk5eWhX79+cHNzQ48ePXDo0CFcv34dBw8exOjRo3Hr1i29YiKSJHMP+iEiwytqEGqBhQsXCi8vL2Fvby+Cg4PF2rVrBQDx8OFDIYT2gN+cnBzRp08foVQqhVwuF1WrVhXh4eFag4WPHj0qXnnlFVGxYkXh4OAgmjRpUmhA8NOeHVD8LJVKJaZNmya8vb2Fra2taNq0qfjxxx81r69YsUI0a9ZMODg4CCcnJ9G5c2dx8uRJzet4akCxEEKsXLlSKJVKYWVlJdq3b19s+6hUKuHl5SUAiMTExEJxxcfHi9atWwt7e3vh5OQkWrZsKVasWFHs+4iKihJNmzYtVP7dd98JhUIhbty4IbKzs8XAgQOFs7OzcHFxEcOHDxcRERFax927d0/TvgDEgQMHhBBC3L17VwwYMEC4ubkJhUIhatasKYYMGSLS0tKKjYmovJAJIYR50ysiIiIiw+FtKSIiIpIUJjdEREQkKUxuiIiISFKY3BAREZGkMLkhIiIiSWFyQ0RERJLC5IaIiIgkhckNERERSQqTGyIiIpIUJjdEREQkKUxuiIiISFKY3BAREZGk/D+iP+tqca/qGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == .5).any(axis=1)]\n",
    "print(len(df))\n",
    "# df = df[~(df == -20).any(axis=1)]\n",
    "df = df[(df['tourney_level'] == 6)]\n",
    "# df = df[(df['surface_Hard'] == 1.0)]\n",
    "\n",
    "# df = df.drop(df.columns[df.columns.str.contains('_rd')], axis=1)\n",
    "\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set target accuracy# Set target AUC# Set target AUC\n",
    "# Set target AUC\n",
    "target_auc = 0.825\n",
    "\n",
    "final_auc = 0.0\n",
    "final_acc = 0.0\n",
    "while final_auc < target_auc:\n",
    "    best_auc, best_acc, best_model_weights = cross_validate(OutcomeProbabilityV6, X_train, y_train, epochs=100, target_auc=target_auc)\n",
    "    print(f\"Best cross-validated AUC: {best_auc:.4f}\")\n",
    "    print(f\"Best cross-validated accuracy: {best_acc*100:.2f}%\")\n",
    "\n",
    "    # Final training on full training data\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    val_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = OutcomeProbabilityV6(input_dim=X.shape[1])\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    final_auc, final_acc, _ = train_and_evaluate(model, train_loader, val_loader, epochs=100, target_auc=target_auc)\n",
    "    print(f\"Final model AUC on test set: {final_auc:.4f}\")\n",
    "    print(f\"Final model accuracy on test set: {final_acc*100:.2f}%\")\n",
    "\n",
    "    if final_auc < target_auc:\n",
    "        print(f\"AUC {final_auc:.4f} not met, restarting the process.\")\n",
    "    # Quick train break\n",
    "    # break\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate and store predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_test_np = y_test_tensor.numpy()\n",
    "    odds_test = odds_df.loc[idx_test].values\n",
    "\n",
    "    # Create DataFrame with predictions and actual values\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test_np.flatten(),\n",
    "        'Predicted': y_pred.flatten(),\n",
    "        'A_Odds': odds_test[:, 0],\n",
    "        'B_Odds': odds_test[:, 1]\n",
    "    })\n",
    "\n",
    "    # Optionally save to CSV\n",
    "    results_df.to_csv('predictions_with_odds.csv', index=False)\n",
    "\n",
    "# Plot ROC curve\n",
    "with torch.no_grad():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_tensor, y_pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted  A_Odds  B_Odds\n",
      "0       0.0   0.106825   13.40    1.02\n",
      "1       0.0   0.627703    2.39    1.56\n",
      "2       0.0   0.559063    2.33    1.60\n",
      "3       1.0   0.673873    1.70    2.13\n",
      "4       0.0   0.039891   12.24    1.04\n",
      "..      ...        ...     ...     ...\n",
      "298     1.0   0.405294    2.02    1.77\n",
      "299     1.0   0.838449    1.33    3.31\n",
      "300     1.0   0.594029    1.25    3.94\n",
      "301     0.0   0.347922    1.96    1.91\n",
      "302     0.0   0.332293    2.81    1.42\n",
      "\n",
      "[303 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    corrected = vegas_odds - 1\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = calculated_probability - ((1 - calculated_probability)/corrected)\n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total returned on Starting $10 bankroll: 0.62 on a total # bets: 103 from a total of 303 games\n",
      "ROI : -0.9 X\n",
      "Avg Bankroll Bet % : 0.247 %\n",
      "Amount of differing favorites %: 0.109\n",
      "Amount of upset bets correct % : 0.545 with Unit $10 won $41.16 on 33 bets\n",
      "Amount of incorrect bet % : 0.4078\n",
      "Correct Bet %: 0.5922\n",
      "Model % Correct : 0.7624 Vegas Correct % : 0.7624\n"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "avg_bet = 0\n",
    "\n",
    "confidence_pct = .5\n",
    "confidence_top_pct = 1\n",
    "\n",
    "START_UNIT = 10\n",
    "UNIT = START_UNIT\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "    current = START_UNIT\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :\n",
    "        kelly = (kelly_criterion(row['A_Odds'], row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['A_Odds'], row['Predicted'])\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['A_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :\n",
    "        kelly = (kelly_criterion(row['B_Odds'], 1-row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['B_Odds'], 1-row['Predicted'])\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['B_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        kelly_A  = (kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        kelly_B  = (kelly_criterion(row['B_Odds'],1-row['Predicted']) * UNIT)\n",
    "\n",
    "        upset_predict += 1 if (kelly_A > 0 and round(row['Predicted']) == 1) or (kelly_B > 0 and round(row['Predicted']) == 0) else 0\n",
    "\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_correct += 1 if kelly_A > 0 else 0\n",
    "                upset_won += (row['A_Odds']-1) * kelly_A\n",
    "            else:\n",
    "                upset_correct += 1 if kelly_B > 0 else 0\n",
    "                upset_won += (row['B_Odds']-1) * kelly_B\n",
    "        elif round(row['Predicted']) == 1:\n",
    "            upset_won -= kelly_A\n",
    "        else:\n",
    "            upset_won -= kelly_B\n",
    "            \n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total returned on Starting ${UNIT} bankroll: {START_UNIT:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"ROI : {((START_UNIT-UNIT)/UNIT):.1f} X\")\n",
    "print(f\"Avg Bankroll Bet % : {(avg_bet/better):.3f} %\")\n",
    "print(f\"Amount of differing favorites %: {(diff_fav/length):.3f}\")\n",
    "print(f\"Amount of upset bets correct % : {(upset_correct/upset_predict):.3f} with Unit ${UNIT} won ${upset_won:.2f} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bet % : {(wrong/better):.4f}\")\n",
    "print(f\"Correct Bet %: {(bet_correct/better):.4f}\")\n",
    "print(f\"Model % Correct : {(model_correct/length):.4f} Vegas Correct % : {(vegas_correct/length):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
