{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20120101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36152\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "df = pd.read_csv('../testcsvs/glickoUpdated.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "df = df[(df['a_glicko_rd'] <= 150) & (df['b_glicko_rd'] <= 150)]\n",
    "\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "\n",
    "# df = pd.DataFrame(games).drop(['tourney_id', 'tourney_name', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug','a_win_percent', 'a_serve_rating', 'a_return_rating', 'a_pressure_rating', 'a_avg_vs_elo', 'a_matches_played', 'b_win_percent', 'b_serve_rating', 'b_return_rating', 'b_pressure_rating', 'b_avg_vs_elo', 'b_matches_played', 'A_Odds', 'b_odds'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>glicko_rating_diff</th>\n",
       "      <th>a_glicko_rating</th>\n",
       "      <th>b_glicko_rating</th>\n",
       "      <th>a_glicko_rd</th>\n",
       "      <th>b_glicko_rd</th>\n",
       "      <th>point_glicko_rating_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_second_won_glicko_rd</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>176.593829</td>\n",
       "      <td>1839.861621</td>\n",
       "      <td>1663.267792</td>\n",
       "      <td>66.538515</td>\n",
       "      <td>69.504749</td>\n",
       "      <td>17.195158</td>\n",
       "      <td>...</td>\n",
       "      <td>1527.112461</td>\n",
       "      <td>1512.254594</td>\n",
       "      <td>61.417982</td>\n",
       "      <td>64.098589</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-13.189440</td>\n",
       "      <td>1691.756210</td>\n",
       "      <td>1704.945650</td>\n",
       "      <td>68.028270</td>\n",
       "      <td>66.514655</td>\n",
       "      <td>-2.440629</td>\n",
       "      <td>...</td>\n",
       "      <td>1521.146582</td>\n",
       "      <td>1521.385633</td>\n",
       "      <td>61.595829</td>\n",
       "      <td>62.238181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-29.363104</td>\n",
       "      <td>1570.536476</td>\n",
       "      <td>1599.899580</td>\n",
       "      <td>83.222649</td>\n",
       "      <td>70.247487</td>\n",
       "      <td>11.519732</td>\n",
       "      <td>...</td>\n",
       "      <td>1507.472345</td>\n",
       "      <td>1505.737017</td>\n",
       "      <td>65.763955</td>\n",
       "      <td>62.931779</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>83.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-90.648654</td>\n",
       "      <td>1640.541369</td>\n",
       "      <td>1731.190024</td>\n",
       "      <td>70.093654</td>\n",
       "      <td>65.999725</td>\n",
       "      <td>-1.933524</td>\n",
       "      <td>...</td>\n",
       "      <td>1504.850516</td>\n",
       "      <td>1505.706100</td>\n",
       "      <td>63.266721</td>\n",
       "      <td>61.949089</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>305.983939</td>\n",
       "      <td>1851.630880</td>\n",
       "      <td>1545.646941</td>\n",
       "      <td>67.025256</td>\n",
       "      <td>79.728825</td>\n",
       "      <td>36.001091</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.880282</td>\n",
       "      <td>1484.226045</td>\n",
       "      <td>61.482268</td>\n",
       "      <td>63.833433</td>\n",
       "      <td>1.19</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  tourney_round  a_player_rank  b_player_rank  \\\n",
       "5373      3.0            0.8           15.0           74.0   \n",
       "5375      3.0            0.8           65.0           46.0   \n",
       "5377      3.0            0.8           95.0           89.0   \n",
       "5378      3.0            0.8           83.0           48.0   \n",
       "5380      3.0            0.8           22.0           70.0   \n",
       "\n",
       "      glicko_rating_diff  a_glicko_rating  b_glicko_rating  a_glicko_rd  \\\n",
       "5373          176.593829      1839.861621      1663.267792    66.538515   \n",
       "5375          -13.189440      1691.756210      1704.945650    68.028270   \n",
       "5377          -29.363104      1570.536476      1599.899580    83.222649   \n",
       "5378          -90.648654      1640.541369      1731.190024    70.093654   \n",
       "5380          305.983939      1851.630880      1545.646941    67.025256   \n",
       "\n",
       "      b_glicko_rd  point_glicko_rating_diff  ...  \\\n",
       "5373    69.504749                 17.195158  ...   \n",
       "5375    66.514655                 -2.440629  ...   \n",
       "5377    70.247487                 11.519732  ...   \n",
       "5378    65.999725                 -1.933524  ...   \n",
       "5380    79.728825                 36.001091  ...   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rating  \\\n",
       "5373                                1527.112461   \n",
       "5375                                1521.146582   \n",
       "5377                                1507.472345   \n",
       "5378                                1504.850516   \n",
       "5380                                1500.880282   \n",
       "\n",
       "      b_surface_second_won_glicko_rating  \\\n",
       "5373                         1512.254594   \n",
       "5375                         1521.385633   \n",
       "5377                         1505.737017   \n",
       "5378                         1505.706100   \n",
       "5380                         1484.226045   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rd  b_surface_second_won_glicko_rd  \\\n",
       "5373                              61.417982                       64.098589   \n",
       "5375                              61.595829                       62.238181   \n",
       "5377                              65.763955                       62.931779   \n",
       "5378                              63.266721                       61.949089   \n",
       "5380                              61.482268                       63.833433   \n",
       "\n",
       "      a_odds  b_odds  a_b_win  surface_Clay  surface_Grass  surface_Hard  \n",
       "5373    1.28    3.59      1.0           0.0            0.0           1.0  \n",
       "5375     NaN     NaN      1.0           0.0            0.0           1.0  \n",
       "5377    1.59    2.29      1.0           0.0            0.0           1.0  \n",
       "5378    1.54    2.40      1.0           0.0            0.0           1.0  \n",
       "5380    1.19    4.44      1.0           0.0            0.0           1.0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.shortcut = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn(self.fc(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "class OutcomeProbabilityV6(nn.Module):\n",
    "    def __init__(self, input_dim=172, dropout_prob=0.33):\n",
    "        hidden_dim1=input_dim * 2\n",
    "        hidden_dim2=input_dim\n",
    "        hidden_dim3=round(input_dim/2) \n",
    "        super(OutcomeProbabilityV6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(hidden_dim1, hidden_dim1)\n",
    "        self.res_block2 = ResidualBlock(hidden_dim1, hidden_dim2)\n",
    "        self.res_block3 = ResidualBlock(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        \n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, epochs=100, learning_rate=0.0001, weight_decay=1e-5, target_accuracy=0.75):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    best_acc = -np.inf\n",
    "    best_weights = None\n",
    "    early_stopping_patience = 20\n",
    "    early_stopping_counter = 0\n",
    "    current_epoch = 0\n",
    "\n",
    "    while best_acc < target_accuracy and current_epoch < epochs:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                y_pred = model(X_batch)\n",
    "                val_loss += loss_fn(y_pred, y_batch).item() * X_batch.size(0)\n",
    "                predicted = y_pred.round()\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        acc = correct / total\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        # if early_stopping_counter >= early_stopping_patience:\n",
    "        #     print(\"Early stopping triggered\")\n",
    "        #     break\n",
    "\n",
    "        if (current_epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{current_epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {acc*100:.2f}%')\n",
    "\n",
    "        current_epoch += 1\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "def cross_validate(model_class, X, y, folds=5, epochs=100, batch_size=128, target_accuracy=0.75):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    best_acc = 0.0\n",
    "    best_model_weights = None\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        print(f\"Fold {fold + 1}/{folds}\")\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        X_train_fold = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
    "        X_val_fold = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        train_data = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_data = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = model_class(input_dim=X.shape[1])\n",
    "        fold_acc, fold_weights = train_and_evaluate(model, train_loader, val_loader, epochs=epochs, target_accuracy=target_accuracy)\n",
    "        if fold_acc > best_acc:\n",
    "            best_acc = fold_acc\n",
    "            best_model_weights = fold_weights\n",
    "\n",
    "    return best_acc, best_model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6222, Val Loss: 0.6218, Accuracy: 64.72%\n",
      "Epoch [20/100], Loss: 0.6143, Val Loss: 0.6185, Accuracy: 64.97%\n",
      "Epoch [30/100], Loss: 0.6090, Val Loss: 0.6190, Accuracy: 64.68%\n",
      "Epoch [40/100], Loss: 0.6071, Val Loss: 0.6178, Accuracy: 64.75%\n",
      "Epoch [50/100], Loss: 0.6064, Val Loss: 0.6184, Accuracy: 64.68%\n",
      "Epoch [60/100], Loss: 0.6057, Val Loss: 0.6168, Accuracy: 64.82%\n",
      "Epoch [70/100], Loss: 0.6054, Val Loss: 0.6168, Accuracy: 64.64%\n",
      "Epoch [80/100], Loss: 0.6051, Val Loss: 0.6182, Accuracy: 64.72%\n",
      "Epoch [90/100], Loss: 0.6041, Val Loss: 0.6189, Accuracy: 64.79%\n",
      "Epoch [100/100], Loss: 0.6049, Val Loss: 0.6169, Accuracy: 64.72%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6274, Val Loss: 0.6015, Accuracy: 67.05%\n",
      "Epoch [20/100], Loss: 0.6211, Val Loss: 0.5951, Accuracy: 67.91%\n",
      "Epoch [30/100], Loss: 0.6164, Val Loss: 0.5953, Accuracy: 67.52%\n",
      "Epoch [40/100], Loss: 0.6165, Val Loss: 0.5939, Accuracy: 68.31%\n",
      "Epoch [50/100], Loss: 0.6117, Val Loss: 0.5909, Accuracy: 68.31%\n",
      "Epoch [60/100], Loss: 0.6136, Val Loss: 0.5910, Accuracy: 68.02%\n",
      "Epoch [70/100], Loss: 0.6107, Val Loss: 0.5912, Accuracy: 68.20%\n",
      "Epoch [80/100], Loss: 0.6121, Val Loss: 0.5905, Accuracy: 68.20%\n",
      "Epoch [90/100], Loss: 0.6112, Val Loss: 0.5913, Accuracy: 67.88%\n",
      "Epoch [100/100], Loss: 0.6111, Val Loss: 0.5922, Accuracy: 68.34%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6230, Val Loss: 0.6138, Accuracy: 64.72%\n",
      "Epoch [20/100], Loss: 0.6159, Val Loss: 0.6087, Accuracy: 64.86%\n",
      "Epoch [30/100], Loss: 0.6100, Val Loss: 0.6088, Accuracy: 65.65%\n",
      "Epoch [40/100], Loss: 0.6124, Val Loss: 0.6093, Accuracy: 65.79%\n",
      "Epoch [50/100], Loss: 0.6081, Val Loss: 0.6093, Accuracy: 65.47%\n",
      "Epoch [60/100], Loss: 0.6094, Val Loss: 0.6095, Accuracy: 65.11%\n",
      "Epoch [70/100], Loss: 0.6089, Val Loss: 0.6094, Accuracy: 65.25%\n",
      "Epoch [80/100], Loss: 0.6115, Val Loss: 0.6090, Accuracy: 65.40%\n",
      "Epoch [90/100], Loss: 0.6087, Val Loss: 0.6100, Accuracy: 65.43%\n",
      "Epoch [100/100], Loss: 0.6106, Val Loss: 0.6099, Accuracy: 65.54%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6195, Val Loss: 0.6209, Accuracy: 65.03%\n",
      "Epoch [20/100], Loss: 0.6110, Val Loss: 0.6203, Accuracy: 65.10%\n",
      "Epoch [30/100], Loss: 0.6090, Val Loss: 0.6220, Accuracy: 64.52%\n",
      "Epoch [40/100], Loss: 0.6079, Val Loss: 0.6192, Accuracy: 65.06%\n",
      "Epoch [50/100], Loss: 0.6095, Val Loss: 0.6203, Accuracy: 64.60%\n",
      "Epoch [60/100], Loss: 0.6091, Val Loss: 0.6199, Accuracy: 64.81%\n",
      "Epoch [70/100], Loss: 0.6081, Val Loss: 0.6195, Accuracy: 64.60%\n",
      "Epoch [80/100], Loss: 0.6092, Val Loss: 0.6196, Accuracy: 64.63%\n",
      "Epoch [90/100], Loss: 0.6089, Val Loss: 0.6215, Accuracy: 64.74%\n",
      "Epoch [100/100], Loss: 0.6083, Val Loss: 0.6204, Accuracy: 64.85%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6221, Val Loss: 0.6089, Accuracy: 65.75%\n",
      "Epoch [20/100], Loss: 0.6187, Val Loss: 0.6038, Accuracy: 66.25%\n",
      "Epoch [30/100], Loss: 0.6113, Val Loss: 0.6023, Accuracy: 66.54%\n",
      "Epoch [40/100], Loss: 0.6121, Val Loss: 0.6022, Accuracy: 66.03%\n",
      "Epoch [50/100], Loss: 0.6087, Val Loss: 0.6018, Accuracy: 66.75%\n",
      "Epoch [60/100], Loss: 0.6074, Val Loss: 0.6009, Accuracy: 66.64%\n",
      "Epoch [70/100], Loss: 0.6075, Val Loss: 0.6014, Accuracy: 66.61%\n",
      "Epoch [80/100], Loss: 0.6092, Val Loss: 0.6012, Accuracy: 66.64%\n",
      "Epoch [90/100], Loss: 0.6074, Val Loss: 0.6015, Accuracy: 66.50%\n",
      "Epoch [100/100], Loss: 0.6068, Val Loss: 0.6017, Accuracy: 66.54%\n",
      "Best cross-validated accuracy: 68.66%\n",
      "Epoch [10/100], Loss: 0.6091, Val Loss: 0.6003, Accuracy: 68.30%\n",
      "Epoch [20/100], Loss: 0.6070, Val Loss: 0.5997, Accuracy: 68.30%\n",
      "Epoch [30/100], Loss: 0.6071, Val Loss: 0.6000, Accuracy: 68.30%\n",
      "Epoch [40/100], Loss: 0.6048, Val Loss: 0.5998, Accuracy: 68.45%\n",
      "Epoch [50/100], Loss: 0.6078, Val Loss: 0.6006, Accuracy: 68.16%\n",
      "Epoch [60/100], Loss: 0.6091, Val Loss: 0.6001, Accuracy: 68.48%\n",
      "Epoch [70/100], Loss: 0.6072, Val Loss: 0.6000, Accuracy: 68.25%\n",
      "Epoch [80/100], Loss: 0.6083, Val Loss: 0.6003, Accuracy: 68.22%\n",
      "Epoch [90/100], Loss: 0.6068, Val Loss: 0.6001, Accuracy: 68.45%\n",
      "Epoch [100/100], Loss: 0.6079, Val Loss: 0.5999, Accuracy: 68.30%\n",
      "Final model accuracy on test set: 68.59%\n",
      "Accuracy 68.59% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6203, Val Loss: 0.6221, Accuracy: 64.25%\n",
      "Epoch [20/100], Loss: 0.6152, Val Loss: 0.6204, Accuracy: 64.64%\n",
      "Epoch [30/100], Loss: 0.6113, Val Loss: 0.6174, Accuracy: 65.18%\n",
      "Epoch [40/100], Loss: 0.6068, Val Loss: 0.6185, Accuracy: 65.22%\n",
      "Epoch [50/100], Loss: 0.6075, Val Loss: 0.6178, Accuracy: 65.00%\n",
      "Epoch [60/100], Loss: 0.6073, Val Loss: 0.6177, Accuracy: 65.04%\n",
      "Epoch [70/100], Loss: 0.6060, Val Loss: 0.6170, Accuracy: 65.00%\n",
      "Epoch [80/100], Loss: 0.6071, Val Loss: 0.6173, Accuracy: 64.82%\n",
      "Epoch [90/100], Loss: 0.6052, Val Loss: 0.6174, Accuracy: 65.00%\n",
      "Epoch [100/100], Loss: 0.6071, Val Loss: 0.6174, Accuracy: 64.97%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6264, Val Loss: 0.5978, Accuracy: 67.12%\n",
      "Epoch [20/100], Loss: 0.6211, Val Loss: 0.5929, Accuracy: 67.62%\n",
      "Epoch [30/100], Loss: 0.6167, Val Loss: 0.5947, Accuracy: 67.66%\n",
      "Epoch [40/100], Loss: 0.6150, Val Loss: 0.5951, Accuracy: 68.02%\n",
      "Epoch [50/100], Loss: 0.6146, Val Loss: 0.5892, Accuracy: 68.31%\n",
      "Epoch [60/100], Loss: 0.6108, Val Loss: 0.5902, Accuracy: 68.52%\n",
      "Epoch [70/100], Loss: 0.6087, Val Loss: 0.5902, Accuracy: 68.34%\n",
      "Epoch [80/100], Loss: 0.6105, Val Loss: 0.5899, Accuracy: 68.13%\n",
      "Epoch [90/100], Loss: 0.6103, Val Loss: 0.5897, Accuracy: 68.63%\n",
      "Epoch [100/100], Loss: 0.6101, Val Loss: 0.5903, Accuracy: 68.38%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6238, Val Loss: 0.6131, Accuracy: 64.54%\n",
      "Epoch [20/100], Loss: 0.6145, Val Loss: 0.6102, Accuracy: 65.79%\n",
      "Epoch [30/100], Loss: 0.6114, Val Loss: 0.6085, Accuracy: 66.01%\n",
      "Epoch [40/100], Loss: 0.6106, Val Loss: 0.6101, Accuracy: 65.76%\n",
      "Epoch [50/100], Loss: 0.6060, Val Loss: 0.6082, Accuracy: 65.69%\n",
      "Epoch [60/100], Loss: 0.6093, Val Loss: 0.6083, Accuracy: 65.43%\n",
      "Epoch [70/100], Loss: 0.6077, Val Loss: 0.6084, Accuracy: 65.72%\n",
      "Epoch [80/100], Loss: 0.6067, Val Loss: 0.6079, Accuracy: 65.69%\n",
      "Epoch [90/100], Loss: 0.6095, Val Loss: 0.6071, Accuracy: 65.87%\n",
      "Epoch [100/100], Loss: 0.6070, Val Loss: 0.6083, Accuracy: 65.65%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6185, Val Loss: 0.6210, Accuracy: 64.60%\n",
      "Epoch [20/100], Loss: 0.6103, Val Loss: 0.6214, Accuracy: 64.34%\n",
      "Epoch [30/100], Loss: 0.6062, Val Loss: 0.6212, Accuracy: 64.34%\n",
      "Epoch [40/100], Loss: 0.6063, Val Loss: 0.6219, Accuracy: 64.96%\n",
      "Epoch [50/100], Loss: 0.6090, Val Loss: 0.6214, Accuracy: 64.56%\n",
      "Epoch [60/100], Loss: 0.6079, Val Loss: 0.6231, Accuracy: 64.42%\n",
      "Epoch [70/100], Loss: 0.6083, Val Loss: 0.6215, Accuracy: 64.78%\n",
      "Epoch [80/100], Loss: 0.6083, Val Loss: 0.6224, Accuracy: 64.88%\n",
      "Epoch [90/100], Loss: 0.6051, Val Loss: 0.6220, Accuracy: 64.42%\n",
      "Epoch [100/100], Loss: 0.6069, Val Loss: 0.6222, Accuracy: 64.45%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6219, Val Loss: 0.6070, Accuracy: 65.31%\n",
      "Epoch [20/100], Loss: 0.6185, Val Loss: 0.6041, Accuracy: 65.71%\n",
      "Epoch [30/100], Loss: 0.6164, Val Loss: 0.6030, Accuracy: 66.39%\n",
      "Epoch [40/100], Loss: 0.6128, Val Loss: 0.6032, Accuracy: 66.25%\n",
      "Epoch [50/100], Loss: 0.6095, Val Loss: 0.6017, Accuracy: 66.32%\n",
      "Epoch [60/100], Loss: 0.6075, Val Loss: 0.6020, Accuracy: 66.32%\n",
      "Epoch [70/100], Loss: 0.6081, Val Loss: 0.6017, Accuracy: 66.39%\n",
      "Epoch [80/100], Loss: 0.6070, Val Loss: 0.6016, Accuracy: 66.43%\n",
      "Epoch [90/100], Loss: 0.6074, Val Loss: 0.6018, Accuracy: 66.28%\n",
      "Epoch [100/100], Loss: 0.6048, Val Loss: 0.6022, Accuracy: 66.10%\n",
      "Best cross-validated accuracy: 68.66%\n",
      "Epoch [10/100], Loss: 0.6076, Val Loss: 0.5988, Accuracy: 68.10%\n",
      "Epoch [20/100], Loss: 0.6072, Val Loss: 0.6007, Accuracy: 67.56%\n",
      "Epoch [30/100], Loss: 0.6048, Val Loss: 0.5995, Accuracy: 68.13%\n",
      "Epoch [40/100], Loss: 0.6041, Val Loss: 0.5999, Accuracy: 68.22%\n",
      "Epoch [50/100], Loss: 0.6050, Val Loss: 0.5998, Accuracy: 68.07%\n",
      "Epoch [60/100], Loss: 0.6059, Val Loss: 0.5997, Accuracy: 67.99%\n",
      "Epoch [70/100], Loss: 0.6046, Val Loss: 0.5997, Accuracy: 68.10%\n",
      "Epoch [80/100], Loss: 0.6041, Val Loss: 0.5996, Accuracy: 68.04%\n",
      "Epoch [90/100], Loss: 0.6047, Val Loss: 0.5998, Accuracy: 68.16%\n",
      "Epoch [100/100], Loss: 0.6045, Val Loss: 0.5995, Accuracy: 68.02%\n",
      "Final model accuracy on test set: 68.53%\n",
      "Accuracy 68.53% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6169, Val Loss: 0.6215, Accuracy: 64.90%\n",
      "Epoch [20/100], Loss: 0.6117, Val Loss: 0.6198, Accuracy: 64.54%\n",
      "Epoch [30/100], Loss: 0.6078, Val Loss: 0.6190, Accuracy: 64.57%\n",
      "Epoch [40/100], Loss: 0.6078, Val Loss: 0.6172, Accuracy: 64.72%\n",
      "Epoch [50/100], Loss: 0.6087, Val Loss: 0.6176, Accuracy: 64.82%\n",
      "Epoch [60/100], Loss: 0.6069, Val Loss: 0.6160, Accuracy: 65.08%\n",
      "Epoch [70/100], Loss: 0.6081, Val Loss: 0.6176, Accuracy: 64.72%\n",
      "Epoch [80/100], Loss: 0.6080, Val Loss: 0.6195, Accuracy: 64.54%\n",
      "Epoch [90/100], Loss: 0.6077, Val Loss: 0.6179, Accuracy: 65.15%\n",
      "Epoch [100/100], Loss: 0.6079, Val Loss: 0.6178, Accuracy: 64.79%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6279, Val Loss: 0.5972, Accuracy: 67.73%\n",
      "Epoch [20/100], Loss: 0.6194, Val Loss: 0.5926, Accuracy: 67.48%\n",
      "Epoch [30/100], Loss: 0.6164, Val Loss: 0.5954, Accuracy: 67.73%\n",
      "Epoch [40/100], Loss: 0.6140, Val Loss: 0.5910, Accuracy: 68.45%\n",
      "Epoch [50/100], Loss: 0.6132, Val Loss: 0.5919, Accuracy: 67.84%\n",
      "Epoch [60/100], Loss: 0.6136, Val Loss: 0.5903, Accuracy: 68.23%\n",
      "Epoch [70/100], Loss: 0.6132, Val Loss: 0.5905, Accuracy: 68.38%\n",
      "Epoch [80/100], Loss: 0.6131, Val Loss: 0.5909, Accuracy: 68.34%\n",
      "Epoch [90/100], Loss: 0.6126, Val Loss: 0.5910, Accuracy: 68.13%\n",
      "Epoch [100/100], Loss: 0.6143, Val Loss: 0.5911, Accuracy: 68.31%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6243, Val Loss: 0.6147, Accuracy: 64.14%\n",
      "Epoch [20/100], Loss: 0.6140, Val Loss: 0.6104, Accuracy: 65.43%\n",
      "Epoch [30/100], Loss: 0.6126, Val Loss: 0.6078, Accuracy: 65.47%\n",
      "Epoch [40/100], Loss: 0.6093, Val Loss: 0.6081, Accuracy: 65.76%\n",
      "Epoch [50/100], Loss: 0.6090, Val Loss: 0.6077, Accuracy: 66.04%\n",
      "Epoch [60/100], Loss: 0.6064, Val Loss: 0.6073, Accuracy: 65.87%\n",
      "Epoch [70/100], Loss: 0.6081, Val Loss: 0.6071, Accuracy: 65.83%\n",
      "Epoch [80/100], Loss: 0.6078, Val Loss: 0.6068, Accuracy: 65.94%\n",
      "Epoch [90/100], Loss: 0.6066, Val Loss: 0.6067, Accuracy: 65.97%\n",
      "Epoch [100/100], Loss: 0.6055, Val Loss: 0.6066, Accuracy: 66.30%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6234, Val Loss: 0.6185, Accuracy: 64.34%\n",
      "Epoch [20/100], Loss: 0.6160, Val Loss: 0.6187, Accuracy: 64.52%\n",
      "Epoch [30/100], Loss: 0.6082, Val Loss: 0.6196, Accuracy: 64.74%\n",
      "Epoch [40/100], Loss: 0.6094, Val Loss: 0.6193, Accuracy: 64.56%\n",
      "Epoch [50/100], Loss: 0.6066, Val Loss: 0.6196, Accuracy: 64.92%\n",
      "Epoch [60/100], Loss: 0.6111, Val Loss: 0.6205, Accuracy: 64.34%\n",
      "Epoch [70/100], Loss: 0.6070, Val Loss: 0.6197, Accuracy: 64.38%\n",
      "Epoch [80/100], Loss: 0.6064, Val Loss: 0.6204, Accuracy: 64.70%\n",
      "Epoch [90/100], Loss: 0.6092, Val Loss: 0.6197, Accuracy: 64.92%\n",
      "Epoch [100/100], Loss: 0.6097, Val Loss: 0.6197, Accuracy: 64.78%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6230, Val Loss: 0.6126, Accuracy: 65.17%\n",
      "Epoch [20/100], Loss: 0.6152, Val Loss: 0.6031, Accuracy: 66.03%\n",
      "Epoch [30/100], Loss: 0.6138, Val Loss: 0.6036, Accuracy: 66.18%\n",
      "Epoch [40/100], Loss: 0.6098, Val Loss: 0.6034, Accuracy: 66.03%\n",
      "Epoch [50/100], Loss: 0.6104, Val Loss: 0.6022, Accuracy: 66.32%\n",
      "Epoch [60/100], Loss: 0.6101, Val Loss: 0.6018, Accuracy: 66.39%\n",
      "Epoch [70/100], Loss: 0.6096, Val Loss: 0.6018, Accuracy: 66.50%\n",
      "Epoch [80/100], Loss: 0.6086, Val Loss: 0.6021, Accuracy: 66.64%\n",
      "Epoch [90/100], Loss: 0.6102, Val Loss: 0.6019, Accuracy: 66.46%\n",
      "Epoch [100/100], Loss: 0.6094, Val Loss: 0.6021, Accuracy: 66.50%\n",
      "Best cross-validated accuracy: 68.66%\n",
      "Epoch [10/100], Loss: 0.6099, Val Loss: 0.6010, Accuracy: 67.99%\n",
      "Epoch [20/100], Loss: 0.6075, Val Loss: 0.6002, Accuracy: 68.50%\n",
      "Final model accuracy on test set: 68.82%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == .5).any(axis=1)]\n",
    "# df = df[~(df == -20).any(axis=1)]\n",
    "# df = df[(df['surface_Hard'] == 1.0)]\n",
    "\n",
    "\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set target accuracy\n",
    "target_accuracy = 0.688\n",
    "\n",
    "final_acc = 0.0\n",
    "while final_acc < target_accuracy:\n",
    "    best_acc, best_model_weights = cross_validate(OutcomeProbabilityV6, X_train, y_train, epochs=100, target_accuracy=target_accuracy)\n",
    "    print(f\"Best cross-validated accuracy: {best_acc*100:.2f}%\")\n",
    "\n",
    "    # Final training on full training data\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    val_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = OutcomeProbabilityV6(input_dim=X.shape[1])\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    final_acc, _ = train_and_evaluate(model, train_loader, val_loader, epochs=100, target_accuracy=target_accuracy)\n",
    "    print(f\"Final model accuracy on test set: {final_acc*100:.2f}%\")\n",
    "\n",
    "    if final_acc < target_accuracy:\n",
    "        print(f\"Accuracy {final_acc*100:.2f}% not met, restarting the process.\")\n",
    "    # Quick train break\n",
    "    # break\n",
    "\n",
    "# Evaluate and store predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_test_np = y_test_tensor.numpy()\n",
    "    odds_test = odds_df.loc[idx_test].values\n",
    "\n",
    "    # Create DataFrame with predictions and actual values\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test_np.flatten(),\n",
    "        'Predicted': y_pred.flatten(),\n",
    "        'A_Odds': odds_test[:, 0],\n",
    "        'B_Odds': odds_test[:, 1]\n",
    "    })\n",
    "\n",
    "    # Optionally save to CSV\n",
    "    results_df.to_csv('predictions_with_odds.csv', index=False)\n",
    "\n",
    "# Plot ROC curve\n",
    "with torch.no_grad():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_tensor, y_pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  A_Odds  B_Odds\n",
      "0        1.0   0.755534    1.11    6.73\n",
      "1        1.0   0.541769    1.67    2.15\n",
      "2        0.0   0.705679    1.51    2.48\n",
      "3        1.0   0.398880    2.70    1.43\n",
      "4        1.0   0.711706    1.71    2.10\n",
      "...      ...        ...     ...     ...\n",
      "3478     0.0   0.194122    2.61    1.47\n",
      "3479     0.0   0.464807    2.63    1.48\n",
      "3480     0.0   0.402206    3.26    1.32\n",
      "3481     0.0   0.412963    2.35    1.58\n",
      "3482     1.0   0.430298    1.36    3.05\n",
      "\n",
      "[3483 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = (vegas_odds * calculated_probability - (1 - calculated_probability)) / vegas_odds\n",
    "    \n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total won on $10 bets: 189.00 on a total # bets: 158 from a total of 3483 games\n",
      "Amount of differing favorites 0.13149583692219352\n",
      "Amount of upset correct 0.4432314410480349 won $-67.79999999999995 on 458 bets\n",
      "Amount of incorrect bets : 0.47468354430379744\n",
      "Correct Bets: 0.5253164556962026\n",
      "Model % Correct : 0.6881998277347114 Vegas Correct % : 0.7025552684467413\n"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "confidence_pct = .55\n",
    "confidence_top_pct = .6\n",
    "\n",
    "UNIT = 10\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct and row['Predicted'] > 1/row['A_Odds'] + .03:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1\n",
    "            total_won += (row['A_Odds']-1) * UNIT #(kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= UNIT #(kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct and 1-row['Predicted'] > 1/row['B_Odds']+ .03:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1\n",
    "            total_won += (row['B_Odds']-1) * UNIT #(kelly_criterion(row['B_Odds'],row['Predicted']) * UNIT)\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= UNIT #(kelly_criterion(row['B_Odds'],row['Predicted']) * UNIT)\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        upset_predict += 1\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            upset_correct += 1\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_won += (row['A_Odds']-1) * UNIT\n",
    "            else:\n",
    "                upset_won += (row['B_Odds']-1) * UNIT\n",
    "        else:\n",
    "            upset_won -= UNIT\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total won on ${UNIT} bets: {total_won:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"Amount of differing favorites {diff_fav/length}\")\n",
    "print(f\"Amount of upset correct {upset_correct/upset_predict} won ${upset_won} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bets : {wrong/better}\")\n",
    "print(f\"Correct Bets: {bet_correct/better}\")\n",
    "print(f\"Model % Correct : {model_correct/length} Vegas Correct % : {vegas_correct/length}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
