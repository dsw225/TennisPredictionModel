{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20120101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32397\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "RD_CUTOFF = 125\n",
    "\n",
    "df = pd.read_csv('../testcsvs/glickoUpdated.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "df = df[(df['a_surface_glicko_rd'] <= RD_CUTOFF) & (df['b_surface_glicko_rd'] <= RD_CUTOFF) & (df['a_glicko_rd'] <= RD_CUTOFF) & (df['b_glicko_rd'] <= RD_CUTOFF)]\n",
    "\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_age</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>b_player_age</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>glicko_rating_diff</th>\n",
       "      <th>a_glicko_rating</th>\n",
       "      <th>b_glicko_rating</th>\n",
       "      <th>a_glicko_rd</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_second_won_glicko_rd</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-156.391443</td>\n",
       "      <td>1648.533408</td>\n",
       "      <td>1804.924851</td>\n",
       "      <td>73.590383</td>\n",
       "      <td>...</td>\n",
       "      <td>1509.676357</td>\n",
       "      <td>1525.177533</td>\n",
       "      <td>68.224718</td>\n",
       "      <td>63.306180</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.779397</td>\n",
       "      <td>1684.801531</td>\n",
       "      <td>1682.022134</td>\n",
       "      <td>68.576543</td>\n",
       "      <td>...</td>\n",
       "      <td>1520.481105</td>\n",
       "      <td>1493.441526</td>\n",
       "      <td>64.043825</td>\n",
       "      <td>72.508115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-61.159514</td>\n",
       "      <td>1621.512570</td>\n",
       "      <td>1682.672084</td>\n",
       "      <td>76.007944</td>\n",
       "      <td>...</td>\n",
       "      <td>1506.545429</td>\n",
       "      <td>1507.882055</td>\n",
       "      <td>67.307645</td>\n",
       "      <td>65.888687</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-65.573917</td>\n",
       "      <td>1697.467187</td>\n",
       "      <td>1763.041103</td>\n",
       "      <td>68.133731</td>\n",
       "      <td>...</td>\n",
       "      <td>1517.206849</td>\n",
       "      <td>1534.732931</td>\n",
       "      <td>63.710167</td>\n",
       "      <td>64.101412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-75.476705</td>\n",
       "      <td>1697.646993</td>\n",
       "      <td>1773.123697</td>\n",
       "      <td>71.445373</td>\n",
       "      <td>...</td>\n",
       "      <td>1494.807275</td>\n",
       "      <td>1535.923504</td>\n",
       "      <td>68.493754</td>\n",
       "      <td>63.744405</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  tourney_round  a_player_age  a_player_rank  b_player_age  \\\n",
       "5373      3.0            0.8          28.0           74.0          23.0   \n",
       "5375      3.0            0.8          28.0           65.0          25.0   \n",
       "5378      3.0            0.8          26.0           83.0          24.0   \n",
       "5381      3.0            0.8          28.0           65.0          27.0   \n",
       "5382      3.0            0.8          29.0           57.0          27.0   \n",
       "\n",
       "      b_player_rank  glicko_rating_diff  a_glicko_rating  b_glicko_rating  \\\n",
       "5373           15.0         -156.391443      1648.533408      1804.924851   \n",
       "5375           46.0            2.779397      1684.801531      1682.022134   \n",
       "5378           48.0          -61.159514      1621.512570      1682.672084   \n",
       "5381           38.0          -65.573917      1697.467187      1763.041103   \n",
       "5382           38.0          -75.476705      1697.646993      1773.123697   \n",
       "\n",
       "      a_glicko_rd  ...  a_surface_return_second_won_glicko_rating  \\\n",
       "5373    73.590383  ...                                1509.676357   \n",
       "5375    68.576543  ...                                1520.481105   \n",
       "5378    76.007944  ...                                1506.545429   \n",
       "5381    68.133731  ...                                1517.206849   \n",
       "5382    71.445373  ...                                1494.807275   \n",
       "\n",
       "      b_surface_second_won_glicko_rating  \\\n",
       "5373                         1525.177533   \n",
       "5375                         1493.441526   \n",
       "5378                         1507.882055   \n",
       "5381                         1534.732931   \n",
       "5382                         1535.923504   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rd  b_surface_second_won_glicko_rd  \\\n",
       "5373                              68.224718                       63.306180   \n",
       "5375                              64.043825                       72.508115   \n",
       "5378                              67.307645                       65.888687   \n",
       "5381                              63.710167                       64.101412   \n",
       "5382                              68.493754                       63.744405   \n",
       "\n",
       "      a_odds  b_odds  a_b_win  surface_Clay  surface_Grass  surface_Hard  \n",
       "5373    3.59    1.28      0.0           0.0            0.0           1.0  \n",
       "5375     NaN     NaN      1.0           0.0            0.0           1.0  \n",
       "5378    1.54    2.40      1.0           0.0            0.0           1.0  \n",
       "5381     NaN     NaN      0.0           0.0            0.0           1.0  \n",
       "5382    2.34    1.56      0.0           0.0            0.0           1.0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.shortcut = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn(self.fc(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "class OutcomeProbabilityV6(nn.Module):\n",
    "    def __init__(self, input_dim=172, dropout_prob=0.33):\n",
    "        hidden_dim1=input_dim * 2\n",
    "        hidden_dim2=input_dim\n",
    "        hidden_dim3=round(input_dim/2) \n",
    "        super(OutcomeProbabilityV6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(hidden_dim1, hidden_dim1)\n",
    "        self.res_block2 = ResidualBlock(hidden_dim1, hidden_dim2)\n",
    "        self.res_block3 = ResidualBlock(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        \n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, epochs=100, learning_rate=0.0001, weight_decay=1e-5, target_accuracy=0.75):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "    best_acc = -np.inf\n",
    "    best_weights = None\n",
    "    early_stopping_patience = 20\n",
    "    early_stopping_counter = 0\n",
    "    current_epoch = 0\n",
    "\n",
    "    while best_acc < target_accuracy and current_epoch < epochs:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                y_pred = model(X_batch)\n",
    "                val_loss += loss_fn(y_pred, y_batch).item() * X_batch.size(0)\n",
    "                predicted = y_pred.round()\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        acc = correct / total\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        # if early_stopping_counter >= early_stopping_patience:\n",
    "        #     print(\"Early stopping triggered\")\n",
    "        #     break\n",
    "\n",
    "        if (current_epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{current_epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {acc*100:.2f}%')\n",
    "\n",
    "        current_epoch += 1\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "def cross_validate(model_class, X, y, folds=5, epochs=100, batch_size=128, target_accuracy=0.75):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    best_acc = 0.0\n",
    "    best_model_weights = None\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        print(f\"Fold {fold + 1}/{folds}\")\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        X_train_fold = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
    "        X_val_fold = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        train_data = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_data = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = model_class(input_dim=X.shape[1])\n",
    "        fold_acc, fold_weights = train_and_evaluate(model, train_loader, val_loader, epochs=epochs, target_accuracy=target_accuracy)\n",
    "        if fold_acc > best_acc:\n",
    "            best_acc = fold_acc\n",
    "            best_model_weights = fold_weights\n",
    "\n",
    "    return best_acc, best_model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6168, Val Loss: 0.5970, Accuracy: 68.31%\n",
      "Epoch [20/100], Loss: 0.6045, Val Loss: 0.5975, Accuracy: 67.54%\n",
      "Epoch [30/100], Loss: 0.5997, Val Loss: 0.5924, Accuracy: 68.31%\n",
      "Epoch [40/100], Loss: 0.5966, Val Loss: 0.5933, Accuracy: 67.16%\n",
      "Epoch [50/100], Loss: 0.5940, Val Loss: 0.5923, Accuracy: 67.99%\n",
      "Epoch [60/100], Loss: 0.5919, Val Loss: 0.5907, Accuracy: 67.41%\n",
      "Epoch [70/100], Loss: 0.5885, Val Loss: 0.5922, Accuracy: 67.41%\n",
      "Epoch [80/100], Loss: 0.5885, Val Loss: 0.5918, Accuracy: 67.99%\n",
      "Epoch [90/100], Loss: 0.5877, Val Loss: 0.5923, Accuracy: 67.67%\n",
      "Epoch [100/100], Loss: 0.5877, Val Loss: 0.5924, Accuracy: 67.61%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6102, Val Loss: 0.6070, Accuracy: 66.58%\n",
      "Epoch [20/100], Loss: 0.5990, Val Loss: 0.6026, Accuracy: 66.45%\n",
      "Epoch [30/100], Loss: 0.5970, Val Loss: 0.6030, Accuracy: 66.84%\n",
      "Epoch [40/100], Loss: 0.5918, Val Loss: 0.6037, Accuracy: 66.65%\n",
      "Epoch [50/100], Loss: 0.5909, Val Loss: 0.6029, Accuracy: 67.03%\n",
      "Epoch [60/100], Loss: 0.5878, Val Loss: 0.6032, Accuracy: 66.71%\n",
      "Epoch [70/100], Loss: 0.5895, Val Loss: 0.6025, Accuracy: 67.22%\n",
      "Epoch [80/100], Loss: 0.5930, Val Loss: 0.6039, Accuracy: 66.77%\n",
      "Epoch [90/100], Loss: 0.5895, Val Loss: 0.6034, Accuracy: 66.58%\n",
      "Epoch [100/100], Loss: 0.5907, Val Loss: 0.6037, Accuracy: 66.71%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6104, Val Loss: 0.6079, Accuracy: 65.92%\n",
      "Epoch [20/100], Loss: 0.6026, Val Loss: 0.6032, Accuracy: 66.43%\n",
      "Epoch [30/100], Loss: 0.5975, Val Loss: 0.6047, Accuracy: 65.28%\n",
      "Epoch [40/100], Loss: 0.5926, Val Loss: 0.5977, Accuracy: 66.50%\n",
      "Epoch [50/100], Loss: 0.5883, Val Loss: 0.5973, Accuracy: 66.37%\n",
      "Epoch [60/100], Loss: 0.5903, Val Loss: 0.5977, Accuracy: 66.11%\n",
      "Epoch [70/100], Loss: 0.5883, Val Loss: 0.5978, Accuracy: 66.50%\n",
      "Epoch [80/100], Loss: 0.5856, Val Loss: 0.5977, Accuracy: 66.24%\n",
      "Epoch [90/100], Loss: 0.5833, Val Loss: 0.5976, Accuracy: 66.37%\n",
      "Epoch [100/100], Loss: 0.5839, Val Loss: 0.5980, Accuracy: 66.37%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6124, Val Loss: 0.5968, Accuracy: 67.07%\n",
      "Epoch [20/100], Loss: 0.6009, Val Loss: 0.5965, Accuracy: 67.33%\n",
      "Epoch [30/100], Loss: 0.5981, Val Loss: 0.5971, Accuracy: 67.20%\n",
      "Epoch [40/100], Loss: 0.5981, Val Loss: 0.5968, Accuracy: 67.39%\n",
      "Epoch [50/100], Loss: 0.6002, Val Loss: 0.5965, Accuracy: 66.62%\n",
      "Epoch [60/100], Loss: 0.5959, Val Loss: 0.5965, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5954, Val Loss: 0.5966, Accuracy: 67.20%\n",
      "Epoch [80/100], Loss: 0.5959, Val Loss: 0.5962, Accuracy: 66.82%\n",
      "Epoch [90/100], Loss: 0.5962, Val Loss: 0.5964, Accuracy: 66.94%\n",
      "Epoch [100/100], Loss: 0.5963, Val Loss: 0.5964, Accuracy: 66.75%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6097, Val Loss: 0.6025, Accuracy: 67.71%\n",
      "Epoch [20/100], Loss: 0.6048, Val Loss: 0.5982, Accuracy: 67.52%\n",
      "Epoch [30/100], Loss: 0.5963, Val Loss: 0.5960, Accuracy: 67.65%\n",
      "Epoch [40/100], Loss: 0.5944, Val Loss: 0.5975, Accuracy: 67.97%\n",
      "Epoch [50/100], Loss: 0.5923, Val Loss: 0.5965, Accuracy: 67.20%\n",
      "Epoch [60/100], Loss: 0.5911, Val Loss: 0.5964, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5896, Val Loss: 0.5965, Accuracy: 67.26%\n",
      "Epoch [80/100], Loss: 0.5947, Val Loss: 0.5970, Accuracy: 67.26%\n",
      "Epoch [90/100], Loss: 0.5918, Val Loss: 0.5959, Accuracy: 67.46%\n",
      "Epoch [100/100], Loss: 0.5933, Val Loss: 0.5963, Accuracy: 67.26%\n",
      "Best cross-validated accuracy: 68.63%\n",
      "Epoch [10/100], Loss: 0.5960, Val Loss: 0.5763, Accuracy: 68.75%\n",
      "Epoch [20/100], Loss: 0.5948, Val Loss: 0.5752, Accuracy: 68.70%\n",
      "Epoch [30/100], Loss: 0.5909, Val Loss: 0.5781, Accuracy: 69.26%\n",
      "Epoch [40/100], Loss: 0.5907, Val Loss: 0.5771, Accuracy: 68.80%\n",
      "Epoch [50/100], Loss: 0.5854, Val Loss: 0.5751, Accuracy: 69.06%\n",
      "Epoch [60/100], Loss: 0.5895, Val Loss: 0.5762, Accuracy: 68.95%\n",
      "Epoch [70/100], Loss: 0.5849, Val Loss: 0.5759, Accuracy: 68.80%\n",
      "Epoch [80/100], Loss: 0.5880, Val Loss: 0.5758, Accuracy: 68.85%\n",
      "Epoch [90/100], Loss: 0.5855, Val Loss: 0.5758, Accuracy: 69.01%\n",
      "Epoch [100/100], Loss: 0.5918, Val Loss: 0.5755, Accuracy: 68.80%\n",
      "Final model accuracy on test set: 69.57%\n",
      "Accuracy 69.57% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6125, Val Loss: 0.5964, Accuracy: 67.93%\n",
      "Epoch [20/100], Loss: 0.6024, Val Loss: 0.5928, Accuracy: 68.18%\n",
      "Epoch [30/100], Loss: 0.6021, Val Loss: 0.5909, Accuracy: 67.93%\n",
      "Epoch [40/100], Loss: 0.5970, Val Loss: 0.5918, Accuracy: 67.86%\n",
      "Epoch [50/100], Loss: 0.5904, Val Loss: 0.5916, Accuracy: 67.93%\n",
      "Epoch [60/100], Loss: 0.5948, Val Loss: 0.5916, Accuracy: 67.86%\n",
      "Epoch [70/100], Loss: 0.5948, Val Loss: 0.5914, Accuracy: 67.73%\n",
      "Epoch [80/100], Loss: 0.5950, Val Loss: 0.5915, Accuracy: 67.67%\n",
      "Epoch [90/100], Loss: 0.5923, Val Loss: 0.5923, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5934, Val Loss: 0.5921, Accuracy: 67.86%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6110, Val Loss: 0.6058, Accuracy: 67.09%\n",
      "Epoch [20/100], Loss: 0.6028, Val Loss: 0.6026, Accuracy: 67.16%\n",
      "Epoch [30/100], Loss: 0.5969, Val Loss: 0.6007, Accuracy: 67.16%\n",
      "Epoch [40/100], Loss: 0.5938, Val Loss: 0.6009, Accuracy: 67.67%\n",
      "Epoch [50/100], Loss: 0.5931, Val Loss: 0.6009, Accuracy: 67.22%\n",
      "Epoch [60/100], Loss: 0.5950, Val Loss: 0.6009, Accuracy: 67.48%\n",
      "Epoch [70/100], Loss: 0.5891, Val Loss: 0.6016, Accuracy: 67.29%\n",
      "Epoch [80/100], Loss: 0.5917, Val Loss: 0.6011, Accuracy: 67.09%\n",
      "Epoch [90/100], Loss: 0.5946, Val Loss: 0.6011, Accuracy: 67.29%\n",
      "Epoch [100/100], Loss: 0.5937, Val Loss: 0.6015, Accuracy: 67.61%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6102, Val Loss: 0.6048, Accuracy: 66.43%\n",
      "Epoch [20/100], Loss: 0.6059, Val Loss: 0.6013, Accuracy: 66.62%\n",
      "Epoch [30/100], Loss: 0.5979, Val Loss: 0.6009, Accuracy: 66.37%\n",
      "Epoch [40/100], Loss: 0.5923, Val Loss: 0.5982, Accuracy: 66.82%\n",
      "Epoch [50/100], Loss: 0.5935, Val Loss: 0.5984, Accuracy: 66.37%\n",
      "Epoch [60/100], Loss: 0.5879, Val Loss: 0.5976, Accuracy: 66.75%\n",
      "Epoch [70/100], Loss: 0.5906, Val Loss: 0.5971, Accuracy: 66.30%\n",
      "Epoch [80/100], Loss: 0.5884, Val Loss: 0.5976, Accuracy: 66.37%\n",
      "Epoch [90/100], Loss: 0.5880, Val Loss: 0.5975, Accuracy: 66.43%\n",
      "Epoch [100/100], Loss: 0.5872, Val Loss: 0.5974, Accuracy: 66.43%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6119, Val Loss: 0.5991, Accuracy: 66.43%\n",
      "Epoch [20/100], Loss: 0.5995, Val Loss: 0.5968, Accuracy: 67.01%\n",
      "Epoch [30/100], Loss: 0.5985, Val Loss: 0.5967, Accuracy: 67.33%\n",
      "Epoch [40/100], Loss: 0.5935, Val Loss: 0.5957, Accuracy: 66.82%\n",
      "Epoch [50/100], Loss: 0.5951, Val Loss: 0.5951, Accuracy: 67.39%\n",
      "Epoch [60/100], Loss: 0.5955, Val Loss: 0.5953, Accuracy: 67.78%\n",
      "Epoch [70/100], Loss: 0.5953, Val Loss: 0.5949, Accuracy: 67.33%\n",
      "Epoch [80/100], Loss: 0.5931, Val Loss: 0.5950, Accuracy: 66.82%\n",
      "Epoch [90/100], Loss: 0.5915, Val Loss: 0.5949, Accuracy: 67.14%\n",
      "Epoch [100/100], Loss: 0.5926, Val Loss: 0.5949, Accuracy: 67.01%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6088, Val Loss: 0.6012, Accuracy: 67.78%\n",
      "Epoch [20/100], Loss: 0.6022, Val Loss: 0.5955, Accuracy: 68.03%\n",
      "Epoch [30/100], Loss: 0.5970, Val Loss: 0.5951, Accuracy: 67.58%\n",
      "Epoch [40/100], Loss: 0.5965, Val Loss: 0.5950, Accuracy: 67.39%\n",
      "Epoch [50/100], Loss: 0.5889, Val Loss: 0.5955, Accuracy: 67.97%\n",
      "Epoch [60/100], Loss: 0.5945, Val Loss: 0.5952, Accuracy: 67.65%\n",
      "Epoch [70/100], Loss: 0.5930, Val Loss: 0.5956, Accuracy: 67.84%\n",
      "Epoch [80/100], Loss: 0.5897, Val Loss: 0.5953, Accuracy: 67.65%\n",
      "Epoch [90/100], Loss: 0.5925, Val Loss: 0.5956, Accuracy: 67.84%\n",
      "Epoch [100/100], Loss: 0.5905, Val Loss: 0.5952, Accuracy: 67.52%\n",
      "Best cross-validated accuracy: 68.69%\n",
      "Epoch [10/100], Loss: 0.5941, Val Loss: 0.5799, Accuracy: 68.70%\n",
      "Epoch [20/100], Loss: 0.5916, Val Loss: 0.5770, Accuracy: 68.95%\n",
      "Epoch [30/100], Loss: 0.5874, Val Loss: 0.5753, Accuracy: 69.21%\n",
      "Epoch [40/100], Loss: 0.5888, Val Loss: 0.5744, Accuracy: 69.16%\n",
      "Epoch [50/100], Loss: 0.5885, Val Loss: 0.5744, Accuracy: 69.21%\n",
      "Epoch [60/100], Loss: 0.5846, Val Loss: 0.5748, Accuracy: 69.01%\n",
      "Epoch [70/100], Loss: 0.5893, Val Loss: 0.5742, Accuracy: 69.06%\n",
      "Epoch [80/100], Loss: 0.5879, Val Loss: 0.5747, Accuracy: 69.11%\n",
      "Epoch [90/100], Loss: 0.5879, Val Loss: 0.5747, Accuracy: 69.42%\n",
      "Epoch [100/100], Loss: 0.5870, Val Loss: 0.5749, Accuracy: 69.11%\n",
      "Final model accuracy on test set: 69.52%\n",
      "Accuracy 69.52% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6166, Val Loss: 0.5986, Accuracy: 67.54%\n",
      "Epoch [20/100], Loss: 0.6035, Val Loss: 0.5968, Accuracy: 67.73%\n",
      "Epoch [30/100], Loss: 0.6014, Val Loss: 0.5954, Accuracy: 68.44%\n",
      "Epoch [40/100], Loss: 0.6014, Val Loss: 0.5918, Accuracy: 68.25%\n",
      "Epoch [50/100], Loss: 0.5941, Val Loss: 0.5958, Accuracy: 67.67%\n",
      "Epoch [60/100], Loss: 0.5955, Val Loss: 0.5932, Accuracy: 68.12%\n",
      "Epoch [70/100], Loss: 0.5910, Val Loss: 0.5956, Accuracy: 67.80%\n",
      "Epoch [80/100], Loss: 0.5876, Val Loss: 0.5921, Accuracy: 68.05%\n",
      "Epoch [90/100], Loss: 0.5854, Val Loss: 0.5924, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5910, Val Loss: 0.5918, Accuracy: 68.05%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6069, Val Loss: 0.6061, Accuracy: 66.58%\n",
      "Epoch [20/100], Loss: 0.6068, Val Loss: 0.6051, Accuracy: 66.52%\n",
      "Epoch [30/100], Loss: 0.5975, Val Loss: 0.6020, Accuracy: 67.03%\n",
      "Epoch [40/100], Loss: 0.5921, Val Loss: 0.6064, Accuracy: 67.03%\n",
      "Epoch [50/100], Loss: 0.5907, Val Loss: 0.6029, Accuracy: 67.03%\n",
      "Epoch [60/100], Loss: 0.5923, Val Loss: 0.6032, Accuracy: 67.03%\n",
      "Epoch [70/100], Loss: 0.5936, Val Loss: 0.6027, Accuracy: 67.03%\n",
      "Epoch [80/100], Loss: 0.5913, Val Loss: 0.6029, Accuracy: 66.97%\n",
      "Epoch [90/100], Loss: 0.5919, Val Loss: 0.6029, Accuracy: 67.03%\n",
      "Epoch [100/100], Loss: 0.5907, Val Loss: 0.6033, Accuracy: 67.03%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6173, Val Loss: 0.6051, Accuracy: 65.66%\n",
      "Epoch [20/100], Loss: 0.6056, Val Loss: 0.6029, Accuracy: 66.05%\n",
      "Epoch [30/100], Loss: 0.5991, Val Loss: 0.6002, Accuracy: 65.86%\n",
      "Epoch [40/100], Loss: 0.5976, Val Loss: 0.5996, Accuracy: 66.56%\n",
      "Epoch [50/100], Loss: 0.5933, Val Loss: 0.6000, Accuracy: 65.47%\n",
      "Epoch [60/100], Loss: 0.5960, Val Loss: 0.5987, Accuracy: 66.43%\n",
      "Epoch [70/100], Loss: 0.5887, Val Loss: 0.6002, Accuracy: 65.86%\n",
      "Epoch [80/100], Loss: 0.5861, Val Loss: 0.5993, Accuracy: 66.11%\n",
      "Epoch [90/100], Loss: 0.5849, Val Loss: 0.5996, Accuracy: 66.18%\n",
      "Epoch [100/100], Loss: 0.5859, Val Loss: 0.5992, Accuracy: 66.30%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6100, Val Loss: 0.5958, Accuracy: 67.01%\n",
      "Epoch [20/100], Loss: 0.5998, Val Loss: 0.5944, Accuracy: 67.01%\n",
      "Epoch [30/100], Loss: 0.5995, Val Loss: 0.5946, Accuracy: 67.26%\n",
      "Epoch [40/100], Loss: 0.5968, Val Loss: 0.5943, Accuracy: 66.82%\n",
      "Epoch [50/100], Loss: 0.5981, Val Loss: 0.5948, Accuracy: 67.65%\n",
      "Epoch [60/100], Loss: 0.5953, Val Loss: 0.5943, Accuracy: 67.52%\n",
      "Epoch [70/100], Loss: 0.5961, Val Loss: 0.5944, Accuracy: 67.52%\n",
      "Epoch [80/100], Loss: 0.5990, Val Loss: 0.5945, Accuracy: 67.58%\n",
      "Epoch [90/100], Loss: 0.5963, Val Loss: 0.5949, Accuracy: 67.01%\n",
      "Epoch [100/100], Loss: 0.5961, Val Loss: 0.5948, Accuracy: 67.65%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6128, Val Loss: 0.6002, Accuracy: 67.91%\n",
      "Epoch [20/100], Loss: 0.6056, Val Loss: 0.5963, Accuracy: 68.61%\n",
      "Epoch [30/100], Loss: 0.5997, Val Loss: 0.5959, Accuracy: 67.84%\n",
      "Epoch [40/100], Loss: 0.5942, Val Loss: 0.5956, Accuracy: 67.14%\n",
      "Epoch [50/100], Loss: 0.5887, Val Loss: 0.5958, Accuracy: 66.94%\n",
      "Epoch [60/100], Loss: 0.5947, Val Loss: 0.5955, Accuracy: 67.26%\n",
      "Epoch [70/100], Loss: 0.5892, Val Loss: 0.5955, Accuracy: 67.20%\n",
      "Epoch [80/100], Loss: 0.5939, Val Loss: 0.5955, Accuracy: 67.14%\n",
      "Epoch [90/100], Loss: 0.5923, Val Loss: 0.5956, Accuracy: 66.94%\n",
      "Epoch [100/100], Loss: 0.5891, Val Loss: 0.5954, Accuracy: 67.26%\n",
      "Best cross-validated accuracy: 68.63%\n",
      "Epoch [10/100], Loss: 0.5957, Val Loss: 0.5768, Accuracy: 69.11%\n",
      "Epoch [20/100], Loss: 0.5920, Val Loss: 0.5749, Accuracy: 69.52%\n",
      "Epoch [30/100], Loss: 0.5891, Val Loss: 0.5748, Accuracy: 69.47%\n",
      "Epoch [40/100], Loss: 0.5913, Val Loss: 0.5750, Accuracy: 69.47%\n",
      "Epoch [50/100], Loss: 0.5904, Val Loss: 0.5747, Accuracy: 69.47%\n",
      "Epoch [60/100], Loss: 0.5938, Val Loss: 0.5755, Accuracy: 69.21%\n",
      "Epoch [70/100], Loss: 0.5905, Val Loss: 0.5750, Accuracy: 69.52%\n",
      "Epoch [80/100], Loss: 0.5916, Val Loss: 0.5745, Accuracy: 69.57%\n",
      "Epoch [90/100], Loss: 0.5882, Val Loss: 0.5750, Accuracy: 69.06%\n",
      "Epoch [100/100], Loss: 0.5896, Val Loss: 0.5750, Accuracy: 69.31%\n",
      "Final model accuracy on test set: 69.72%\n",
      "Accuracy 69.72% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6113, Val Loss: 0.5977, Accuracy: 67.54%\n",
      "Epoch [20/100], Loss: 0.6068, Val Loss: 0.5953, Accuracy: 67.80%\n",
      "Epoch [30/100], Loss: 0.6011, Val Loss: 0.5942, Accuracy: 68.05%\n",
      "Epoch [40/100], Loss: 0.5967, Val Loss: 0.5917, Accuracy: 67.99%\n",
      "Epoch [50/100], Loss: 0.5944, Val Loss: 0.5927, Accuracy: 67.54%\n",
      "Epoch [60/100], Loss: 0.5941, Val Loss: 0.5918, Accuracy: 68.31%\n",
      "Epoch [70/100], Loss: 0.5905, Val Loss: 0.5920, Accuracy: 67.80%\n",
      "Epoch [80/100], Loss: 0.5895, Val Loss: 0.5922, Accuracy: 67.80%\n",
      "Epoch [90/100], Loss: 0.5901, Val Loss: 0.5924, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5913, Val Loss: 0.5923, Accuracy: 67.67%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6076, Val Loss: 0.6083, Accuracy: 65.88%\n",
      "Epoch [20/100], Loss: 0.6015, Val Loss: 0.6038, Accuracy: 66.84%\n",
      "Epoch [30/100], Loss: 0.5996, Val Loss: 0.6041, Accuracy: 66.52%\n",
      "Epoch [40/100], Loss: 0.5959, Val Loss: 0.6010, Accuracy: 67.03%\n",
      "Epoch [50/100], Loss: 0.5913, Val Loss: 0.6014, Accuracy: 66.77%\n",
      "Epoch [60/100], Loss: 0.5872, Val Loss: 0.6046, Accuracy: 67.09%\n",
      "Epoch [70/100], Loss: 0.5868, Val Loss: 0.6029, Accuracy: 67.35%\n",
      "Epoch [80/100], Loss: 0.5858, Val Loss: 0.6032, Accuracy: 67.48%\n",
      "Epoch [90/100], Loss: 0.5860, Val Loss: 0.6028, Accuracy: 67.29%\n",
      "Epoch [100/100], Loss: 0.5887, Val Loss: 0.6025, Accuracy: 67.16%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6111, Val Loss: 0.6056, Accuracy: 66.05%\n",
      "Epoch [20/100], Loss: 0.6025, Val Loss: 0.6015, Accuracy: 65.98%\n",
      "Epoch [30/100], Loss: 0.5975, Val Loss: 0.5992, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5965, Val Loss: 0.6002, Accuracy: 66.56%\n",
      "Epoch [50/100], Loss: 0.5940, Val Loss: 0.5982, Accuracy: 66.75%\n",
      "Epoch [60/100], Loss: 0.5913, Val Loss: 0.5981, Accuracy: 66.62%\n",
      "Epoch [70/100], Loss: 0.5898, Val Loss: 0.5980, Accuracy: 66.50%\n",
      "Epoch [80/100], Loss: 0.5899, Val Loss: 0.5981, Accuracy: 66.82%\n",
      "Epoch [90/100], Loss: 0.5916, Val Loss: 0.5980, Accuracy: 66.30%\n",
      "Epoch [100/100], Loss: 0.5924, Val Loss: 0.5980, Accuracy: 66.75%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6109, Val Loss: 0.5952, Accuracy: 67.71%\n",
      "Epoch [20/100], Loss: 0.6058, Val Loss: 0.5947, Accuracy: 67.65%\n",
      "Epoch [30/100], Loss: 0.5959, Val Loss: 0.5947, Accuracy: 66.88%\n",
      "Epoch [40/100], Loss: 0.5948, Val Loss: 0.5947, Accuracy: 66.88%\n",
      "Epoch [50/100], Loss: 0.5960, Val Loss: 0.5949, Accuracy: 66.62%\n",
      "Epoch [60/100], Loss: 0.5953, Val Loss: 0.5949, Accuracy: 66.50%\n",
      "Epoch [70/100], Loss: 0.5931, Val Loss: 0.5947, Accuracy: 66.56%\n",
      "Epoch [80/100], Loss: 0.5929, Val Loss: 0.5946, Accuracy: 66.43%\n",
      "Epoch [90/100], Loss: 0.5916, Val Loss: 0.5946, Accuracy: 66.43%\n",
      "Epoch [100/100], Loss: 0.5920, Val Loss: 0.5947, Accuracy: 66.56%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6111, Val Loss: 0.5996, Accuracy: 68.03%\n",
      "Epoch [20/100], Loss: 0.6015, Val Loss: 0.5992, Accuracy: 66.94%\n",
      "Epoch [30/100], Loss: 0.5954, Val Loss: 0.5969, Accuracy: 67.46%\n",
      "Epoch [40/100], Loss: 0.5964, Val Loss: 0.5971, Accuracy: 67.20%\n",
      "Epoch [50/100], Loss: 0.5960, Val Loss: 0.5969, Accuracy: 67.52%\n",
      "Epoch [60/100], Loss: 0.5950, Val Loss: 0.5971, Accuracy: 67.46%\n",
      "Epoch [70/100], Loss: 0.5923, Val Loss: 0.5964, Accuracy: 67.39%\n",
      "Epoch [80/100], Loss: 0.5928, Val Loss: 0.5971, Accuracy: 67.33%\n",
      "Epoch [90/100], Loss: 0.5904, Val Loss: 0.5970, Accuracy: 67.46%\n",
      "Epoch [100/100], Loss: 0.5945, Val Loss: 0.5975, Accuracy: 67.26%\n",
      "Best cross-validated accuracy: 68.50%\n",
      "Epoch [10/100], Loss: 0.5957, Val Loss: 0.5774, Accuracy: 68.65%\n",
      "Epoch [20/100], Loss: 0.5941, Val Loss: 0.5772, Accuracy: 69.52%\n",
      "Epoch [30/100], Loss: 0.5924, Val Loss: 0.5756, Accuracy: 69.16%\n",
      "Epoch [40/100], Loss: 0.5915, Val Loss: 0.5753, Accuracy: 69.67%\n",
      "Epoch [50/100], Loss: 0.5877, Val Loss: 0.5752, Accuracy: 69.52%\n",
      "Epoch [60/100], Loss: 0.5907, Val Loss: 0.5756, Accuracy: 69.36%\n",
      "Epoch [70/100], Loss: 0.5889, Val Loss: 0.5757, Accuracy: 69.57%\n",
      "Epoch [80/100], Loss: 0.5915, Val Loss: 0.5755, Accuracy: 69.67%\n",
      "Epoch [90/100], Loss: 0.5934, Val Loss: 0.5752, Accuracy: 69.42%\n",
      "Epoch [100/100], Loss: 0.5897, Val Loss: 0.5757, Accuracy: 69.47%\n",
      "Final model accuracy on test set: 69.77%\n",
      "Accuracy 69.77% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6111, Val Loss: 0.5965, Accuracy: 68.44%\n",
      "Epoch [20/100], Loss: 0.6007, Val Loss: 0.5938, Accuracy: 68.37%\n",
      "Epoch [30/100], Loss: 0.5978, Val Loss: 0.5931, Accuracy: 68.18%\n",
      "Epoch [40/100], Loss: 0.5978, Val Loss: 0.5921, Accuracy: 68.18%\n",
      "Epoch [50/100], Loss: 0.5947, Val Loss: 0.5930, Accuracy: 68.12%\n",
      "Epoch [60/100], Loss: 0.5911, Val Loss: 0.5917, Accuracy: 68.18%\n",
      "Epoch [70/100], Loss: 0.5916, Val Loss: 0.5920, Accuracy: 68.18%\n",
      "Epoch [80/100], Loss: 0.5921, Val Loss: 0.5918, Accuracy: 68.18%\n",
      "Epoch [90/100], Loss: 0.5866, Val Loss: 0.5921, Accuracy: 68.25%\n",
      "Epoch [100/100], Loss: 0.5907, Val Loss: 0.5916, Accuracy: 68.25%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6081, Val Loss: 0.6049, Accuracy: 66.71%\n",
      "Epoch [20/100], Loss: 0.6023, Val Loss: 0.6046, Accuracy: 67.41%\n",
      "Epoch [30/100], Loss: 0.5957, Val Loss: 0.6020, Accuracy: 66.84%\n",
      "Epoch [40/100], Loss: 0.5921, Val Loss: 0.6007, Accuracy: 67.16%\n",
      "Epoch [50/100], Loss: 0.5911, Val Loss: 0.6008, Accuracy: 67.16%\n",
      "Epoch [60/100], Loss: 0.5903, Val Loss: 0.6004, Accuracy: 67.03%\n",
      "Epoch [70/100], Loss: 0.5877, Val Loss: 0.6008, Accuracy: 67.16%\n",
      "Epoch [80/100], Loss: 0.5906, Val Loss: 0.6010, Accuracy: 67.29%\n",
      "Epoch [90/100], Loss: 0.5906, Val Loss: 0.6011, Accuracy: 67.29%\n",
      "Epoch [100/100], Loss: 0.5929, Val Loss: 0.6016, Accuracy: 67.09%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6102, Val Loss: 0.6079, Accuracy: 65.02%\n",
      "Epoch [20/100], Loss: 0.6005, Val Loss: 0.6053, Accuracy: 65.79%\n",
      "Epoch [30/100], Loss: 0.5968, Val Loss: 0.6015, Accuracy: 66.11%\n",
      "Epoch [40/100], Loss: 0.5949, Val Loss: 0.5999, Accuracy: 66.11%\n",
      "Epoch [50/100], Loss: 0.5932, Val Loss: 0.5991, Accuracy: 65.98%\n",
      "Epoch [60/100], Loss: 0.5878, Val Loss: 0.5988, Accuracy: 65.98%\n",
      "Epoch [70/100], Loss: 0.5865, Val Loss: 0.5994, Accuracy: 66.18%\n",
      "Epoch [80/100], Loss: 0.5858, Val Loss: 0.5994, Accuracy: 65.86%\n",
      "Epoch [90/100], Loss: 0.5863, Val Loss: 0.5993, Accuracy: 66.30%\n",
      "Epoch [100/100], Loss: 0.5907, Val Loss: 0.5994, Accuracy: 66.11%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6118, Val Loss: 0.5979, Accuracy: 67.20%\n",
      "Epoch [20/100], Loss: 0.6076, Val Loss: 0.5958, Accuracy: 67.07%\n",
      "Epoch [30/100], Loss: 0.5965, Val Loss: 0.5952, Accuracy: 66.69%\n",
      "Epoch [40/100], Loss: 0.5954, Val Loss: 0.5955, Accuracy: 66.50%\n",
      "Epoch [50/100], Loss: 0.5984, Val Loss: 0.5955, Accuracy: 66.56%\n",
      "Epoch [60/100], Loss: 0.6014, Val Loss: 0.5953, Accuracy: 66.56%\n",
      "Epoch [70/100], Loss: 0.6010, Val Loss: 0.5957, Accuracy: 66.05%\n",
      "Epoch [80/100], Loss: 0.5960, Val Loss: 0.5957, Accuracy: 66.43%\n",
      "Epoch [90/100], Loss: 0.5995, Val Loss: 0.5959, Accuracy: 66.75%\n",
      "Epoch [100/100], Loss: 0.5974, Val Loss: 0.5954, Accuracy: 66.43%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6163, Val Loss: 0.6000, Accuracy: 67.46%\n",
      "Epoch [20/100], Loss: 0.6052, Val Loss: 0.5963, Accuracy: 67.39%\n",
      "Epoch [30/100], Loss: 0.5987, Val Loss: 0.5964, Accuracy: 67.07%\n",
      "Epoch [40/100], Loss: 0.5940, Val Loss: 0.5984, Accuracy: 67.20%\n",
      "Epoch [50/100], Loss: 0.5940, Val Loss: 0.5974, Accuracy: 67.20%\n",
      "Epoch [60/100], Loss: 0.5913, Val Loss: 0.5979, Accuracy: 66.75%\n",
      "Epoch [70/100], Loss: 0.5921, Val Loss: 0.5975, Accuracy: 67.14%\n",
      "Epoch [80/100], Loss: 0.5902, Val Loss: 0.5973, Accuracy: 67.01%\n",
      "Epoch [90/100], Loss: 0.5914, Val Loss: 0.5978, Accuracy: 66.94%\n",
      "Epoch [100/100], Loss: 0.5929, Val Loss: 0.5971, Accuracy: 67.20%\n",
      "Best cross-validated accuracy: 68.76%\n",
      "Epoch [10/100], Loss: 0.6012, Val Loss: 0.5773, Accuracy: 68.65%\n",
      "Epoch [20/100], Loss: 0.5986, Val Loss: 0.5771, Accuracy: 68.80%\n",
      "Epoch [30/100], Loss: 0.5917, Val Loss: 0.5762, Accuracy: 69.06%\n",
      "Epoch [40/100], Loss: 0.5915, Val Loss: 0.5757, Accuracy: 68.90%\n",
      "Epoch [50/100], Loss: 0.5872, Val Loss: 0.5760, Accuracy: 69.52%\n",
      "Epoch [60/100], Loss: 0.5850, Val Loss: 0.5762, Accuracy: 68.90%\n",
      "Epoch [70/100], Loss: 0.5875, Val Loss: 0.5760, Accuracy: 69.01%\n",
      "Epoch [80/100], Loss: 0.5880, Val Loss: 0.5761, Accuracy: 68.95%\n",
      "Epoch [90/100], Loss: 0.5874, Val Loss: 0.5772, Accuracy: 68.44%\n",
      "Epoch [100/100], Loss: 0.5869, Val Loss: 0.5763, Accuracy: 68.95%\n",
      "Final model accuracy on test set: 69.52%\n",
      "Accuracy 69.52% not met, restarting the process.\n",
      "Fold 1/5\n",
      "Epoch [10/100], Loss: 0.6141, Val Loss: 0.5961, Accuracy: 67.67%\n",
      "Epoch [20/100], Loss: 0.6042, Val Loss: 0.5954, Accuracy: 67.48%\n",
      "Epoch [30/100], Loss: 0.6019, Val Loss: 0.5930, Accuracy: 67.99%\n",
      "Epoch [40/100], Loss: 0.5970, Val Loss: 0.5930, Accuracy: 67.99%\n",
      "Epoch [50/100], Loss: 0.5943, Val Loss: 0.5928, Accuracy: 67.80%\n",
      "Epoch [60/100], Loss: 0.5944, Val Loss: 0.5931, Accuracy: 68.12%\n",
      "Epoch [70/100], Loss: 0.5942, Val Loss: 0.5930, Accuracy: 67.93%\n",
      "Epoch [80/100], Loss: 0.5975, Val Loss: 0.5929, Accuracy: 68.05%\n",
      "Epoch [90/100], Loss: 0.5993, Val Loss: 0.5930, Accuracy: 67.93%\n",
      "Epoch [100/100], Loss: 0.5960, Val Loss: 0.5929, Accuracy: 67.86%\n",
      "Fold 2/5\n",
      "Epoch [10/100], Loss: 0.6108, Val Loss: 0.6048, Accuracy: 66.77%\n",
      "Epoch [20/100], Loss: 0.5988, Val Loss: 0.6029, Accuracy: 66.84%\n",
      "Epoch [30/100], Loss: 0.5958, Val Loss: 0.5994, Accuracy: 67.29%\n",
      "Epoch [40/100], Loss: 0.5953, Val Loss: 0.6000, Accuracy: 67.48%\n",
      "Epoch [50/100], Loss: 0.5927, Val Loss: 0.6005, Accuracy: 67.54%\n",
      "Epoch [60/100], Loss: 0.5894, Val Loss: 0.6006, Accuracy: 67.67%\n",
      "Epoch [70/100], Loss: 0.5930, Val Loss: 0.6006, Accuracy: 67.41%\n",
      "Epoch [80/100], Loss: 0.5900, Val Loss: 0.6002, Accuracy: 67.48%\n",
      "Epoch [90/100], Loss: 0.5919, Val Loss: 0.5999, Accuracy: 67.35%\n",
      "Epoch [100/100], Loss: 0.5924, Val Loss: 0.6004, Accuracy: 67.54%\n",
      "Fold 3/5\n",
      "Epoch [10/100], Loss: 0.6072, Val Loss: 0.6059, Accuracy: 65.47%\n",
      "Epoch [20/100], Loss: 0.6029, Val Loss: 0.6019, Accuracy: 66.24%\n",
      "Epoch [30/100], Loss: 0.5973, Val Loss: 0.6010, Accuracy: 66.05%\n",
      "Epoch [40/100], Loss: 0.5933, Val Loss: 0.5991, Accuracy: 66.37%\n",
      "Epoch [50/100], Loss: 0.5928, Val Loss: 0.5985, Accuracy: 66.05%\n",
      "Epoch [60/100], Loss: 0.5930, Val Loss: 0.5993, Accuracy: 66.50%\n",
      "Epoch [70/100], Loss: 0.5864, Val Loss: 0.5989, Accuracy: 66.37%\n",
      "Epoch [80/100], Loss: 0.5863, Val Loss: 0.5989, Accuracy: 66.37%\n",
      "Epoch [90/100], Loss: 0.5843, Val Loss: 0.5985, Accuracy: 66.75%\n",
      "Epoch [100/100], Loss: 0.5869, Val Loss: 0.5986, Accuracy: 66.37%\n",
      "Fold 4/5\n",
      "Epoch [10/100], Loss: 0.6088, Val Loss: 0.5960, Accuracy: 67.84%\n",
      "Epoch [20/100], Loss: 0.6014, Val Loss: 0.5986, Accuracy: 67.78%\n",
      "Epoch [30/100], Loss: 0.5987, Val Loss: 0.5958, Accuracy: 67.26%\n",
      "Epoch [40/100], Loss: 0.5982, Val Loss: 0.5955, Accuracy: 67.07%\n",
      "Epoch [50/100], Loss: 0.5985, Val Loss: 0.5954, Accuracy: 67.20%\n",
      "Epoch [60/100], Loss: 0.6001, Val Loss: 0.5952, Accuracy: 67.01%\n",
      "Epoch [70/100], Loss: 0.5979, Val Loss: 0.5950, Accuracy: 66.88%\n",
      "Epoch [80/100], Loss: 0.5965, Val Loss: 0.5954, Accuracy: 67.20%\n",
      "Epoch [90/100], Loss: 0.5964, Val Loss: 0.5951, Accuracy: 66.82%\n",
      "Epoch [100/100], Loss: 0.5937, Val Loss: 0.5952, Accuracy: 67.20%\n",
      "Fold 5/5\n",
      "Epoch [10/100], Loss: 0.6109, Val Loss: 0.5984, Accuracy: 68.16%\n",
      "Epoch [20/100], Loss: 0.6014, Val Loss: 0.5963, Accuracy: 67.71%\n",
      "Epoch [30/100], Loss: 0.5935, Val Loss: 0.5959, Accuracy: 67.97%\n",
      "Epoch [40/100], Loss: 0.5958, Val Loss: 0.5955, Accuracy: 67.78%\n",
      "Epoch [50/100], Loss: 0.5916, Val Loss: 0.5967, Accuracy: 67.26%\n",
      "Epoch [60/100], Loss: 0.5902, Val Loss: 0.5965, Accuracy: 67.39%\n",
      "Epoch [70/100], Loss: 0.5932, Val Loss: 0.5961, Accuracy: 67.78%\n",
      "Epoch [80/100], Loss: 0.5889, Val Loss: 0.5963, Accuracy: 67.58%\n",
      "Epoch [90/100], Loss: 0.5928, Val Loss: 0.5966, Accuracy: 67.52%\n",
      "Epoch [100/100], Loss: 0.5951, Val Loss: 0.5961, Accuracy: 67.58%\n",
      "Best cross-validated accuracy: 68.50%\n",
      "Epoch [10/100], Loss: 0.5993, Val Loss: 0.5785, Accuracy: 68.29%\n",
      "Epoch [20/100], Loss: 0.5963, Val Loss: 0.5780, Accuracy: 68.70%\n",
      "Epoch [30/100], Loss: 0.5934, Val Loss: 0.5750, Accuracy: 69.98%\n",
      "Final model accuracy on test set: 69.98%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == .5).any(axis=1)]\n",
    "# df = df[~(df == -20).any(axis=1)]\n",
    "# df = df[(df['surface_Hard'] == 1.0)]\n",
    "\n",
    "# df = df.drop(df.columns[df.columns.str.contains('_rd')], axis=1)\n",
    "\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set target accuracy\n",
    "target_accuracy = 0.6987\n",
    "\n",
    "final_acc = 0.0\n",
    "while final_acc < target_accuracy:\n",
    "    best_acc, best_model_weights = cross_validate(OutcomeProbabilityV6, X_train, y_train, epochs=100, target_accuracy=target_accuracy)\n",
    "    print(f\"Best cross-validated accuracy: {best_acc*100:.2f}%\")\n",
    "\n",
    "    # Final training on full training data\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    val_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = OutcomeProbabilityV6(input_dim=X.shape[1])\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    final_acc, _ = train_and_evaluate(model, train_loader, val_loader, epochs=100, target_accuracy=target_accuracy)\n",
    "    print(f\"Final model accuracy on test set: {final_acc*100:.2f}%\")\n",
    "\n",
    "    if final_acc < target_accuracy:\n",
    "        print(f\"Accuracy {final_acc*100:.2f}% not met, restarting the process.\")\n",
    "    # Quick train break\n",
    "    # break\n",
    "\n",
    "# Evaluate and store predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_test_np = y_test_tensor.numpy()\n",
    "    odds_test = odds_df.loc[idx_test].values\n",
    "\n",
    "    # Create DataFrame with predictions and actual values\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test_np.flatten(),\n",
    "        'Predicted': y_pred.flatten(),\n",
    "        'A_Odds': odds_test[:, 0],\n",
    "        'B_Odds': odds_test[:, 1]\n",
    "    })\n",
    "\n",
    "    # Optionally save to CSV\n",
    "    results_df.to_csv('predictions_with_odds.csv', index=False)\n",
    "\n",
    "# Plot ROC curve\n",
    "with torch.no_grad():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_tensor, y_pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  A_Odds  B_Odds\n",
      "0        0.0   0.436902    1.53    2.45\n",
      "1        0.0   0.686483    1.63    2.25\n",
      "2        0.0   0.418131    2.76    1.42\n",
      "3        1.0   0.729107    1.19    4.53\n",
      "4        0.0   0.456603    2.78    1.43\n",
      "...      ...        ...     ...     ...\n",
      "1947     0.0   0.312409    3.03    1.36\n",
      "1948     1.0   0.500917    1.58    2.33\n",
      "1949     0.0   0.694436    1.33    3.24\n",
      "1950     1.0   0.757615    1.36    3.12\n",
      "1951     0.0   0.457611    3.10    1.36\n",
      "\n",
      "[1952 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = (vegas_odds * calculated_probability - (1 - calculated_probability)) / vegas_odds\n",
    "    \n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total won on $1 bets: -29.01 on a total # bets: 1952 from a total of 1952 games\n",
      "Amount of differing favorites 0.12141393442622951\n",
      "Amount of upset correct 0.5147679324894515 won $24.47000000000001 on 237 bets\n",
      "Amount of incorrect bets : 0.30020491803278687\n",
      "Correct Bets: 0.6997950819672131\n",
      "Model % Correct : 0.6997950819672131 Vegas Correct % : 0.6987704918032787\n"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "confidence_pct = .5\n",
    "confidence_top_pct = 1\n",
    "\n",
    "UNIT = 1\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :#and row['Predicted'] > 1/row['A_Odds'] + .03:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1\n",
    "            total_won += (row['A_Odds']-1) * UNIT #(kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= UNIT #(kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :# and 1-row['Predicted'] > 1/row['B_Odds']+ .03:\n",
    "        better += 1\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1\n",
    "            total_won += (row['B_Odds']-1) * UNIT #(kelly_criterion(row['B_Odds'],row['Predicted']) * UNIT)\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= UNIT #(kelly_criterion(row['B_Odds'],row['Predicted']) * UNIT)\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        upset_predict += 1\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            upset_correct += 1\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_won += (row['A_Odds']-1) * UNIT\n",
    "            else:\n",
    "                upset_won += (row['B_Odds']-1) * UNIT\n",
    "        else:\n",
    "            upset_won -= UNIT\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total won on ${UNIT} bets: {total_won:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"Amount of differing favorites {diff_fav/length}\")\n",
    "print(f\"Amount of upset correct {upset_correct/upset_predict} won ${upset_won} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bets : {wrong/better}\")\n",
    "print(f\"Correct Bets: {bet_correct/better}\")\n",
    "print(f\"Model % Correct : {model_correct/length} Vegas Correct % : {vegas_correct/length}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
