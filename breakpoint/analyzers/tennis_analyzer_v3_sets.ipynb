{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_curve\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20130101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36813\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "df = pd.read_csv('../testcsvs/glickoUpdated.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'a_b_win', 'games', 'tiebreaks'], axis=1)\n",
    "\n",
    "# df = pd.DataFrame(games).drop(['tourney_id', 'tourney_name', 'tourney_date', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug','a_win_percent', 'a_serve_rating', 'a_return_rating', 'a_pressure_rating', 'a_avg_vs_elo', 'a_matches_played', 'b_win_percent', 'b_serve_rating', 'b_return_rating', 'b_pressure_rating', 'b_avg_vs_elo', 'b_matches_played', 'A_Odds', 'b_odds'], axis=1)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# One-Hot Encode the 'category_text' column\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "\n",
    "# Convert to DataFrame\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df, category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_age</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>b_player_age</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>glicko_rating_diff</th>\n",
       "      <th>a_glicko_rating</th>\n",
       "      <th>b_glicko_rating</th>\n",
       "      <th>a_glicko_rd</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_second_won_glicko_rd</th>\n",
       "      <th>sets</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>109.440244</td>\n",
       "      <td>1748.578813</td>\n",
       "      <td>1639.138569</td>\n",
       "      <td>69.218597</td>\n",
       "      <td>...</td>\n",
       "      <td>1525.908593</td>\n",
       "      <td>1517.937658</td>\n",
       "      <td>66.528677</td>\n",
       "      <td>66.002918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-2.699559</td>\n",
       "      <td>1753.795842</td>\n",
       "      <td>1756.495401</td>\n",
       "      <td>78.154224</td>\n",
       "      <td>...</td>\n",
       "      <td>1536.913003</td>\n",
       "      <td>1517.127728</td>\n",
       "      <td>70.116002</td>\n",
       "      <td>64.639126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.567183</td>\n",
       "      <td>1688.929747</td>\n",
       "      <td>1687.362564</td>\n",
       "      <td>86.599848</td>\n",
       "      <td>...</td>\n",
       "      <td>1491.133924</td>\n",
       "      <td>1508.334818</td>\n",
       "      <td>69.849716</td>\n",
       "      <td>65.220607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-187.275163</td>\n",
       "      <td>1383.357011</td>\n",
       "      <td>1570.632174</td>\n",
       "      <td>292.237988</td>\n",
       "      <td>...</td>\n",
       "      <td>1471.098463</td>\n",
       "      <td>1515.147076</td>\n",
       "      <td>248.745451</td>\n",
       "      <td>70.303497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>223.167673</td>\n",
       "      <td>1932.516975</td>\n",
       "      <td>1709.349303</td>\n",
       "      <td>107.395435</td>\n",
       "      <td>...</td>\n",
       "      <td>1551.669156</td>\n",
       "      <td>1505.512790</td>\n",
       "      <td>84.977325</td>\n",
       "      <td>75.692922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_of  tourney_round  a_player_age  a_player_rank  b_player_age  \\\n",
       "8138      3.0            0.8          25.0           63.0          28.0   \n",
       "8139      3.0            0.8          23.0           30.0          32.0   \n",
       "8140      3.0            0.8          25.0           70.0          25.0   \n",
       "8141      3.0            0.8          28.0          376.0          25.0   \n",
       "8142      3.0            0.8          22.0           26.0          27.0   \n",
       "\n",
       "      b_player_rank  glicko_rating_diff  a_glicko_rating  b_glicko_rating  \\\n",
       "8138           73.0          109.440244      1748.578813      1639.138569   \n",
       "8139           62.0           -2.699559      1753.795842      1756.495401   \n",
       "8140           54.0            1.567183      1688.929747      1687.362564   \n",
       "8141          104.0         -187.275163      1383.357011      1570.632174   \n",
       "8142           59.0          223.167673      1932.516975      1709.349303   \n",
       "\n",
       "      a_glicko_rd  ...  a_surface_return_second_won_glicko_rating  \\\n",
       "8138    69.218597  ...                                1525.908593   \n",
       "8139    78.154224  ...                                1536.913003   \n",
       "8140    86.599848  ...                                1491.133924   \n",
       "8141   292.237988  ...                                1471.098463   \n",
       "8142   107.395435  ...                                1551.669156   \n",
       "\n",
       "      b_surface_second_won_glicko_rating  \\\n",
       "8138                         1517.937658   \n",
       "8139                         1517.127728   \n",
       "8140                         1508.334818   \n",
       "8141                         1515.147076   \n",
       "8142                         1505.512790   \n",
       "\n",
       "      a_surface_return_second_won_glicko_rd  b_surface_second_won_glicko_rd  \\\n",
       "8138                              66.528677                       66.002918   \n",
       "8139                              70.116002                       64.639126   \n",
       "8140                              69.849716                       65.220607   \n",
       "8141                             248.745451                       70.303497   \n",
       "8142                              84.977325                       75.692922   \n",
       "\n",
       "      sets  a_odds  b_odds  surface_Clay  surface_Grass  surface_Hard  \n",
       "8138   0.0    1.91    1.83           0.0            0.0           1.0  \n",
       "8139   1.0    1.65    2.18           0.0            0.0           1.0  \n",
       "8140   1.0    1.52    2.47           0.0            0.0           1.0  \n",
       "8141   0.0     NaN     NaN           1.0            0.0           0.0  \n",
       "8142   1.0    1.63    2.22           1.0            0.0           0.0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "# df = df[~(df == 1500).any(axis=1)]\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "# # Plot a_elo_rating vs b_elo_rating for a_b_win == 1\n",
    "# x1 = df[df['a_b_win'] == 1]['a_recent_elo_rating']\n",
    "# y1 = df[df['a_b_win'] == 1]['b_recent_elo_rating']\n",
    "# plt.scatter(x1, y1, color='blue', label='Favorite Wins', s=.5, alpha=0.5)\n",
    "\n",
    "# # Plot b_elo_rating vs a_elo_rating for a_b_win == 0\n",
    "# x2 = df[df['a_b_win'] == 0]['b_recent_elo_rating']\n",
    "# y2 = df[df['a_b_win'] == 0]['a_recent_elo_rating']\n",
    "# plt.scatter(x2, y2, color='orange', label='Upset', s=.5, alpha=0.5)\n",
    "\n",
    "# # Combine data for a single trendline\n",
    "# combined_x = np.concatenate([x1, x2])\n",
    "# combined_y = np.concatenate([y1, y2])\n",
    "\n",
    "# # Fit a polynomial of degree 2 to the combined data\n",
    "# print(combined_x)\n",
    "# coefficients = np.polyfit(combined_x, combined_y, 3)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(combined_x.min(), combined_x.max(), 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Quadratic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(1100, 2300)\n",
    "# plt.ylim(1100, 2300)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Winner')\n",
    "# plt.ylabel('ELO Rating Loser')\n",
    "# plt.title('Scatter Plot of ELO Ratings based on Win/Loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "\n",
    "# df['elo_diff'] = df['a_recent_elo_rating']\n",
    "\n",
    "# # Create bins for ELO difference in intervals of 10\n",
    "# bins = np.arange(df['elo_diff'].min(), df['elo_diff'].max() + 10, 10)\n",
    "# labels = (bins[:-1] + bins[1:]) / 2\n",
    "# df['elo_diff_bin'] = pd.cut(df['elo_diff'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Calculate average win rate at each ELO difference bin\n",
    "# average_win_rate = df.groupby('elo_diff_bin')['a_b_win'].mean().reset_index()\n",
    "# average_win_rate.columns = ['elo_diff_bin', 'avg_win_rate']\n",
    "\n",
    "# # Convert the bin labels to numeric values\n",
    "# average_win_rate['elo_diff_bin'] = average_win_rate['elo_diff_bin'].astype(float)\n",
    "\n",
    "# average_win_rate = average_win_rate[~np.isnan(average_win_rate).any(axis=1)]\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], color='blue', label='Average Win Rate', s=10, alpha=0.5)\n",
    "\n",
    "# # Fit a polynomial of degree 3 to the average win rate data\n",
    "# coefficients = np.polyfit(average_win_rate['elo_diff_bin'], average_win_rate['avg_win_rate'], 5)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# trendline_x = np.linspace(-600, 600, 100)\n",
    "# trendline_y = polynomial(trendline_x)\n",
    "# plt.plot(trendline_x, trendline_y, color='green', linewidth=1, label='Cubic Trendline')\n",
    "\n",
    "# # Setting the limits for x and y axis\n",
    "# plt.xlim(-600, 600)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('ELO Rating Difference (Winner - Loser)')\n",
    "# plt.ylabel('Average Win Rate')\n",
    "# plt.title('Scatter Plot of ELO Rating Difference vs. Win Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomeProbability(nn.Module):\n",
    "    def __init__(self, input_dim=36, dropout_prob=0.33):\n",
    "        hidden_dim = int(input_dim * (2/3))\n",
    "        super(OutcomeProbability, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)  # No sigmoid activation here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     51\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 52\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     53\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     54\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m, in \u001b[0;36mOutcomeProbability.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)  \u001b[38;5;66;03m# No sigmoid activation here\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df == .5).any(axis=1)]\n",
    "df = df[~(df == -20).any(axis=1)]\n",
    "\n",
    "# Extract odds and keep track of original indices\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "# Drop odds columns from the main DataFrame\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "# Separate features and target variable\n",
    "y = df['sets'].values\n",
    "X = df.drop('sets', axis=1).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, odds_df['index'].values, test_size=1/5, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_dataset = data.TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32), \n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "test_dataset = data.TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32), \n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 32\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = OutcomeProbability(input_dim=X.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = ceil(len(X_train) / batch_size)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        predictions.extend(torch.sigmoid(outputs).numpy())\n",
    "        actuals.extend(labels.numpy())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Loss: {test_loss / len(test_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Convert predictions and actuals to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Create a DataFrame with actuals and predictions\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': actuals,\n",
    "    'Predicted': predictions\n",
    "})\n",
    "comparison_df['index'] = idx_test\n",
    "\n",
    "# Merge the predictions with the original odds DataFrame\n",
    "comparison_test_values = odds_df.set_index('index').loc[idx_test]\n",
    "comparison_df = comparison_df.merge(\n",
    "    comparison_test_values.reset_index(),\n",
    "    on='index',\n",
    "    suffixes=('_model', '_original')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  index  a_odds  b_odds\n",
      "0        1.0   0.557799   9710    5.34    1.15\n",
      "1        0.0   0.449628  13827    1.11    6.35\n",
      "2        1.0   0.030533  13354    1.34    3.18\n",
      "3        0.0   0.590916  18891    1.76    2.03\n",
      "4        0.0   0.241654  17974    6.51    1.11\n",
      "...      ...        ...    ...     ...     ...\n",
      "2714     0.0   0.383567  26876    2.16    1.70\n",
      "2715     0.0   0.459142  22972    2.50    1.55\n",
      "2716     1.0   0.293903  19462    4.86    1.18\n",
      "2717     0.0   0.635385  14354    1.53    2.49\n",
      "2718     1.0   0.417027  12956    2.47    1.53\n",
      "\n",
      "[2719 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# results_df.head()\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    vegas_odds -= 1\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = calculated_probability - ((1 - calculated_probability)/vegas_odds)\n",
    "    # print(kelly_fraction)\n",
    "    \n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total won on $30 bankroll bets: 94.56 on a total # bets: 292 from a total of 2719 games\n",
      "Avg_bet_size $9.800283192834556\n",
      "Amount of incorrect bets : 0.6164383561643836\n",
      "Correct Bets: 0.3835616438356164\n",
      "Model % Correct : 0.6057374034571533\n"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "model_correct = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = comparison_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "confidence_pct = .5\n",
    "confidence_top_pct = 1\n",
    "\n",
    "avg_bet = 0\n",
    "\n",
    "OVER = 2.56\n",
    "UNDER = 1.48\n",
    "\n",
    "UNIT = 30\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :\n",
    "        kelly = (kelly_criterion(OVER, row['Predicted']) * UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1\n",
    "            total_won += (OVER-1) * kelly\n",
    "        else:\n",
    "            wrong += 1\n",
    "            total_won -= kelly\n",
    "\n",
    "    # if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :\n",
    "    #     kelly = (kelly_criterion(UNDER, 1-row['Predicted']) * UNIT)\n",
    "    #     better += 1 if kelly > 0 else 0\n",
    "    #     avg_bet += kelly\n",
    "    #     if(row['Actual'] == 0):\n",
    "    #         bet_correct += 1\n",
    "    #         total_won += (UNDER-1) * kelly\n",
    "    #     else:\n",
    "    #         wrong += 1\n",
    "    #         total_won -= kelly\n",
    "\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total won on ${UNIT} bankroll bets: {total_won:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"Avg_bet_size ${avg_bet/better}\")\n",
    "print(f\"Amount of incorrect bets : {wrong/better}\")\n",
    "print(f\"Correct Bets: {bet_correct/better}\")\n",
    "print(f\"Model % Correct : {model_correct/length}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
