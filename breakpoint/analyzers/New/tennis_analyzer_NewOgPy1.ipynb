{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20100101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36794\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_age</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>a_player_rank_points</th>\n",
       "      <th>b_player_age</th>\n",
       "      <th>b_player_rank</th>\n",
       "      <th>b_player_rank_points</th>\n",
       "      <th>rank_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_glicko_rating</th>\n",
       "      <th>b_surface_second_won_glicko_rating</th>\n",
       "      <th>a_surface_return_second_won_glicko_rd</th>\n",
       "      <th>b_surface_second_won_glicko_rd</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>350.159044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_date  best_of  tourney_round  a_player_age  a_player_rank  \\\n",
       "0   2010-01-04      3.0            0.8          20.0          306.0   \n",
       "1   2010-01-04      3.0            0.8          28.0          104.0   \n",
       "2   2010-01-04      3.0            0.8          30.0          111.0   \n",
       "3   2010-01-04      3.0            0.8          28.0           59.0   \n",
       "4   2010-01-04      3.0            0.8          33.0          446.0   \n",
       "\n",
       "   a_player_rank_points  b_player_age  b_player_rank  b_player_rank_points  \\\n",
       "0                 137.0          31.0           12.0                2625.0   \n",
       "1                 525.0          21.0           14.0                2430.0   \n",
       "2                 496.0          22.0          107.0                 516.0   \n",
       "3                 739.0          26.0          103.0                 526.0   \n",
       "4                  75.0          25.0           38.0                1015.0   \n",
       "\n",
       "   rank_diff  ...  a_surface_return_second_won_glicko_rating  \\\n",
       "0      294.0  ...                                     1500.0   \n",
       "1       90.0  ...                                     1500.0   \n",
       "2        4.0  ...                                     1500.0   \n",
       "3      -44.0  ...                                     1500.0   \n",
       "4      408.0  ...                                     1500.0   \n",
       "\n",
       "   b_surface_second_won_glicko_rating  a_surface_return_second_won_glicko_rd  \\\n",
       "0                              1500.0                             350.159044   \n",
       "1                              1500.0                             350.159044   \n",
       "2                              1500.0                             350.159044   \n",
       "3                              1500.0                             350.159044   \n",
       "4                              1500.0                             350.159044   \n",
       "\n",
       "   b_surface_second_won_glicko_rd  a_odds  b_odds  a_b_win  surface_Clay  \\\n",
       "0                      350.159044     NaN     NaN      0.0           0.0   \n",
       "1                      350.159044     NaN     NaN      0.0           0.0   \n",
       "2                      350.159044     NaN     NaN      0.0           0.0   \n",
       "3                      350.159044     NaN     NaN      0.0           0.0   \n",
       "4                      350.159044     NaN     NaN      0.0           0.0   \n",
       "\n",
       "   surface_Grass  surface_Hard  \n",
       "0            0.0           1.0  \n",
       "1            0.0           1.0  \n",
       "2            0.0           1.0  \n",
       "3            0.0           1.0  \n",
       "4            0.0           1.0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "RD_CUTOFF = 125\n",
    "\n",
    "df = pd.read_csv('../../testcsvs/GlickoUpdated.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "# df = df[(df['a_glicko_rd'] <= RD_CUTOFF) & (df['b_glicko_rd'] <= RD_CUTOFF)]\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "# print(df.duplicated().sum())\n",
    "\n",
    "# print(len(df))\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df.reset_index(drop=True), category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "# print(df.duplicated().sum())\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OutcomeProbability(nn.Module):\n",
    "#     def __init__(self, input_dim=160):\n",
    "#         hidden_dim1= round ((input_dim + 1) / 2)\n",
    "#         super(OutcomeProbability, self).__init__()\n",
    "#         self.hidden = nn.Linear(input_dim, hidden_dim1)\n",
    "#         self.relu = nn.SiLU()\n",
    "#         self.bn = nn.BatchNorm1d(hidden_dim1)\n",
    "#         self.output = nn.Linear(hidden_dim1, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "#     def forward(self, x):\n",
    "#         x = self.bn(self.relu(self.hidden(x)))\n",
    "#         x = self.sigmoid(self.output(x))\n",
    "#         return x\n",
    "    \n",
    "class OutcomeProbability(nn.Module):\n",
    "    def __init__(self, input_dim=160):\n",
    "        hidden_dim1= round ((input_dim) / 2)\n",
    "        hidden_dim2= round ((hidden_dim1) / 2)\n",
    "        super(OutcomeProbability, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.hidden1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.hidden2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu1 = nn.SiLU()\n",
    "        self.relu2 = nn.SiLU()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.output = nn.Linear(hidden_dim2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn1(self.relu1(self.hidden1(x)))\n",
    "        x = self.bn2(self.relu2(self.hidden2(x)))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.shortcut = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn(self.fc(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "class OutcomeProbabilityV6(nn.Module):\n",
    "    def __init__(self, input_dim=172, dropout_prob=0.33):\n",
    "        hidden_dim1=input_dim * 2\n",
    "        hidden_dim2=input_dim\n",
    "        hidden_dim3=round(input_dim/2) \n",
    "        super(OutcomeProbabilityV6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(hidden_dim1, hidden_dim1)\n",
    "        self.res_block2 = ResidualBlock(hidden_dim1, hidden_dim2)\n",
    "        self.res_block3 = ResidualBlock(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        \n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=160):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.relu = nn.SiLU() #hehe\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))  # Softmax is applied in the loss function\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    loss_fn = nn.BCEWithLogitsLoss()  # binary cross entropy\n",
    "\n",
    "    optimal_lr = .001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=optimal_lr)\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Parameters for learning rate warmup\n",
    "    warmup_epochs = 5\n",
    "    total_epochs = 300\n",
    "    batch_size = 32\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "    \n",
    "    # Set up learning rate scheduler (StepLR after warm-up)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = -np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        # Warm-up phase: linearly increase learning rate\n",
    "        if epoch < warmup_epochs:\n",
    "            # print(optimizer.param_groups[0]['lr'])\n",
    "            lr = optimal_lr * (epoch + 1) / warmup_epochs\n",
    "            # print(lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        model.train()\n",
    "        with tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # Take a batch\n",
    "                X_batch = X_train[start:start + batch_size]\n",
    "                y_batch = y_train[start:start + batch_size]\n",
    "                # Forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                # Print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "\n",
    "        # Evaluate accuracy at the end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            print(f\"Accuracy: {acc}\")\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # Apply scheduler after warm-up period\n",
    "        if epoch >= warmup_epochs:\n",
    "            scheduler.step()\n",
    "\n",
    "        # print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Restore model with the best weights and return the best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6331473588943481\n",
      "Accuracy: 0.6372577548027039\n",
      "Accuracy: 0.6385789513587952\n",
      "Accuracy: 0.6396065950393677\n",
      "Accuracy: 0.6403405666351318\n",
      "Accuracy: 0.6410745978355408\n",
      "Accuracy: 0.6434233784675598\n",
      "Accuracy: 0.6438637971878052\n",
      "Accuracy: 0.6444509625434875\n",
      "Accuracy: 0.6456253528594971\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[415], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# print(len(X.columns))\u001b[39;00m\n\u001b[1;32m     46\u001b[0m model \u001b[38;5;241m=\u001b[39m OutcomeProbabilityV6(\u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#For date removal\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m acc \u001b[38;5;241m=\u001b[39m model_train(model, X_train, y_train, X_test, y_test)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal model accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[414], line 40\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(model, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/decorators.py:50\u001b[0m, in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     48\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()(fn)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:428\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    425\u001b[0m     is_jit_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_is_tracing\n\u001b[1;32m    426\u001b[0m     is_fx_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39m_symbolic_trace\u001b[38;5;241m.\u001b[39mis_fx_tracing\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fx_tracing():\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39merror_on_nested_fx_trace:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/functools.py:76\u001b[0m, in \u001b[0;36mwraps\u001b[0;34m(wrapped, assigned, updated)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwraps\u001b[39m(wrapped,\n\u001b[1;32m     66\u001b[0m           assigned \u001b[38;5;241m=\u001b[39m WRAPPER_ASSIGNMENTS,\n\u001b[1;32m     67\u001b[0m           updated \u001b[38;5;241m=\u001b[39m WRAPPER_UPDATES):\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decorator factory to apply update_wrapper() to a wrapper function\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m       Returns a decorator that invokes update_wrapper() with the decorated\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m       update_wrapper().\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partial(update_wrapper, wrapped\u001b[38;5;241m=\u001b[39mwrapped,\n\u001b[1;32m     77\u001b[0m                    assigned\u001b[38;5;241m=\u001b[39massigned, updated\u001b[38;5;241m=\u001b[39mupdated)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "# print(len(df))\n",
    "\n",
    "# Extract relevant columns for odds and index\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "# Drop odds columns from the main dataframe\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "# Extract target variable `y` and features `X`\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1)\n",
    "\n",
    "# Ensure the 'tourney_date' column is in datetime format\n",
    "X['tourney_date'] = pd.to_datetime(X['tourney_date'])\n",
    "\n",
    "# Define the date ranges for training and testing\n",
    "train_start_date = \"2012-01-01\"\n",
    "train_end_date = \"2016-12-31\"\n",
    "test_start_date = \"2017-01-01\"\n",
    "test_end_date = \"2019-12-31\"\n",
    "\n",
    "# Filter the data for training and testing based on the date range\n",
    "train_mask = (X['tourney_date'] >= train_start_date) & (X['tourney_date'] <= train_end_date)\n",
    "test_mask = (X['tourney_date'] >= test_start_date) & (X['tourney_date'] <= test_end_date)\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = X.loc[train_mask].drop(columns=['tourney_date']).values  # Drop the 'tourney_date' column if not needed for training\n",
    "y_train = y[train_mask]\n",
    "idx_train = odds_df.loc[train_mask, 'index'].values\n",
    "\n",
    "X_test = X.loc[test_mask].drop(columns=['tourney_date']).values  # Drop the 'tourney_date' column if not needed for testing\n",
    "y_test = y[test_mask]\n",
    "idx_test = odds_df.loc[test_mask, 'index'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Make sure y_train has the correct shape\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # Ensure y_test has the correct shape\n",
    "\n",
    "\n",
    "\n",
    "# print(len(X.columns))\n",
    "model = OutcomeProbabilityV6(len(X.columns)-1) #For date removal\n",
    "acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {acc*100:.2f}%\")\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        y_pred = model(X_test[i:i+1])\n",
    "        # print(f\"{X_test[i].numpy()} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n",
    " \n",
    "    # Plot the ROC curve\n",
    "    y_pred = model(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr) # ROC curve = TPR vs FPR\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    corrected = vegas_odds - 1\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = calculated_probability - ((1 - calculated_probability)/corrected)\n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[377], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m vegas_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m wrong \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 15\u001b[0m comparison_df \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     16\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(comparison_df)\n\u001b[1;32m     18\u001b[0m avg_bet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "avg_bet = 0\n",
    "\n",
    "confidence_pct = .5\n",
    "confidence_top_pct = 1\n",
    "\n",
    "START_UNIT = 10\n",
    "UNIT = START_UNIT\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "    current = START_UNIT\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :\n",
    "        kelly = (kelly_criterion(row['A_Odds'], row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['A_Odds'], row['Predicted'])\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['A_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :\n",
    "        kelly = (kelly_criterion(row['B_Odds'], 1-row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['B_Odds'], 1-row['Predicted'])\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['B_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        kelly_A  = (kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        kelly_B  = (kelly_criterion(row['B_Odds'],1-row['Predicted']) * UNIT)\n",
    "\n",
    "        upset_predict += 1 if (kelly_A > 0 and round(row['Predicted']) == 1) or (kelly_B > 0 and round(row['Predicted']) == 0) else 0\n",
    "\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_correct += 1 if kelly_A > 0 else 0\n",
    "                upset_won += (row['A_Odds']-1) * kelly_A\n",
    "            else:\n",
    "                upset_correct += 1 if kelly_B > 0 else 0\n",
    "                upset_won += (row['B_Odds']-1) * kelly_B\n",
    "        elif round(row['Predicted']) == 1:\n",
    "            upset_won -= kelly_A\n",
    "        else:\n",
    "            upset_won -= kelly_B\n",
    "            \n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total returned on Starting ${UNIT} bankroll: {START_UNIT:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"ROI : {((START_UNIT-UNIT)/UNIT):.1f} X\")\n",
    "print(f\"Avg Bankroll Bet % : {(avg_bet/better):.3f} %\")\n",
    "print(f\"Amount of differing favorites %: {(diff_fav/length):.3f}\")\n",
    "print(f\"Amount of upset bets correct % : {(upset_correct/upset_predict):.3f} with Unit ${UNIT} won ${upset_won:.2f} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bet % : {(wrong/better):.4f}\")\n",
    "print(f\"Correct Bet %: {(bet_correct/better):.4f}\")\n",
    "print(f\"Model % Correct : {(model_correct/length):.4f} Vegas Correct % : {(vegas_correct/length):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
