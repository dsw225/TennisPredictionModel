{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Tennis Analyzer ML Model V2</h1>\n",
    "<h3 style=\"text-align: center;\">Dan Warnick</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start we will begin by selecting the data points we want to analyze with existing known results. For each data entry we will have two players each with the following data entries.</p>\n",
    "<table style=\"font-size: .8em;\">\n",
    "    <tr>\n",
    "        <th>Player Name</th>\n",
    "    </tr>\n",
    "</table>\n",
    "<p>Along with match facts like Clay/Hard/Grass Court or Indoor/Outdoor. In the future may want to add weather and adjust certain parameters for more accuracy and more data points to train from, however for now this seems a good start.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.) Collect Data Efficiently</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "from django.http import HttpResponse\n",
    "from django.template import loader\n",
    "import os\n",
    "from django.db import models\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as utils\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from asgiref.sync import sync_to_async # type: ignore\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'breakpoint.settings')\n",
    "# django.setup()\n",
    "\n",
    "# from render.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20100101'\n",
    "end = '20231231'\n",
    "match_type = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30873\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>best_of</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_round</th>\n",
       "      <th>a_player_age</th>\n",
       "      <th>a_player_hand</th>\n",
       "      <th>a_player_ht</th>\n",
       "      <th>a_player_rank</th>\n",
       "      <th>a_player_rank_points</th>\n",
       "      <th>b_player_age</th>\n",
       "      <th>...</th>\n",
       "      <th>a_surface_return_second_won_steph_rating</th>\n",
       "      <th>b_surface_second_won_steph_rating</th>\n",
       "      <th>a_surface_return_second_won_steph_rd</th>\n",
       "      <th>b_surface_second_won_steph_rd</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>a_b_win</th>\n",
       "      <th>surface_Clay</th>\n",
       "      <th>surface_Grass</th>\n",
       "      <th>surface_Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2240.437276</td>\n",
       "      <td>2254.797606</td>\n",
       "      <td>83.989772</td>\n",
       "      <td>82.219561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2222.195316</td>\n",
       "      <td>2229.115963</td>\n",
       "      <td>78.596809</td>\n",
       "      <td>82.965040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2274.598195</td>\n",
       "      <td>2315.399953</td>\n",
       "      <td>123.685795</td>\n",
       "      <td>90.600524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2228.403331</td>\n",
       "      <td>2254.264240</td>\n",
       "      <td>79.353430</td>\n",
       "      <td>75.273354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2278.439169</td>\n",
       "      <td>2253.402628</td>\n",
       "      <td>105.159633</td>\n",
       "      <td>94.631223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_date  best_of  tourney_level  tourney_round  a_player_age  \\\n",
       "0   2010-02-12      3.0            2.0           0.85          28.0   \n",
       "1   2010-02-21      3.0            2.0           1.00          24.0   \n",
       "2   2010-02-21      3.0            2.0           1.00          27.0   \n",
       "3   2010-02-24      3.0            2.0           0.80          29.0   \n",
       "4   2010-02-25      3.0            2.0           0.80          27.0   \n",
       "\n",
       "   a_player_hand  a_player_ht  a_player_rank  a_player_rank_points  \\\n",
       "0            0.0        183.0           32.0                1225.0   \n",
       "1            1.0        206.0           25.0                1430.0   \n",
       "2            1.0        175.0           19.0                1780.0   \n",
       "3            0.0        193.0           56.0                 783.0   \n",
       "4            1.0        175.0           17.0                1885.0   \n",
       "\n",
       "   b_player_age  ...  a_surface_return_second_won_steph_rating  \\\n",
       "0          28.0  ...                               2240.437276   \n",
       "1          22.0  ...                               2222.195316   \n",
       "2          30.0  ...                               2274.598195   \n",
       "3          28.0  ...                               2228.403331   \n",
       "4          22.0  ...                               2278.439169   \n",
       "\n",
       "   b_surface_second_won_steph_rating  a_surface_return_second_won_steph_rd  \\\n",
       "0                        2254.797606                             83.989772   \n",
       "1                        2229.115963                             78.596809   \n",
       "2                        2315.399953                            123.685795   \n",
       "3                        2254.264240                             79.353430   \n",
       "4                        2253.402628                            105.159633   \n",
       "\n",
       "   b_surface_second_won_steph_rd  a_odds  b_odds  a_b_win  surface_Clay  \\\n",
       "0                      82.219561     NaN     NaN      0.0           0.0   \n",
       "1                      82.965040     NaN     NaN      0.0           0.0   \n",
       "2                      90.600524     NaN     NaN      0.0           1.0   \n",
       "3                      75.273354     NaN     NaN      1.0           0.0   \n",
       "4                      94.631223     NaN     NaN      1.0           1.0   \n",
       "\n",
       "   surface_Grass  surface_Hard  \n",
       "0            0.0           1.0  \n",
       "1            0.0           1.0  \n",
       "2            0.0           0.0  \n",
       "3            0.0           1.0  \n",
       "4            0.0           0.0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.strptime(start, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end, '%Y%m%d').date()\n",
    "\n",
    "# if match_type == 'm':   \n",
    "#     typer = MensTennisMatch\n",
    "#     insert_db = MensTennisMatchStats\n",
    "# else:\n",
    "#     typer = WomensTennisMatch\n",
    "#     insert_db = WomensTennisMatchStats\n",
    "\n",
    "# query = insert_db.objects.filter(\n",
    "#         tourney_date__range=(start_date, end_date)\n",
    "#     ).order_by('tourney_date')\n",
    "    \n",
    "# games = await sync_to_async(list)(query.all().values())\n",
    "\n",
    "RD_CUTOFF = 125\n",
    "\n",
    "df = pd.read_csv('../../testcsvs/StephFixRP25.csv')\n",
    "# df = pd.read_csv('../../testcsvs/GlickoUpdated.csv')\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date']).dt.date\n",
    "df = df[(df['tourney_date'] >= start_date) & (df['tourney_date'] <= end_date)]\n",
    "# df = df[(df['a_glicko_rd'] <= RD_CUTOFF) & (df['b_glicko_rd'] <= RD_CUTOFF)]\n",
    "df = df[(df['a_steph_rd'] <= RD_CUTOFF) & (df['b_steph_rd'] <= RD_CUTOFF)]\n",
    "\n",
    "df = df.drop(['tourney_id', 'tourney_name', 'match_num', 'a_player_name', 'b_player_name', 'a_player_id', 'a_player_slug', 'b_player_id', 'b_player_slug', 'sets', 'games', 'tiebreaks'], axis=1)\n",
    "# print(df.duplicated().sum())\n",
    "\n",
    "# print(len(df))\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "category_encoded = one_hot_encoder.fit_transform(df[['surface']])\n",
    "category_encoded_df = pd.DataFrame(category_encoded, columns=one_hot_encoder.get_feature_names_out(['surface']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns back to the original DataFrame\n",
    "df = pd.concat([df.reset_index(drop=True), category_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'category_text' column\n",
    "df.drop('surface', axis=1, inplace=True)\n",
    "# print(df.duplicated().sum())\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OutcomeProbability(nn.Module):\n",
    "#     def __init__(self, input_dim=160):\n",
    "#         hidden_dim1= round ((input_dim + 1) / 2)\n",
    "#         super(OutcomeProbability, self).__init__()\n",
    "#         self.hidden = nn.Linear(input_dim, hidden_dim1)\n",
    "#         self.relu = nn.SiLU()\n",
    "#         self.bn = nn.BatchNorm1d(hidden_dim1)\n",
    "#         self.output = nn.Linear(hidden_dim1, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "#     def forward(self, x):\n",
    "#         x = self.bn(self.relu(self.hidden(x)))\n",
    "#         x = self.sigmoid(self.output(x))\n",
    "#         return x\n",
    "    \n",
    "class OutcomeProbability(nn.Module):\n",
    "    def __init__(self, input_dim=160):\n",
    "        hidden_dim1= round ((input_dim) / 2)\n",
    "        hidden_dim2= round ((hidden_dim1) / 2)\n",
    "        super(OutcomeProbability, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.hidden1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.hidden2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu1 = nn.SiLU()\n",
    "        self.relu2 = nn.SiLU()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.output = nn.Linear(hidden_dim2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn1(self.relu1(self.hidden1(x)))\n",
    "        x = self.bn2(self.relu2(self.hidden2(x)))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.shortcut = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn(self.fc(x)))\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "class OutcomeProbabilityV6(nn.Module):\n",
    "    def __init__(self, input_dim=172, dropout_prob=0.33):\n",
    "        hidden_dim1=input_dim * 2\n",
    "        hidden_dim2=input_dim\n",
    "        hidden_dim3=round(input_dim/2) \n",
    "        super(OutcomeProbabilityV6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(hidden_dim1, hidden_dim1)\n",
    "        self.res_block2 = ResidualBlock(hidden_dim1, hidden_dim2)\n",
    "        self.res_block3 = ResidualBlock(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        \n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=160):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.relu = nn.SiLU() #hehe\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))  # Softmax is applied in the loss function\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    loss_fn = nn.BCEWithLogitsLoss()  # binary cross entropy\n",
    "\n",
    "    optimal_lr = .001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=optimal_lr)\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Parameters for learning rate warmup\n",
    "    warmup_epochs = 5\n",
    "    total_epochs = 300\n",
    "    batch_size = 32\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "    \n",
    "    # Set up learning rate scheduler (StepLR after warm-up)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = -np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        # Warm-up phase: linearly increase learning rate\n",
    "        if epoch < warmup_epochs:\n",
    "            # print(optimizer.param_groups[0]['lr'])\n",
    "            lr = optimal_lr * (epoch + 1) / warmup_epochs\n",
    "            # print(lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        model.train()\n",
    "        with tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # Take a batch\n",
    "                X_batch = X_train[start:start + batch_size]\n",
    "                y_batch = y_train[start:start + batch_size]\n",
    "                # Forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                # Print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "\n",
    "        # Evaluate accuracy at the end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            print(f\"Accuracy: {acc}\")\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # Apply scheduler after warm-up period\n",
    "        if epoch >= warmup_epochs:\n",
    "            scheduler.step()\n",
    "\n",
    "        # print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Restore model with the best weights and return the best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6000000238418579\n",
      "Accuracy: 0.6040683388710022\n",
      "Accuracy: 0.6349877715110779\n",
      "Accuracy: 0.6476810574531555\n",
      "Accuracy: 0.6484947204589844\n",
      "Accuracy: 0.64947110414505\n",
      "Accuracy: 0.6540276408195496\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "# print(len(df))\n",
    "\n",
    "# Extract relevant columns for odds and index\n",
    "odds_df = df[['a_odds', 'b_odds']].copy()\n",
    "odds_df['index'] = df.index\n",
    "\n",
    "# Drop odds columns from the main dataframe\n",
    "df = df.drop(columns=['a_odds', 'b_odds'])\n",
    "\n",
    "# Extract target variable `y` and features `X`\n",
    "y = df['a_b_win'].values\n",
    "X = df.drop('a_b_win', axis=1)\n",
    "\n",
    "# Ensure the 'tourney_date' column is in datetime format\n",
    "X['tourney_date'] = pd.to_datetime(X['tourney_date'])\n",
    "\n",
    "# Define the date ranges for training and testing\n",
    "train_start_date = \"2012-01-01\"\n",
    "train_end_date = \"2016-12-31\"\n",
    "test_start_date = \"2017-01-01\"\n",
    "test_end_date = \"2019-12-31\"\n",
    "\n",
    "# Filter the data for training and testing based on the date range\n",
    "train_mask = (X['tourney_date'] >= train_start_date) & (X['tourney_date'] <= train_end_date)\n",
    "test_mask = (X['tourney_date'] >= test_start_date) & (X['tourney_date'] <= test_end_date)\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train = X.loc[train_mask].drop(columns=['tourney_date']).values  # Drop the 'tourney_date' column if not needed for training\n",
    "y_train = y[train_mask]\n",
    "idx_train = odds_df.loc[train_mask, 'index'].values\n",
    "\n",
    "X_test = X.loc[test_mask].drop(columns=['tourney_date']).values  # Drop the 'tourney_date' column if not needed for testing\n",
    "y_test = y[test_mask]\n",
    "idx_test = odds_df.loc[test_mask, 'index'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Make sure y_train has the correct shape\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # Ensure y_test has the correct shape\n",
    "\n",
    "\n",
    "\n",
    "# print(len(X.columns))\n",
    "model = OutcomeProbabilityV6(len(X.columns)-1) #For date removal\n",
    "acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {acc*100:.2f}%\")\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        y_pred = model(X_test[i:i+1])\n",
    "        # print(f\"{X_test[i].numpy()} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n",
    " \n",
    "    # Plot the ROC curve\n",
    "    y_pred = model(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr) # ROC curve = TPR vs FPR\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly Criterion\n",
    "def kelly_criterion(vegas_odds, calculated_probability):\n",
    "    corrected = vegas_odds - 1\n",
    "    # Calculate the Kelly fraction\n",
    "    kelly_fraction = calculated_probability - ((1 - calculated_probability)/corrected)\n",
    "    # Ensure that the fraction is not negative\n",
    "    kelly_fraction = max(0, kelly_fraction)\n",
    "    \n",
    "    return kelly_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m vegas_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m wrong \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 15\u001b[0m comparison_df \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     16\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(comparison_df)\n\u001b[1;32m     18\u001b[0m avg_bet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "better = 0\n",
    "total_won = 0\n",
    "diff_fav = 0\n",
    "bet_correct = 0\n",
    "\n",
    "upset_predict = 0\n",
    "upset_correct = 0\n",
    "upset_won = 0\n",
    "\n",
    "model_correct = 0\n",
    "vegas_correct = 0\n",
    "vegas_total = 0\n",
    "\n",
    "wrong = 0\n",
    "comparison_df = results_df.dropna()\n",
    "length = len(comparison_df)\n",
    "\n",
    "avg_bet = 0\n",
    "\n",
    "confidence_pct = .5\n",
    "confidence_top_pct = 1\n",
    "\n",
    "START_UNIT = 10\n",
    "UNIT = START_UNIT\n",
    "\n",
    "for i, row in comparison_df.iterrows():\n",
    "    current = START_UNIT\n",
    "    if confidence_top_pct > row['Predicted'] > confidence_pct :\n",
    "        kelly = (kelly_criterion(row['A_Odds'], row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['A_Odds'], row['Predicted'])\n",
    "        if(row['Actual'] == 1):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['A_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if 1-confidence_top_pct < row['Predicted'] < 1-confidence_pct :\n",
    "        kelly = (kelly_criterion(row['B_Odds'], 1-row['Predicted']) * START_UNIT)\n",
    "        better += 1 if kelly > 0 else 0\n",
    "        avg_bet += kelly_criterion(row['B_Odds'], 1-row['Predicted'])\n",
    "        if(row['Actual'] == 0):\n",
    "            bet_correct += 1 if kelly > 0 else 0\n",
    "            START_UNIT += (row['B_Odds']-1) * kelly\n",
    "        else:\n",
    "            wrong += 1 if kelly > 0 else 0\n",
    "            START_UNIT -= kelly\n",
    "\n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        kelly_A  = (kelly_criterion(row['A_Odds'],row['Predicted']) * UNIT)\n",
    "        kelly_B  = (kelly_criterion(row['B_Odds'],1-row['Predicted']) * UNIT)\n",
    "\n",
    "        upset_predict += 1 if (kelly_A > 0 and round(row['Predicted']) == 1) or (kelly_B > 0 and round(row['Predicted']) == 0) else 0\n",
    "\n",
    "        if round(row['Predicted']) == round(row['Actual']):\n",
    "            if(row['Actual'] == 1):\n",
    "                upset_correct += 1 if kelly_A > 0 else 0\n",
    "                upset_won += (row['A_Odds']-1) * kelly_A\n",
    "            else:\n",
    "                upset_correct += 1 if kelly_B > 0 else 0\n",
    "                upset_won += (row['B_Odds']-1) * kelly_B\n",
    "        elif round(row['Predicted']) == 1:\n",
    "            upset_won -= kelly_A\n",
    "        else:\n",
    "            upset_won -= kelly_B\n",
    "            \n",
    "    if round(row['Predicted']) != round(1/row['A_Odds']):\n",
    "        diff_fav += 1\n",
    "\n",
    "    if row['Actual']==1 and row['A_Odds'] < row['B_Odds']:\n",
    "        # print(f\"A odds : {row['a_odds']} B odds : {row['b_odds']}\")\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if row['Actual']==0 and row['A_Odds'] > row['B_Odds']:\n",
    "        vegas_correct += 1\n",
    "\n",
    "    if round(row['Predicted']) == round(row['Actual']):\n",
    "        model_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Total returned on Starting ${UNIT} bankroll: {START_UNIT:.2f} on a total # bets: {better} from a total of {length} games\")\n",
    "print(f\"ROI : {((START_UNIT-UNIT)/UNIT):.1f} X\")\n",
    "print(f\"Avg Bankroll Bet % : {(avg_bet/better):.3f} %\")\n",
    "print(f\"Amount of differing favorites %: {(diff_fav/length):.3f}\")\n",
    "print(f\"Amount of upset bets correct % : {(upset_correct/upset_predict):.3f} with Unit ${UNIT} won ${upset_won:.2f} on {upset_predict} bets\")\n",
    "print(f\"Amount of incorrect bet % : {(wrong/better):.4f}\")\n",
    "print(f\"Correct Bet %: {(bet_correct/better):.4f}\")\n",
    "print(f\"Model % Correct : {(model_correct/length):.4f} Vegas Correct % : {(vegas_correct/length):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
